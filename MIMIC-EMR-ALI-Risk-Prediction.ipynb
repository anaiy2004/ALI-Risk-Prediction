{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of MIMICEMREventPrediction(Working).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPiSB9faj09OOi2wMijJxwk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anaiy2004/ALI-Risk-Prediction/blob/main/MIMIC-EMR-ALI-Risk-Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWyIKqlKBtlo"
      },
      "source": [
        "!wget -r -N -c -np --user anaiysomalwar --ask-password https://physionet.org/files/mimiciii/1.4/    \n",
        "#reading in files from MIMIC III (password protected)\n",
        "#run this directly on terminal when using gcp\n",
        "#output of code cell deleted for privacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-7g0Q2hS9_S",
        "outputId": "3ad5af92-7c6d-40b2-c85b-a3a9d0c2758d"
      },
      "source": [
        "#allows for Pyspark / SQL use on Google Collab\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://apache.claz.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\"\n",
        "!pip3 install findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (1.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVxgcrZgWrQ_"
      },
      "source": [
        "#https://github.com/dhlee4/AcuteOrganFailureInterventionModel/blob/master/mimic_hp_training_scale.py lines 117 - end of file -> first step of recreation calls mimic_run_experiment on line 131\n",
        "#since mimic_run_experiment is called, we move to line 25 in that same file, where the class has the constructor\n",
        "#on line 31, mimic_preprocesser is called is constructed, so we go to https://github.com/dhlee4/AcuteOrganFailureInterventionModel/blob/master/mimic_preprocess.py\n",
        "#on line 8, mimic_data_abstracter is called so we go to https://github.com/dhlee4/AcuteOrganFailureInterventionModel/blob/master/mimic_data_abstracter.py -> does nothing but def methods\n",
        "#on line 9 from mimic_preprocess, data_preprocessor is initialized https://github.com/dhlee4/AcuteOrganFailureInterventionModel/blob/master/data_preprocessor.py\n",
        "#where data_preprocessor is initialized, preprocessor_gen is called\n",
        "\n",
        "#Target Disease: 42731, 5849, 51881,5990\n",
        "from pyspark.sql.functions import col,when,lit\n",
        "# this target disease does not do anyything\n",
        "target_disease=[\"51881\"]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEAjr5vxWnJX"
      },
      "source": [
        "def add_demo():\n",
        "        import pyspark\n",
        "        from pyspark.sql.functions import datediff,col\n",
        "        from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
        "        from pyspark.ml.feature import VectorAssembler\n",
        "        import pandas as pd\n",
        "\n",
        "        cur_demo = pd.read_csv(\"physionet.org/files/mimiciii/1.4/PATIENTS.csv.gz\", low_memory= False)\n",
        "        patientsFinalColumns = [\"SUBJECT_ID\", \"DOB\", \"GENDER\"]\n",
        "        cur_demo = cur_demo[cur_demo.columns.intersection(patientsFinalColumns)]\n",
        "        \n",
        "        cur_pts = pd.read_csv(\"physionet.org/files/mimiciii/1.4/ADMISSIONS.csv.gz\",  low_memory= False)\n",
        "        admissionsFinalColumnNames = [\"SUBJECT_ID\", \"HADM_ID\", \"ADMITTIME\", \"ADMISSION_TYPE\", \"ADMISSION_LOCATION\", \"INSURANCE\", \"LANGUAGE\", \"RELIGION\", \"MARITAL_STATUS\", \"ETHNICITY\"]\n",
        "        cur_pts = cur_pts[cur_pts.columns.intersection(admissionsFinalColumnNames)]\n",
        "\n",
        "        from pyspark.context import SparkContext\n",
        "        from pyspark.sql.session import SparkSession\n",
        "        sc = SparkContext.getOrCreate();\n",
        "        spark = SparkSession(sc)\n",
        "        cur_pts.LANGUAGE = cur_pts.LANGUAGE.astype(str)\n",
        "        cur_pts.MARITAL_STATUS = cur_pts.MARITAL_STATUS.astype(str)\n",
        "        cur_pts.RELIGION = cur_pts.RELIGION.astype(str)\n",
        "        cur_demo = spark.createDataFrame(cur_demo)\n",
        "        cur_pts = spark.createDataFrame(cur_pts)\n",
        "        merged_demo = cur_demo.join(cur_pts,\"SUBJECT_ID\").drop(\"SUBJECT_ID\")\n",
        "        merged_demo = merged_demo.withColumn(\"AGE\",datediff(\"ADMITTIME\",\"DOB\")/365.0).withColumn(\"AGE\",when(col(\"AGE\")>90,90).otherwise(col(\"AGE\"))).drop(\"ADMITTIME\",\"DOB\").where(\"AGE > 18\").fillna(\"N/A\")\n",
        "\n",
        "        target_col = merged_demo.columns\n",
        "        target_col.remove(\"AGE\")\n",
        "        target_col.remove(\"HADM_ID\")\n",
        "        target_col.sort()\n",
        "        vector_target = [\"AGE\"]\n",
        "        demo_col_list = [\"AGE\"]\n",
        "        for cat_col in target_col:\n",
        "            SI_model= StringIndexer(inputCol=cat_col, outputCol=\"SI_{0}\".format(cat_col)).fit(merged_demo)\n",
        "            demo_col_list = demo_col_list+[demo_var+\"||\"+demo_info for demo_var, demo_info in (zip([cat_col]*len(SI_model.labels),SI_model.labels))]\n",
        "            merged_demo = SI_model.transform(merged_demo)\n",
        "            merged_demo = OneHotEncoder(inputCol=\"SI_{0}\".format(cat_col),outputCol=\"OH_{0}\".format(cat_col), dropLast=False).fit(merged_demo).transform(merged_demo)\n",
        "            vector_target.append(\"OH_{0}\".format(cat_col))\n",
        "\n",
        "        import json\n",
        "\n",
        "        return_df = VectorAssembler(inputCols=vector_target,outputCol=\"demo_feature\").transform(merged_demo)\n",
        "        return return_df.withColumnRenamed(\"HADM_ID\", \"ID\").select(\"ID\",\"demo_feature\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TKIjA8_N_YU"
      },
      "source": [
        "#x = add_demo()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOwslu8CQyVJ"
      },
      "source": [
        "#look at https://github.com/dhlee4/AcuteOrganFailureInterventionModel/blob/master/mimic_data_abstracter.py\n",
        "####################### -> Part 2 of the Code -> equivalent to get_df_df method\n",
        "#https://github.com/dhlee4/AcuteOrganFailureInterventionModel/blob/master/mimic_data_abstracter.py lines 22 -> 39\n",
        "def get_def_df():\n",
        "  import pandas as pd\n",
        "  cur_chart_df = pd.read_csv(\"physionet.org/files/mimiciii/1.4/D_ITEMS.csv.gz\")\n",
        "  cur_chart_df = cur_chart_df[cur_chart_df[\"LINKSTO\"] == \"chartevents\"]\n",
        "  cur_chart_dfFinalColumns = [\"ITEMID\",\"LABEL\"]\n",
        "  cur_chart_df = cur_chart_df[cur_chart_df.columns.intersection(cur_chart_dfFinalColumns)]\n",
        "  cur_chart_df_AddedList = []\n",
        "  for i in range(len(cur_chart_df)):\n",
        "    cur_chart_df_AddedList.append( \"VITAL\") #this is the .alias lit() segment in SQL\n",
        "  cur_chart_df[\"SOURCE\"] = cur_chart_df_AddedList\n",
        "  cur_chart_df.head()\n",
        "\n",
        "  cur_med_df = pd.read_csv(\"physionet.org/files/mimiciii/1.4/D_ITEMS.csv.gz\")\n",
        "  cur_med_df = cur_med_df[cur_med_df[\"LINKSTO\"] == \"inputevents_mv\"]\n",
        "  cur_med_dfFinalColumns = [\"ITEMID\", \"LABEL\"]\n",
        "  cur_med_df = cur_med_df[cur_med_df.columns.intersection(cur_med_dfFinalColumns)]\n",
        "  cur_med_df_AddedList = []\n",
        "  for i in range(len(cur_med_df)):\n",
        "    cur_med_df_AddedList.append(\"MED\") #this is the .alias lit() segment in SQL\n",
        "  cur_med_df[\"SOURCE\"] = cur_med_df_AddedList\n",
        "  cur_med_df.head()\n",
        "\n",
        "  cur_proc_df = pd.read_csv(\"physionet.org/files/mimiciii/1.4/D_ITEMS.csv.gz\")\n",
        "  cur_proc_df = cur_proc_df[cur_proc_df[\"LINKSTO\"] == \"procedureevents_mv\"]\n",
        "  cur_proc_dfFinalColumns = [\"ITEMID\", \"LABEL\"]\n",
        "  cur_proc_df = cur_proc_df[cur_proc_df.columns.intersection(cur_proc_dfFinalColumns)]\n",
        "  cur_proc_df_AddedList = []\n",
        "  for i in range(len(cur_proc_df)):\n",
        "    cur_proc_df_AddedList.append(\"PROC\") #this is the .alias lit() segment in SQL\n",
        "  cur_proc_df[\"SOURCE\"] = cur_proc_df_AddedList\n",
        "  cur_proc_df.head()\n",
        "\n",
        "  cur_lab_df = pd.read_csv(\"physionet.org/files/mimiciii/1.4/D_ITEMS.csv.gz\")\n",
        "  cur_lab_dfFinalColumns = [\"ITEMID\", \"LABEL\"]\n",
        "  cur_lab_df = cur_lab_df[cur_lab_df.columns.intersection(cur_lab_dfFinalColumns)]\n",
        "  cur_lab_df_AddedList = []\n",
        "  for i in range(len(cur_lab_df)):\n",
        "    cur_lab_df_AddedList.append(\"LAB\") #this is the .alias lit() segment in SQL\n",
        "  cur_lab_df[\"SOURCE\"] = cur_lab_df_AddedList\n",
        "  cur_lab_df.head()\n",
        "\n",
        "  #double check whether \\ in SQL is just a line break\n",
        "  import pandas as pd\n",
        "  #what does lit($$) mean? I am just adding together things instead of the .concat method, but there is lit($$) between them, which I am assuming is \" \"\n",
        "  cur_cpt_df = pd.read_csv(\"physionet.org/files/mimiciii/1.4/CPTEVENTS.csv.gz\").fillna(\"\")\n",
        "  cur_cpt_df_renamedCPT_CD = cur_cpt_df[\"CPT_CD\"]\n",
        "  cur_cpt_df[\"ITEMID\"] = cur_cpt_df_renamedCPT_CD\n",
        "  cur_cpt_df_concatdescription = []\n",
        "  for i in range(len(cur_cpt_df)):\n",
        "    cur_cpt_df_concatdescription.append(cur_cpt_df[\"SECTIONHEADER\"][i] + \" \" + cur_cpt_df[\"SUBSECTIONHEADER\"][i] + cur_cpt_df[\"DESCRIPTION\"][i]) #double check this\n",
        "  cur_cpt_df[\"LABEL\"] = cur_cpt_df_concatdescription\n",
        "  cur_cpt_df_AddedList = []\n",
        "  for i in range(len(cur_cpt_df)):\n",
        "    cur_cpt_df_AddedList.append(\"CPT\") #this is the .alias lit() segment in SQL\n",
        "  cur_cpt_df[\"SOURCE\"] = cur_cpt_df_AddedList\n",
        "  cur_cpt_dfFinalColumns = [\"ITEMID\", \"LABEL\", \"SOURCE\"]\n",
        "  cur_cpt_df = cur_cpt_df[cur_cpt_df.columns.intersection(cur_cpt_dfFinalColumns)]\n",
        "  cur_cpt_df = cur_cpt_df.drop_duplicates(inplace = False)\n",
        "  cur_cpt_df.head()\n",
        "  # currently on line 32 of github\n",
        "\n",
        "  cur_icd_df = pd.read_csv(\"physionet.org/files/mimiciii/1.4/D_ICD_DIAGNOSES.csv.gz\")\n",
        "  cur_icd_df_renamedICD9Code = cur_icd_df[\"ICD9_CODE\"]\n",
        "  cur_icd_df[\"ITEMID\"] = cur_icd_df_renamedICD9Code\n",
        "  cur_icd_df_renamedLongTitle = cur_icd_df[\"LONG_TITLE\"]\n",
        "  cur_icd_df[\"LABEL\"] = cur_icd_df_renamedLongTitle\n",
        "  cur_icd_df_AddedList = []\n",
        "  for i in range(len(cur_icd_df)):\n",
        "    cur_icd_df_AddedList.append(\"ICD_DIAGNOSIS\") #this is the .alias lit() segment in SQL\n",
        "  cur_icd_df[\"SOURCE\"] = cur_icd_df_AddedList\n",
        "  cur_icd_dfFinalColumns = [\"ITEMID\", \"LABEL\", \"SOURCE\"]\n",
        "  cur_icd_df = cur_icd_df[cur_icd_df.columns.intersection(cur_icd_dfFinalColumns)]\n",
        "  cur_icd_df.head()\n",
        "\n",
        "  #what are we merging the dataframes by? -> assuming that we just stack them and remove duplicates, which is what the union operator seems to be\n",
        "  def_df = pd.concat([cur_med_df, cur_proc_df, cur_chart_df, cur_lab_df, cur_cpt_df,cur_icd_df]).drop_duplicates()\n",
        "  print(len(def_df))\n",
        "  def_df.head()\n",
        "  return def_df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa4klIQZOpjt"
      },
      "source": [
        "#y = get_def_df()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzMOwSZTiUZl"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9EN3AWDAljQ"
      },
      "source": [
        "####################### -> Part 3 of the Code -> equivalent to the remove_dnr_pts and get_obs_df method\n",
        "#https://github.com/dhlee4/AcuteOrganFailureInterventionModel/blob/master/mimic_data_abstracter.py lines 45 -> 73\n",
        "#implement get_obs_df on line 75 to create cur_chart for line 45\n",
        "#cur_dnr_inst = cur_chart_df[cur_chart_df[\"ITEMID\"] == 223758]\n",
        "#cur_dnr_inst = cur_dnr_inst[cur_dnr_inst[\"VALUE\"].isin(cur_dnr_assertion)]\n",
        "#beginning implementation of get_obs_df method -> lines 75 - 111\n",
        "\n",
        "import pandas as pd\n",
        "def remove_dnr_pts(cur_chart = pd.DataFrame()):\n",
        "  # double check whether get_obs_df is called first and that this if statement is just as a safety measure, because if remove_dnr_pts is called first\n",
        "  #then, it would call get_obs_df which would call remove_dnr_points w/o the if statement, store it in cur_chart, and go through the non-if statement again\n",
        "  if(cur_chart.empty):\n",
        "    cur_chart = get_obs_df()\n",
        "\n",
        "  cur_dnr_assertion = [\"DNR (do not resuscitate)\", \"DNR / DNI\", \"Comfort measures only\", \"DNI (do not intubate)\"]\n",
        "  cur_dnr_inst = cur_chart[cur_chart[\"ITEMID\"] == 223758]\n",
        "  cur_dnr_inst = cur_dnr_inst[cur_dnr_inst[\"VALUE\"].isin(cur_dnr_assertion)]\n",
        "  cur_dnr_inst = cur_dnr_inst.groupby(\"ID\").TIME_OBS.agg(['min'])\n",
        "  cur_dnr_inst = cur_dnr_inst.rename(columns = {\"min\" : \"DNR_TIME\"})\n",
        "  cur_chart = cur_chart.merge(cur_dnr_inst, on = \"ID\", how = \"left\")\n",
        "  print(cur_dnr_inst.shape)\n",
        "  del cur_dnr_inst\n",
        "  cur_chart = cur_chart.head(int(len(cur_chart)/15)) # MAKE SURE TO COMMENT OUT CHANGED FROM 200!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "  #double check correct lambda function\n",
        "  cur_chart = cur_chart[cur_chart['DNR_TIME'].apply(lambda x: str(x) == \"NaT\" or cur_chart[\"DNR_TIME\"] > cur_chart[\"TIME_OBS\"])]\n",
        "  print(cur_chart.head())\n",
        "  cur_chart = cur_chart.drop(columns = [\"DNR_TIME\"])\n",
        "  pts_icu_stay = get_icu_stay() #continue this method, check whether to uncomment final code from get_obs_df\n",
        "  cur_chart = cur_chart.merge(pts_icu_stay, on = \"ID\")\n",
        "  cur_chart = cur_chart[cur_chart[\"INTIME\"] <= cur_chart[\"TIME_OBS\"]]\n",
        "  cur_chart = cur_chart[cur_chart[\"OUTTIME\"] >= cur_chart[\"TIME_OBS\"]]\n",
        "  cur_chart = cur_chart.drop(columns = [\"INTIME\", \"OUTTIME\"])\n",
        "  return cur_chart\n",
        "\n",
        "def get_obs_df():\n",
        "  import pandas as pd\n",
        "  cur_vital = pd.read_csv(\"physionet.org/files/mimiciii/1.4/CHARTEVENTS.csv.gz\", usecols = [\"HADM_ID\", \"VALUE\", \"CHARTTIME\", \"ITEMID\"], dtype = {\"HADM_ID\" : \"int32\", \"ITEMID\" : \"int32\"})\n",
        "  cur_vital = cur_vital.rename(columns = {\"HADM_ID\" : \"ID\", \"CHARTTIME\" : \"TIME_OBS\"})\n",
        "  cur_vital_AddedList = []\n",
        "  for i in range(len(cur_vital)):\n",
        "    cur_vital_AddedList.append(\"VITAL\") #this is the .alias lit() segment in SQL\n",
        "  cur_vital[\"SOURCE\"] = cur_vital_AddedList\n",
        "  print(cur_vital.info())\n",
        "  print(cur_vital.memory_usage())\n",
        "  cur_vital.head()\n",
        "\n",
        "  import pandas as pd\n",
        "  cur_lab = pd.read_csv(\"physionet.org/files/mimiciii/1.4/LABEVENTS.csv.gz\", usecols = [\"HADM_ID\", \"VALUE\", \"CHARTTIME\", \"ITEMID\"])\n",
        "  cur_lab = cur_lab.rename(columns = {\"HADM_ID\" : \"ID\", \"CHARTTIME\" : \"TIME_OBS\"})\n",
        "  cur_lab_AddedList = []\n",
        "  for i in range(len(cur_lab)):\n",
        "    cur_lab_AddedList.append(\"LAB\") #this is the .alias lit() segment in SQL\n",
        "  cur_lab[\"SOURCE\"] = cur_lab_AddedList\n",
        "  print(cur_lab.info())\n",
        "  print(cur_lab.memory_usage())\n",
        "  cur_lab.head()\n",
        "  cur_vital = cur_vital.head(int(len(cur_vital)/40)) # MAKE SURE TO COMMENT OUT  -> CHANGED FROM 40\n",
        "\n",
        "  merged_obs = pd.concat([cur_vital, cur_lab])\n",
        "  merged_obs.head()\n",
        "\n",
        "  #continuing get_obs_df method -> line 103 to 105\n",
        "  # TEST THIS PART OF THE CODE\n",
        "  merged_obs = pd.merge(merged_obs, get_icu_stay(), on='ID')\n",
        "  merged_obs[\"INTIME\"] = pd.to_datetime(merged_obs[\"INTIME\"])\n",
        "  merged_obs[\"OUTTIME\"] = pd.to_datetime(merged_obs[\"OUTTIME\"])\n",
        "  merged_obs[\"TIME_OBS\"] = pd.to_datetime(merged_obs[\"TIME_OBS\"])\n",
        "  merged_obs = merged_obs[merged_obs[\"INTIME\"] < merged_obs[\"OUTTIME\"]]\n",
        "  merged_obs = merged_obs[merged_obs[\"TIME_OBS\"] <= merged_obs[\"OUTTIME\"]].drop(columns = [\"INTIME\", \"OUTTIME\"])\n",
        "  merged_obs.head()\n",
        "  # DOUBLE CHECK WHETHER TO INCLUDE THIS, maybe comment out for testing\n",
        "  print(\"check!!!\")\n",
        "  merged_obs = remove_dnr_pts(cur_chart = merged_obs)\n",
        "\n",
        "  return merged_obs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS4YhcAJQHVY"
      },
      "source": [
        "#implementing the get_icu_stay method, which is a helper method for get_obs_df (line 103 /216 -222)\n",
        "def get_icu_stay():\n",
        "  import pandas as pd\n",
        "  get_icu_stay_df = pd.read_csv(\"physionet.org/files/mimiciii/1.4/ICUSTAYS.csv.gz\", usecols = [\"HADM_ID\", \"INTIME\", \"OUTTIME\", \"DBSOURCE\"])\n",
        "  get_icu_stay_df = get_icu_stay_df[get_icu_stay_df[\"DBSOURCE\"] == \"metavision\"]\n",
        "  get_icu_stay_df = get_icu_stay_df.rename(columns = {\"HADM_ID\" : \"ID\"})\n",
        "  get_icu_stay_df[\"INTIME\"] = pd.to_datetime(get_icu_stay_df[\"INTIME\"])\n",
        "  get_icu_stay_df[\"OUTTIME\"] = pd.to_datetime(get_icu_stay_df[\"OUTTIME\"])\n",
        "  get_icu_stay_df.head()\n",
        "  return get_icu_stay_df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5sCB--Px_rY"
      },
      "source": [
        "#obsDf = get_obs_df() use only top comment\n",
        "#cur_chart = remove_dnr_pts(obsDf)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEwvhPLIuX9-"
      },
      "source": [
        "#obsDf.head()\n",
        "#check why dbsource x and y exist and are not merged -> should be baesd on the icu_stay new code for the method"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H2TnJ0f0dzx"
      },
      "source": [
        "def get_action_df():\n",
        "  cur_med = pd.read_csv(\"physionet.org/files/mimiciii/1.4/INPUTEVENTS_MV.csv.gz\", usecols = [\"HADM_ID\", \"STARTTIME\", \"ITEMID\"])\n",
        "  cur_med_AddedList = []\n",
        "  for i in range(len(cur_med)):\n",
        "    cur_med_AddedList.append(\"MED\") #this is the .alias lit() segment in SQL\n",
        "  cur_med[\"SOURCE\"] = cur_med_AddedList\n",
        "  cur_med = cur_med.rename(columns = {\"HADM_ID\" : \"ID\", \"STARTTIME\" : \"TIME_OBS\"})\n",
        "\n",
        "  cur_cpt = pd.read_csv(\"physionet.org/files/mimiciii/1.4/CPTEVENTS.csv.gz\", usecols = [\"HADM_ID\", \"CHARTDATE\", \"CPT_NUMBER\"])\n",
        "  cur_cpt_AddedList = []\n",
        "  for i in range(len(cur_cpt)):\n",
        "    cur_cpt_AddedList.append(\"CPT\") #this is the .alias lit() segment in SQL\n",
        "  cur_cpt[\"SOURCE\"] = cur_cpt_AddedList\n",
        "  cur_cpt = cur_cpt.rename(columns = {\"HADM_ID\" : \"ID\", \"CHARTDATE\" : \"TIME_OBS\", \"CPT_NUMBER\" : \"ITEMID\"})\n",
        "\n",
        "  cur_proc = pd.read_csv(\"physionet.org/files/mimiciii/1.4/PROCEDUREEVENTS_MV.csv.gz\", usecols = [\"HADM_ID\", \"STARTTIME\", \"ITEMID\"])\n",
        "  cur_proc_AddedList = []\n",
        "  for i in range(len(cur_proc)):\n",
        "    cur_proc_AddedList.append(\"PROC\") #this is the .alias lit() segment in SQL\n",
        "  cur_proc[\"SOURCE\"] = cur_proc_AddedList\n",
        "  cur_proc = cur_proc.rename(columns = {\"HADM_ID\" : \"ID\", \"STARTTIME\" : \"TIME_OBS\"})\n",
        "\n",
        "  ret_df = None\n",
        "  for cur_df in [cur_med,cur_cpt,cur_proc]:\n",
        "    #double check this if statement to ensure same purpose\n",
        "    if(not cur_df.empty):\n",
        "      if ret_df is not None:\n",
        "        ret_df = pd.concat([ret_df, cur_df])\n",
        "      else:\n",
        "        ret_df = cur_df\n",
        "  return ret_df.drop_duplicates()\n",
        "      \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7k01YDp1hmA"
      },
      "source": [
        "#x = get_action_df()\n",
        "#x.head()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbMtO1ak4-LB"
      },
      "source": [
        "def get_terminal_df():\n",
        "  cur_df = pd.read_csv(\"physionet.org/files/mimiciii/1.4/DIAGNOSES_ICD.csv.gz\", usecols = [\"HADM_ID\", \"ICD9_CODE\"])\n",
        "  ret_df = cur_df.rename(columns = {\"HADM_ID\" : \"ID\"})\n",
        "  return ret_df"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF4pCkuH1kFi"
      },
      "source": [
        "#y = get_terminal_df()\n",
        "#y.head()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLujyfsG6A8x"
      },
      "source": [
        "def get_hospital_death():  \n",
        "  ret_df = pd.read_csv(\"physionet.org/files/mimiciii/1.4/ADMISSIONS.csv.gz\", usecols = [\"HADM_ID\", \"HOSPITAL_EXPIRE_FLAG\"])\n",
        "  ret_df = ret_df.rename(columns = {\"HADM_ID\" : \"ID\", \"HOSPITAL_EXPIRE_FLAG\" : \"IS_DEAD\"})\n",
        "  return ret_df"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9abV3Ao6toN"
      },
      "source": [
        "#z = get_hospital_death()\n",
        "#z.head()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDqgF1RE6vTs"
      },
      "source": [
        "def get_action_itemids():\n",
        "  cur_target_action_cpt_rdd = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/physionet.org/files/mimiciii/1.4/CPTEVENTS.csv.gz\") \\\n",
        "            .where(col(\"CHARTDATE\").isNotNull()).where(\"SECTIONHEADER <> 'Evaluation and management'\")\\\n",
        "            .select(\"CPT_CD\").rdd.flatMap(list).map(lambda x: {\"SOURCE\":\"CPT\",\"ITEMID\":x})\n",
        "\n",
        "  cur_target_action_med_rdd = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/physionet.org/files/mimiciii/1.4/D_ITEMS.csv.gz\")\\\n",
        "            .where(\"DBSOURCE == 'metavision' and LINKSTO = 'inputevents_mv'\")\\\n",
        "            .where(col(\"CATEGORY\").isin([\"Dialysis\", \"2-Ventilation\", \"Blood Products/Colloids\", \"4-Procedures\"\n",
        "                                                        , \"1-Intubation/Extubation\",\"3-Significant Events\", \"Medications\"]))\\\n",
        "            .select(\"ITEMID\").rdd.flatMap(list).map(lambda x:{\"SOURCE\":\"MED\",\"ITEMID\":x})\n",
        "\n",
        "  cur_target_action_proc_rdd = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/physionet.org/files/mimiciii/1.4/D_ITEMS.csv.gz\")\\\n",
        "            .where(\"DBSOURCE == 'metavision' and LINKSTO = 'procedureevents_mv'\")\\\n",
        "            .where(col(\"CATEGORY\").isin([\"Dialysis\", \"2-Ventilation\", \"Blood Products/Colloids\", \"4-Procedures\"\n",
        "                                                        , \"1-Intubation/Extubation\",\"3-Significant Events\", \"Medications\"]))\\\n",
        "            .select(\"ITEMID\").rdd.flatMap(list).map(lambda x:{\"SOURCE\":\"PROC\",\"ITEMID\":x})\n",
        "\n",
        "  ret_df = spark.sparkContext.union([cur_target_action_cpt_rdd,cur_target_action_med_rdd,cur_target_action_proc_rdd]).\\\n",
        "            toDF().distinct()\n",
        "  return ret_df"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS4TUIsAp8wk"
      },
      "source": [
        "#x = get_action_itemids()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T07TK23rQHk"
      },
      "source": [
        "#pandasDF = x.toPandas()\n",
        "#print(pandasDF)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jc59jsquht6"
      },
      "source": [
        "#DBG methods were coppied and pasted; irrelevant for this purpose    \n",
        "def get_target_ids_list_DBG(self):\n",
        "  return self.cur_target_id\n",
        "\n",
        "def get_obs_df_DBG(self,target_id):\n",
        "  if type(self) == data_abstracter:\n",
        "      raise NotImplementedError(\"Method need to be called in sub-class but currently called in base class\")\n",
        "\n",
        "  '''\n",
        "  :param target_id: target ID used for debug run\n",
        "  :return:\n",
        "  '''\n",
        "  import pyspark\n",
        "  #maybe this can be moved to main method?\n",
        "  try:\n",
        "      return self.spark.read.parquet(self.cached_obs_df+self.dbg_post_fix)\n",
        "  except pyspark.sql.utils.AnalysisException as ex:\n",
        "      template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
        "      message = template.format(type(ex).__name__, ex.args)\n",
        "      self.logger.info(message)\n",
        "      self.logger.info(\"PROCESS\")\n",
        "  from pyspark.sql.functions import col\n",
        "  cur_df = self.get_obs_df()\n",
        "  cur_df.where(col(\"ID\").isin(target_id)).write.save(self.cached_obs_df+self.dbg_post_fix)\n",
        "  return self.spark.read.parquet(self.cached_obs_df+self.dbg_post_fix)\n",
        "\n",
        "def get_action_df_DBG(self,target_id):\n",
        "  if type(self) == data_abstracter:\n",
        "      raise NotImplementedError(\"Method need to be called in sub-class but currently called in base class\")\n",
        "\n",
        "  '''\n",
        "  :param target_id:target ID used for debug run\n",
        "  :return:\n",
        "  '''\n",
        "  import pyspark\n",
        "\n",
        "  try:\n",
        "      return self.spark.read.parquet(self.cached_action_df+self.dbg_post_fix)\n",
        "  except pyspark.sql.utils.AnalysisException as ex:\n",
        "      template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
        "      message = template.format(type(ex).__name__, ex.args)\n",
        "      self.logger.info(message)\n",
        "      self.logger.info(\"PROCESS\")\n",
        "  from pyspark.sql.functions import col\n",
        "  cur_df = self.get_action_df()\n",
        "  cur_df.where(col(\"ID\").isin(target_id)).write.save(self.cached_action_df+self.dbg_post_fix)\n",
        "  return self.spark.read.parquet(self.cached_action_df+self.dbg_post_fix)\n",
        "\n",
        "def get_terminal_df_DBG(self,target_id):\n",
        "  if type(self) == data_abstracter:\n",
        "      raise NotImplementedError(\"Method need to be called in sub-class but currently called in base class\")\n",
        "\n",
        "  '''\n",
        "  :param target_id:target ID used for debug run\n",
        "  :return:\n",
        "  '''\n",
        "  import pyspark\n",
        "  try:\n",
        "      return self.spark.read.parquet(self.cached_terminal_df+self.dbg_post_fix)\n",
        "  except pyspark.sql.utils.AnalysisException as ex:\n",
        "      template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
        "      message = template.format(type(ex).__name__, ex.args)\n",
        "      self.logger.info(message)\n",
        "      self.logger.info(\"PROCESS\")\n",
        "  from pyspark.sql.functions import col\n",
        "  cur_df = self.get_terminal_df()\n",
        "  cur_df.where(col(\"ID\").isin(target_id)).write.save(self.cached_terminal_df+self.dbg_post_fix)\n",
        "  return self.spark.read.parquet(self.cached_terminal_df+self.dbg_post_fix)\n",
        "\n",
        "def get_target_ids_list():\n",
        "  from pyspark.context import SparkContext\n",
        "  from pyspark.sql.session import SparkSession\n",
        "  sc = SparkContext.getOrCreate();\n",
        "  spark = SparkSession(sc)\n",
        "  obs_df = get_obs_df()\n",
        "  obs_df.VALUE = obs_df.VALUE.astype(str)\n",
        "  cur_target_id_list = spark.createDataFrame(obs_df)\n",
        "  cur_target_id_list = cur_target_id_list.select(\"ID\").distinct().rdd.flatMap(list).collect()\n",
        "  return cur_target_id_list"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIgLagVyu4Mp"
      },
      "source": [
        "def get_target_test_id(tr_te_prop = 0.1):\n",
        "\n",
        "        import json\n",
        "        cur_list = get_target_ids_list()\n",
        "        from random import shuffle\n",
        "        shuffle(cur_list)\n",
        "        target_test_id_list = cur_list[:int(len(cur_list)*tr_te_prop)]\n",
        "        return target_test_id_list\n",
        "\n",
        "def get_target_tr_val_id(tr_val_prop = 0.2):\n",
        "        import json\n",
        "        cur_all_ids = get_target_ids_list()\n",
        "        cur_test_list = get_target_test_id()\n",
        "        from random import shuffle\n",
        "        cur_tr_ids = list(set(cur_all_ids).difference(set(cur_test_list)))\n",
        "        shuffle(cur_tr_ids)\n",
        "        target_val_ids = cur_tr_ids[:int(len(cur_tr_ids)*tr_val_prop)]\n",
        "        target_train_ids = cur_tr_ids[int(len(cur_tr_ids)*tr_val_prop):]\n",
        "        return {\"TR\":target_train_ids, \"VAL\":target_val_ids}\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HZoHXkUYNtm"
      },
      "source": [
        "def mimic_preprocess_init():\n",
        "  #data_preprocesser_init() -> does nothing\n",
        "  return mimic_data_abstracter_init()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53YpmA88YqcC"
      },
      "source": [
        "def data_abstracter_init():\n",
        "  import pyspark\n",
        "  from pyspark.sql.session import SparkSession\n",
        "  from pyspark import SparkConf\n",
        "  def_df = get_def_df()\n",
        "  obs_df = get_obs_df()\n",
        "\n",
        "  from pyspark.sql.functions import col\n",
        "  cur_target_id = get_target_ids_list()\n",
        "  obs_df = obs_df[obs_df[\"ID\"].isin(cur_target_id)]\n",
        "  action_df = get_action_df()\n",
        "  action_df = action_df[action_df[\"ID\"].isin(cur_target_id)]\n",
        "  terminal_df = get_terminal_df()\n",
        "  terminal_df = terminal_df[terminal_df[\"ID\"].isin(cur_target_id)]\n",
        "\n",
        "  return cur_target_id, obs_df, action_df, terminal_df, def_df"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4zIa4pWYyUI"
      },
      "source": [
        "def mimic_data_abstracter_init():\n",
        "  return data_abstracter_init()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDo_QWAnZIP0",
        "outputId": "4b79af5c-8d4e-476c-b752-7333eb26997f"
      },
      "source": [
        "#main run\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql.session import SparkSession\n",
        "import pyspark\n",
        "cur_target_id, obs_df, action_df, terminal_df, def_df = mimic_preprocess_init()\n",
        "#data_run_experiment_init() -> does nothing"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "37878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 330712483 entries, 0 to 330712482\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   ID        int32 \n",
            " 1   ITEMID    int32 \n",
            " 2   TIME_OBS  object\n",
            " 3   VALUE     object\n",
            " 4   SOURCE    object\n",
            "dtypes: int32(2), object(3)\n",
            "memory usage: 9.9+ GB\n",
            "None\n",
            "Index              128\n",
            "ID          1322849932\n",
            "ITEMID      1322849932\n",
            "TIME_OBS    2645699864\n",
            "VALUE       2645699864\n",
            "SOURCE      2645699864\n",
            "dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27854055 entries, 0 to 27854054\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype  \n",
            "---  ------    -----  \n",
            " 0   ID        float64\n",
            " 1   ITEMID    int64  \n",
            " 2   TIME_OBS  object \n",
            " 3   VALUE     object \n",
            " 4   SOURCE    object \n",
            "dtypes: float64(1), int64(1), object(3)\n",
            "memory usage: 1.0+ GB\n",
            "None\n",
            "Index             128\n",
            "ID          222832440\n",
            "ITEMID      222832440\n",
            "TIME_OBS    222832440\n",
            "VALUE       222832440\n",
            "SOURCE      222832440\n",
            "dtype: int64\n",
            "check!!!\n",
            "(0, 1)\n",
            "         ID  ITEMID            TIME_OBS VALUE SOURCE    DBSOURCE DNR_TIME\n",
            "0  165660.0  223834 2134-05-12 12:00:00    15  VITAL  metavision      NaT\n",
            "1  165660.0  223835 2134-05-12 12:00:00   100  VITAL  metavision      NaT\n",
            "2  165660.0  224328 2134-05-12 12:00:00  0.37  VITAL  metavision      NaT\n",
            "3  165660.0  224329 2134-05-12 12:00:00     6  VITAL  metavision      NaT\n",
            "4  165660.0  224330 2134-05-12 12:00:00   2.5  VITAL  metavision      NaT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 330712483 entries, 0 to 330712482\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   ID        int32 \n",
            " 1   ITEMID    int32 \n",
            " 2   TIME_OBS  object\n",
            " 3   VALUE     object\n",
            " 4   SOURCE    object\n",
            "dtypes: int32(2), object(3)\n",
            "memory usage: 9.9+ GB\n",
            "None\n",
            "Index              128\n",
            "ID          1322849932\n",
            "ITEMID      1322849932\n",
            "TIME_OBS    2645699864\n",
            "VALUE       2645699864\n",
            "SOURCE      2645699864\n",
            "dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27854055 entries, 0 to 27854054\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype  \n",
            "---  ------    -----  \n",
            " 0   ID        float64\n",
            " 1   ITEMID    int64  \n",
            " 2   TIME_OBS  object \n",
            " 3   VALUE     object \n",
            " 4   SOURCE    object \n",
            "dtypes: float64(1), int64(1), object(3)\n",
            "memory usage: 1.0+ GB\n",
            "None\n",
            "Index             128\n",
            "ID          222832440\n",
            "ITEMID      222832440\n",
            "TIME_OBS    222832440\n",
            "VALUE       222832440\n",
            "SOURCE      222832440\n",
            "dtype: int64\n",
            "check!!!\n",
            "(0, 1)\n",
            "         ID  ITEMID            TIME_OBS VALUE SOURCE    DBSOURCE DNR_TIME\n",
            "0  165660.0  223834 2134-05-12 12:00:00    15  VITAL  metavision      NaT\n",
            "1  165660.0  223835 2134-05-12 12:00:00   100  VITAL  metavision      NaT\n",
            "2  165660.0  224328 2134-05-12 12:00:00  0.37  VITAL  metavision      NaT\n",
            "3  165660.0  224329 2134-05-12 12:00:00     6  VITAL  metavision      NaT\n",
            "4  165660.0  224330 2134-05-12 12:00:00   2.5  VITAL  metavision      NaT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DtypeWarning: Columns (4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIoSuFDZ5Od"
      },
      "source": [
        "def run_preprocessor(obs_df = obs_df):\n",
        "  from pyspark.context import SparkContext\n",
        "  from pyspark.sql.session import SparkSession\n",
        "  from pyspark.sql.functions import col,split,struct, date_add\n",
        "  sc = SparkContext.getOrCreate();\n",
        "  spark = SparkSession(sc)\n",
        "  obs_df.VALUE = obs_df.VALUE.astype(str)\n",
        "  obs_df = spark.createDataFrame(obs_df)\n",
        "  cur_obs_bf_dropna = obs_df.select(\"ID\", \"ITEMID\", \"VALUE\", \"TIME_OBS\",\n",
        "                                          split(\"TIME_OBS\", \"\\ \").getItem(0).alias(\"DATE_OBS\")) \\\n",
        "            .withColumn(\"TIME_SPAN\", struct(col(\"DATE_OBS\").cast(\"timestamp\").alias(\"TIME_FROM\") \\\n",
        "                                            , date_add(\"DATE_OBS\", 1).cast(\"timestamp\").alias(\"TIME_TO\")))\n",
        "\n",
        "\n",
        "  cur_obs = cur_obs_bf_dropna.dropna()\n",
        "  return run_remaining(cur_obs)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2Vtvy-MipYU"
      },
      "source": [
        "def run_remaining(cur_obs):\n",
        "  from pyspark.sql.functions import count,col\n",
        "  cur_obs.groupBy(\"ITEMID\").agg(count(\"*\").alias(\"cnt\")).orderBy(col(\"cnt\").desc()).show(300)\n",
        "  num_cat_tagged = num_cat_tagger(cur_obs)\n",
        "  cat_raw_filtered, cat_voca_list = cat_frequency_filter(num_cat_tagged.where(\"IS_CAT == 1\"))\n",
        "  num_raw_filtered, num_ref_list = num_iqr_filter(num_cat_tagged.where(\"IS_CAT == 0\"))\n",
        "  num_instance = count_instance(cat_raw_filtered, num_raw_filtered)\n",
        "  for cur_th in th_range:\n",
        "    REPARTITION_CONST = 200\n",
        "    cat_filtered = availability_filter(cat_raw_filtered, num_instance, availability_th=cur_th,\n",
        "                                        REPARTITION_CONST=REPARTITION_CONST)\n",
        "\n",
        "    num_filtered = availability_filter(num_raw_filtered, num_instance, availability_th=cur_th,\n",
        "                                        REPARTITION_CONST=REPARTITION_CONST)\n",
        "\n",
        "\n",
        "    cat_featurized = cat_featurizer(cat_filtered, voca_df=cat_voca_list\\\n",
        "                                                          , REPARTITION_CONST=REPARTITION_CONST)\n",
        "\n",
        "\n",
        "    num_featurized = num_featurizer(num_filtered, ref_df=num_ref_list\\\n",
        "                                                          , REPARTITION_CONST=REPARTITION_CONST)\n",
        "\n",
        "    merged_all = feature_aggregator(num_featurized, cat_featurized\\\n",
        "                                                          , REPARTITION_CONST=REPARTITION_CONST)\n",
        "    target_rdd, target_schema, feature_column = flattener_df_prep(merged_all)\n",
        "    cur_df = spark.createDataFrame(target_rdd, target_schema).persist()\n",
        "\n",
        "  return cur_df\n",
        "  "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-DF7CUOwqry"
      },
      "source": [
        "#helper methods for run_remaining\n",
        "from pyspark.sql.functions import col,when,lit\n",
        "def num_cat_tagger(data_frame, inputCol=\"VALUE\", outputCol=\"IS_CAT\",labelCol=\"ITEMID\",REPARTITION_CONST = None,nominal_th = 2):\n",
        "        #DL0411: Output should be list of features with corresponding num/cat instances\n",
        "        from pyspark.sql.functions import size,collect_set\n",
        "        if REPARTITION_CONST is None:\n",
        "            get_nominal_var = data_frame.repartition(labelCol).groupBy(labelCol).agg(size(collect_set(inputCol)).alias(\"value_cnt\"))\\\n",
        "                         .where(\"value_cnt<={0}\".format(nominal_th)).select(labelCol).rdd.flatMap(list).collect()\n",
        "        else:\n",
        "            get_nominal_var = data_frame.repartition(REPARTITION_CONST).groupBy(labelCol).agg(size(collect_set(inputCol)).alias(\"value_cnt\"))\\\n",
        "                         .where(\"value_cnt<={0}\".format(nominal_th)).select(labelCol).rdd.flatMap(list).collect()\n",
        "        data_frame.show()\n",
        "\n",
        "        if REPARTITION_CONST is None:\n",
        "            ret_data_frame = data_frame.withColumn(outputCol,\n",
        "                when((col(inputCol).rlike('^(?!-0?(\\.0+)?(E|$))-?(0|[1-9]\\d*)?(\\.\\d+)?(?<=\\d)(E-?(0|[1-9]\\d*))?$'))&\n",
        "                     (~col(labelCol).isin(get_nominal_var)),lit(\"0\"))\\\n",
        "                .otherwise(lit(\"1\")))\n",
        "        else:\n",
        "            ret_data_frame = data_frame.withColumn(outputCol,\n",
        "                when((col(inputCol).rlike('^(?!-0?(\\.0+)?(E|$))-?(0|[1-9]\\d*)?(\\.\\d+)?(?<=\\d)(E-?(0|[1-9]\\d*))?$'))&\n",
        "                     (~col(labelCol).isin(get_nominal_var)),lit(\"0\"))\\\n",
        "                .otherwise(lit(\"1\"))).repartition(REPARTITION_CONST)\n",
        "        return ret_data_frame\n",
        "\n",
        "def cat_frequency_filter(data_frame,threshold_lb = 0,threshold_ub = 1,inputCol=\"VALUE\",labelCol=\"ITEMID\",REPARTITION_CONST=None):\n",
        "        from pyspark.sql.functions import count,monotonically_increasing_id\n",
        "        label_count = data_frame.groupBy(labelCol).agg(count(\"*\").alias(\"label_count\"))\n",
        "        if REPARTITION_CONST is not None:\n",
        "            label_count = label_count.repartition(REPARTITION_CONST).persist()\n",
        "        if REPARTITION_CONST is None:\n",
        "            cur_freq = data_frame.groupBy(labelCol,inputCol).agg(count(\"*\").alias(\"indiv_count\")).join(label_count,labelCol)\\\n",
        "                                .withColumn(\"cat_freq\",col(\"indiv_count\")/col(\"label_count\"))\n",
        "        else:\n",
        "            cur_freq = data_frame.groupBy(labelCol,inputCol).agg(count(\"*\").alias(\"indiv_count\")).repartition(REPARTITION_CONST).join(label_count,labelCol)\\\n",
        "                                .withColumn(\"cat_freq\",col(\"indiv_count\")/col(\"label_count\")).repartition(REPARTITION_CONST)\n",
        "        cur_freq = cur_freq.where((col(\"cat_freq\")>=threshold_lb) & (col(\"cat_freq\")<=threshold_ub)).drop(\"cat_freq\")\n",
        "        #cur_freq.orderBy(col(labelCol),-1*col(\"cat_freq\")).show(500)\n",
        "\n",
        "        ret_data_frame = data_frame.join(cur_freq,[inputCol,labelCol]).drop(\"indiv_count\").drop(\"label_count\")\n",
        "\n",
        "        if REPARTITION_CONST is not None:\n",
        "            ret_data_frame = ret_data_frame.repartition(REPARTITION_CONST)\n",
        "        ret_voca = ret_data_frame.select(\"ITEMID\",\"VALUE\").distinct()\n",
        "        ret_voca = ret_voca.rdd.map(lambda x: (x.ITEMID,x.VALUE)).zipWithUniqueId().map(lambda x: {\"idx\":x[1], \"ITEMID\":x[0][0], \"VALUE\":x[0][1]}).toDF()\n",
        "        if REPARTITION_CONST is not None:\n",
        "            ret_voca = ret_voca.repartition(REPARTITION_CONST)\n",
        "\n",
        "        return (ret_data_frame, ret_voca)\n",
        "\n",
        "def num_iqr_filter(data_frame, inputCol=\"VALUE\",labelCol=\"ITEMID\",REPARTITION_CONST = None,sc=None):\n",
        "        from pyspark.sql.window import Window\n",
        "        from pyspark.sql.functions import abs,percent_rank,row_number,collect_list,udf,struct,count,avg,stddev_pop\n",
        "        from pyspark.sql.types import MapType,StringType,DoubleType\n",
        "        if REPARTITION_CONST is None:\n",
        "            value_order = Window.partitionBy(labelCol).orderBy(col(inputCol).cast(\"float\"))\n",
        "            Q1_percentile = Window.partitionBy(labelCol).orderBy(abs(0.25-col(\"percentile\")))\n",
        "            Q2_percentile = Window.partitionBy(labelCol).orderBy(abs(0.5-col(\"percentile\")))\n",
        "            Q3_percentile = Window.partitionBy(labelCol).orderBy(abs(0.75-col(\"percentile\")))\n",
        "            percent_data_frame = data_frame.select(labelCol, inputCol, percent_rank().over(value_order).alias(\"percentile\"))\n",
        "            Q1_data_frame = percent_data_frame.withColumn(\"Q1_rn\",row_number().over(Q1_percentile)).where(\"Q1_rn == 1\")\\\n",
        "                            .select(labelCol,inputCol,lit(\"Q1\").alias(\"quantile\"))\n",
        "            Q2_data_frame = percent_data_frame.withColumn(\"Q2_rn\",row_number().over(Q2_percentile)).where(\"Q2_rn == 1\")\\\n",
        "                            .select(labelCol,inputCol,lit(\"Q2\").alias(\"quantile\"))\n",
        "            Q3_data_frame = percent_data_frame.withColumn(\"Q3_rn\",row_number().over(Q3_percentile)).where(\"Q3_rn == 1\")\\\n",
        "                            .select(labelCol,inputCol,lit(\"Q3\").alias(\"quantile\"))\n",
        "            merge_all = Q1_data_frame.unionAll(Q2_data_frame).unionAll(Q3_data_frame).persist()\n",
        "\n",
        "\n",
        "            udf_parse_list_to_map = udf(lambda maps: dict(list(tuple(x) for x in maps)),MapType(StringType(),StringType()))\n",
        "\n",
        "            aggregate_quantiles = merge_all.groupBy(labelCol).agg(collect_list(struct(\"quantile\",inputCol)).alias(\"quant_info\"))\n",
        "\n",
        "            aggregate_quantiles = aggregate_quantiles.select(labelCol,udf_parse_list_to_map(\"quant_info\").alias(\"quant_info\"))\n",
        "\n",
        "            iqr_data_frame = aggregate_quantiles.withColumn(\"Q1\",col(\"quant_info\").getItem(\"Q1\").cast(\"float\"))\\\n",
        "                .withColumn(\"Q2\",col(\"quant_info\").getItem(\"Q2\").cast(\"float\"))\\\n",
        "                .withColumn(\"Q3\",col(\"quant_info\").getItem(\"Q3\").cast(\"float\"))\n",
        "\n",
        "        else:\n",
        "            cur_label_list = data_frame.select(labelCol).distinct().rdd.flatMap(list).collect()\n",
        "            cur_iqr_list = list()\n",
        "            cnt = -1\n",
        "            for cur_item in cur_label_list:\n",
        "                cnt = cnt+1\n",
        "                data_frame.where(col(labelCol) == cur_item).registerTempTable(\"cur_table\")\n",
        "                cur_iqr = sc.sql(\"select {0}, percentile_approx({1},0.25) as Q1, percentile_approx({2},0.5) as Q2, percentile_approx({3},0.75) as Q3 from cur_table group by {4}\".format(labelCol,inputCol,inputCol,inputCol,labelCol)).first().asDict()\n",
        "                cur_iqr_list.append(cur_iqr)\n",
        "                sc.catalog.dropTempView(\"cur_table\")\n",
        "                #percent_data_frame = data_frame.select(labelCol, inputCol, percent_rank().over(value_order).alias(\"percentile\")).repartition(REPARTITION_CONST).cache().checkpoint()\n",
        "            iqr_data_frame = sc.createDataFrame(cur_iqr_list).repartition(REPARTITION_CONST)\n",
        "\n",
        "\n",
        "        if REPARTITION_CONST is None:\n",
        "            iqr_data_frame = iqr_data_frame.withColumn(\"IQR\",col(\"Q3\")-col(\"Q1\"))\\\n",
        "                                       .withColumn(\"LB\",col(\"Q1\")-1.5*col(\"IQR\"))\\\n",
        "                                       .withColumn(\"UB\",col(\"Q3\")+1.5*col(\"IQR\"))\\\n",
        "                                       .select(labelCol,\"LB\",\"UB\")\n",
        "        else:\n",
        "            iqr_data_frame = iqr_data_frame.withColumn(\"IQR\",col(\"Q3\")-col(\"Q1\"))\\\n",
        "                                       .withColumn(\"LB\",col(\"Q1\")-1.5*col(\"IQR\"))\\\n",
        "                                       .withColumn(\"UB\",col(\"Q3\")+1.5*col(\"IQR\"))\\\n",
        "                                       .select(labelCol,\"LB\",\"UB\").repartition(REPARTITION_CONST).persist()\n",
        "        if REPARTITION_CONST is None:\n",
        "\n",
        "            ret_data_frame = data_frame.repartition(labelCol).join(iqr_data_frame,labelCol).where((col(\"LB\").cast(\"float\") <= col(inputCol).cast(\"float\")) & (col(\"UB\").cast(\"float\")>=col(inputCol).cast(\"float\")))\\\n",
        "                                                                 .drop(\"LB\").drop(\"UB\").persist()\n",
        "            ref_df = ret_data_frame.repartition(labelCol).groupBy(labelCol)\\\n",
        "                               .agg(count(inputCol).alias(\"ref_count\"),avg(inputCol).alias(\"ref_avg\"),stddev_pop(inputCol).alias(\"ref_std\")).persist()\n",
        "\n",
        "            return (ret_data_frame, ref_df)\n",
        "        else:\n",
        "              ret_data_frame = data_frame.join(iqr_data_frame,labelCol).where((col(\"LB\").cast(\"float\") <= col(inputCol).cast(\"float\")) & (col(\"UB\").cast(\"float\")>=col(inputCol).cast(\"float\")))\\\n",
        "                                                                  .drop(\"LB\").drop(\"UB\").repartition(REPARTITION_CONST)\n",
        "              ref_df = ret_data_frame.groupBy(labelCol)\\\n",
        "                                .agg(count(inputCol).alias(\"ref_count\"),avg(inputCol).alias(\"ref_avg\"),stddev_pop(inputCol).alias(\"ref_std\")).repartition(REPARTITION_CONST)\n",
        "\n",
        "              return (ret_data_frame, ref_df)\n",
        "\n",
        "def count_instance(raw_feature1, raw_feature2 = None):\n",
        "        from pyspark.sql.functions import collect_set,size\n",
        "        raw1_distinct_instance = raw_feature1\\\n",
        "            .select(\"ID\",\"TIME_SPAN\").withColumn(\"T1\",col(\"TIME_SPAN\").TIME_FROM.cast(\"timestamp\"))\\\n",
        "            .withColumn(\"T2\",col(\"TIME_SPAN\").TIME_TO.cast(\"timestamp\")).select(\"ID\",\"T1\",\"T2\")\n",
        "        if raw_feature2 is not None:\n",
        "            raw2_distinct_instance = raw_feature2\\\n",
        "                .select(\"ID\",\"TIME_SPAN\").withColumn(\"T1\",col(\"TIME_SPAN\").TIME_FROM.cast(\"timestamp\"))\\\n",
        "                .withColumn(\"T2\",col(\"TIME_SPAN\").TIME_TO.cast(\"timestamp\")).select(\"ID\",\"T1\",\"T2\")\n",
        "        else:\n",
        "            raw2_distinct_instance = None\n",
        "        if raw2_distinct_instance is not None:\n",
        "            all_inst = raw1_distinct_instance.unionAll(raw2_distinct_instance)\n",
        "        else:\n",
        "            all_inst = raw1_distinct_instance\n",
        "\n",
        "        return all_inst.distinct().groupBy(\"ID\").agg(collect_set(\"T1\").alias(\"collected_set\")).select(\"ID\",size(\"collected_set\").alias(\"list_size\")).rdd.map(lambda x: x.list_size).reduce(lambda a,b:a+b)\n",
        "\n",
        "def availability_filter(data_frame,n_inst = None, availability_th = 0.80,labelCol=\"ITEMID\",idCol=\"ID\",timeCol=\"TIME_SPAN\",REPARTITION_CONST=None):\n",
        "        from pyspark.sql.functions import count\n",
        "        if not n_inst:\n",
        "            total_cnt = data_frame.select(idCol,timeCol).distinct().count()\n",
        "\n",
        "        else:\n",
        "            total_cnt = n_inst\n",
        "        target_label_set = data_frame.select(idCol,timeCol,labelCol).distinct()\n",
        "\n",
        "        if REPARTITION_CONST is None:\n",
        "            target_label_set = target_label_set.groupBy(labelCol).agg((count(\"*\")/float(total_cnt)).alias(\"freq\"))\n",
        "        else:\n",
        "            target_label_set = target_label_set.repartition(REPARTITION_CONST)\\\n",
        "                .groupBy(labelCol).agg((count(\"*\")/float(total_cnt)).alias(\"freq\"))\n",
        "\n",
        "        target_label_set.orderBy(col(\"freq\").desc()).show()\n",
        "\n",
        "        if REPARTITION_CONST is not None:\n",
        "            target_label_set = target_label_set.repartition(REPARTITION_CONST)\n",
        "        target_label_set = target_label_set.where(col(\"freq\")>=availability_th).select(labelCol).rdd.flatMap(list).collect()\n",
        "        if len(target_label_set) == 0:\n",
        "            return\n",
        "        ret_data_frame = data_frame.where(col(labelCol).isin(target_label_set))\n",
        "\n",
        "        return ret_data_frame\n",
        "\n",
        "def cat_featurizer(data_frame, voca_df, inputCol=\"VALUE\",labelCol=\"ITEMID\",outputCol=\"cat_features\",REPARTITION_CONST = None):\n",
        "        def prep_cat_dict(avail, pos):  # internal\n",
        "            ret_dict_key = list(map(lambda x: \"C_\" + str(x), avail))\n",
        "            ret_dict = dict(zip(ret_dict_key, [0.0] * len(ret_dict_key)))\n",
        "            pos_dict_key = list(map(lambda x: \"C_\" + str(x), pos))\n",
        "            update_dict = dict(zip(pos_dict_key, [1.0] * len(pos_dict_key)))\n",
        "            ret_dict.update(update_dict)\n",
        "            return ret_dict\n",
        "\n",
        "        from pyspark.sql.functions import udf,collect_set\n",
        "        from pyspark.sql.types import MapType, StringType, DoubleType\n",
        "        if not data_frame:\n",
        "            return\n",
        "\n",
        "        all_var = voca_df.groupBy(labelCol).agg(collect_set(\"idx\").alias(\"AVAIL_LIST\"))\n",
        "        ret_data_frame = data_frame.join(voca_df,[inputCol,labelCol]).drop(\"VALUE\").withColumnRenamed(\"idx\",\"VALUE\")\n",
        "        if REPARTITION_CONST is not None:\n",
        "            ret_data_frame = ret_data_frame.repartition(REPARTITION_CONST)\n",
        "        ret_data_frame = value_aggregator(ret_data_frame).join(all_var,\"ITEMID\")\n",
        "\n",
        "        udf_prep_cat_dict = udf(prep_cat_dict, MapType(StringType(),DoubleType()))\n",
        "        ret_data_frame = ret_data_frame.withColumn(\"cat_features\",udf_prep_cat_dict(\"AVAIL_LIST\",\"VALUE_LIST\"))\n",
        "        return ret_data_frame\n",
        "\n",
        "def value_aggregator(data_frame, aggregateCols = [\"ID\",\"TIME_SPAN\",\"ITEMID\"], catmarkerCol=\"IS_CAT\", inputCol = \"VALUE\", outputCol=\"VALUE_LIST\"):\n",
        "        from pyspark.sql.functions import collect_set, collect_list\n",
        "        cat_data_agg_frame = data_frame.where(col(catmarkerCol) == 1).groupBy(aggregateCols+[catmarkerCol])\\\n",
        "                                                                     .agg(collect_set(inputCol).alias(outputCol))\n",
        "        num_data_agg_frame = data_frame.where(col(catmarkerCol) == 0).groupBy(aggregateCols+[catmarkerCol])\\\n",
        "                                                                     .agg(collect_list(inputCol).alias(outputCol))\n",
        "        return cat_data_agg_frame.unionAll(num_data_agg_frame)\n",
        "\n",
        "def num_featurizer(data_frame, ref_df=None, featurize_process = [\"summary_stat\",\"sustainment_q\"], inputCol=\"VALUE\",labelCol=\"ITEMID\",outputCol=\"num_features\",REPARTITION_CONST=None):\n",
        "        from pyspark.sql.functions import udf,array\n",
        "        from pyspark.sql.types import StringType, DoubleType, MapType\n",
        "        if not data_frame:\n",
        "            return\n",
        "        ret_data_frame = value_aggregator(data_frame)\n",
        "        if REPARTITION_CONST is not None:\n",
        "            ret_data_frame = ret_data_frame\n",
        "        if \"summary_stat\" in featurize_process:\n",
        "            udf_summary_stat = udf(calc_summary_stat,MapType(StringType(),DoubleType()))\n",
        "            ret_data_frame = ret_data_frame.withColumn(\"summary_stat\",udf_summary_stat(inputCol+\"_LIST\",labelCol))\n",
        "            if REPARTITION_CONST is not None:\n",
        "                ret_data_frame = ret_data_frame\n",
        "\n",
        "        if \"sustainment_q\" in featurize_process:\n",
        "            udf_sustainment_quant = udf(sustainment_quantifier,MapType(StringType(),DoubleType()))\n",
        "            ret_data_frame = ret_data_frame.join(ref_df,labelCol).withColumn(\"sustainment_q\",udf_sustainment_quant(\"summary_stat\",labelCol,\"ref_avg\",\"ref_std\",\"ref_count\")).drop(\"ref_avg\").drop(\"ref_std\").drop(\"ref_count\")\n",
        "            if REPARTITION_CONST is not None:\n",
        "                ret_data_frame = ret_data_frame\n",
        "        udf_merge_dict_all = udf(merge_dict_all,MapType(StringType(),DoubleType()))\n",
        "        ret_data_frame = ret_data_frame.withColumn(outputCol,udf_merge_dict_all(array(featurize_process)))\n",
        "        return ret_data_frame\n",
        "\n",
        "def calc_summary_stat(x,labelCol):\n",
        "        import numpy as np\n",
        "        cur_array = np.array(x,dtype=float)\n",
        "        ret_dict = dict()\n",
        "        ret_dict[\"N_{0}_avg\".format(labelCol)] = float(np.average(cur_array))\n",
        "        ret_dict[\"N_{0}_min\".format(labelCol)] = float(np.min(cur_array))\n",
        "        ret_dict[\"N_{0}_max\".format(labelCol)] = float(np.max(cur_array))\n",
        "        ret_dict[\"N_{0}_std\".format(labelCol)] = float(np.std(cur_array))\n",
        "        ret_dict[\"N_{0}_count\".format(labelCol)] = float(np.shape(cur_array)[0])\n",
        "        return ret_dict\n",
        "\n",
        "def sustainment_quantifier(x,cur_label,ref_avg, ref_std, ref_count):\n",
        "        from scipy.stats import ttest_ind_from_stats\n",
        "        import numpy as np\n",
        "        ret_dict = dict()\n",
        "        statistic, p_val = ttest_ind_from_stats(x[\"N_{0}_avg\".format(cur_label)], x[\"N_{0}_std\".format(cur_label)], x[\"N_{0}_count\".format(cur_label)], ref_avg, ref_std, ref_count, equal_var=True)\n",
        "        if not np.isnan(statistic):\n",
        "            if statistic > 0:\n",
        "                one_tailed_pval = 1.0 - p_val/2.0\n",
        "            else:\n",
        "                one_tailed_pval = p_val/2.0\n",
        "            ret_dict[\"N_{0}_TT\".format(cur_label)] = float(p_val)\n",
        "            ret_dict[\"N_{0}_LT\".format(cur_label)] = float(one_tailed_pval)\n",
        "        return ret_dict\n",
        "\n",
        "def merge_dict_all(x): #will not be used outside of the package\n",
        "        ret_dict = dict()\n",
        "        for cur_dict in x:\n",
        "            ret_dict.update(cur_dict)\n",
        "        return ret_dict\n",
        "\n",
        "def feature_aggregator(num_features,cat_features,catinputCol=\"cat_features\",numinputCol=\"num_features\",aggregatorCol = [\"ID\",\"TIME_SPAN\"], outputCol=\"feature_aggregated\",idCol=\"ID\",REPARTITION_CONST = None):\n",
        "        from pyspark.sql.functions import col, udf, collect_list,rand\n",
        "        from pyspark.sql.types import MapType, StringType, DoubleType\n",
        "\n",
        "        if not num_features:\n",
        "            ret_data_frame=cat_features.withColumnRenamed(catinputCol,\"features\")\n",
        "\n",
        "        elif not cat_features:\n",
        "            ret_data_frame=num_features.withColumnRenamed(numinputCol,\"features\")\n",
        "\n",
        "        else:\n",
        "            ret_data_frame = num_features.select(aggregatorCol+[numinputCol]).withColumnRenamed(numinputCol,\"features\")\\\n",
        "                                     .unionAll(cat_features.select(aggregatorCol+[catinputCol]).withColumnRenamed(catinputCol,\"features\"))\n",
        "\n",
        "        if REPARTITION_CONST is not None:\n",
        "            ret_data_frame = ret_data_frame.repartition(REPARTITION_CONST)\n",
        "\n",
        "        udf_merge_dict_all = udf(merge_dict_all,MapType(StringType(),DoubleType()))\n",
        "\n",
        "        # FROM HERE\n",
        "        ret_data_frame = ret_data_frame.groupBy(aggregatorCol)\n",
        "        if REPARTITION_CONST is not None:\n",
        "            ret_data_frame = ret_data_frame.agg(collect_list(\"features\").alias(\"features\")).repartition(REPARTITION_CONST)\n",
        "\n",
        "        else:\n",
        "            ret_data_frame = ret_data_frame.agg(collect_list(\"features\").alias(\"features\"))\n",
        "        #ret_data_frame.orderBy(rand()).show(truncate=False)\n",
        "        ret_data_frame = ret_data_frame.withColumn(outputCol, udf_merge_dict_all(\"features\"))\n",
        "        return ret_data_frame\n",
        "\n",
        "def flattener_df_prep(data_frame, descCol=[\"ID\",\"TIME_SPAN\"] ,inputCol=\"feature_aggregated\",drop_cnt=True):\n",
        "        from pyspark.sql import Row\n",
        "        from pyspark.sql.functions import col,udf,lit\n",
        "        from pyspark.sql.types import StructType,StructField,StringType,DoubleType,BooleanType\n",
        "        data_frame.show()\n",
        "        desc_schema = data_frame.select(descCol).schema\n",
        "        all_feature_column = list(data_frame.select(inputCol).rdd.map(lambda x: set(x[inputCol].keys())).reduce(lambda a,b: a.union(b)))\n",
        "        ret_df = data_frame.rdd.map(lambda x: x.asDict()).map(lambda cur_item: [dict((cur_col,cur_item[cur_col]) for cur_col in descCol)]\\\n",
        "                                                                                + [cur_item[inputCol]]).map(lambda x: merge_dict_all(x))\n",
        "        inst_count = data_frame.count()\n",
        "        ret_schema = desc_schema\n",
        "        ret_feature_col = list()\n",
        "        key_checker = udf(check_key_in_dict,BooleanType())\n",
        "        for cur_col in all_feature_column:\n",
        "    #        print (\"{0}//{1}//{2}\".format(data_frame.where(key_checker(inputCol,lit(cur_col))).count(),inst_count,cur_col))\n",
        "    #        if (data_frame.where(key_checker(inputCol,lit(cur_col))).count() == inst_count):\n",
        "    #            continue\n",
        "            if drop_cnt:\n",
        "                if cur_col.find(\"count\") != -1:\n",
        "                    continue\n",
        "            ret_feature_col.append(cur_col)\n",
        "            ret_schema = ret_schema.add(StructField(cur_col,DoubleType(),True))\n",
        "        return (ret_df, ret_schema,ret_feature_col)\n",
        "\n",
        "def check_key_in_dict(target_dict,target_key):\n",
        "        return target_dict.has_key(target_key)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPG1_-uWNPCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e2a5fe-a6a2-4168-9d0d-f934ebf2983b"
      },
      "source": [
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "spark = SparkSession(SparkContext.getOrCreate())\n",
        "th_range = [0.5]\n",
        "cur_preprocessed = run_preprocessor(obs_df)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|ITEMID|  cnt|\n",
            "+------+-----+\n",
            "|220045|72645|\n",
            "|220210|72133|\n",
            "|220277|70084|\n",
            "|220181|46754|\n",
            "|220179|46627|\n",
            "|220180|46584|\n",
            "|220052|20396|\n",
            "|220050|20301|\n",
            "|220051|20295|\n",
            "|223761|16193|\n",
            "|220074|11504|\n",
            "|223835| 8892|\n",
            "|225664| 7760|\n",
            "|220047| 7308|\n",
            "|220046| 7305|\n",
            "|223770| 7243|\n",
            "|223769| 7228|\n",
            "|224161| 7166|\n",
            "|224162| 7165|\n",
            "|220339| 6741|\n",
            "|223834| 6665|\n",
            "|226253| 6579|\n",
            "|224697| 6423|\n",
            "|224687| 6413|\n",
            "|220293| 6180|\n",
            "|220292| 6164|\n",
            "|224685| 6164|\n",
            "|223876| 6158|\n",
            "|223873| 6136|\n",
            "|224695| 6054|\n",
            "|223752| 5876|\n",
            "|223751| 5875|\n",
            "|223874| 5850|\n",
            "|224689| 5842|\n",
            "|223875| 5486|\n",
            "|224690| 4623|\n",
            "|227442| 4496|\n",
            "| 50971| 4476|\n",
            "|220545| 4406|\n",
            "| 51221| 4390|\n",
            "|220645| 4354|\n",
            "| 50983| 4332|\n",
            "|220602| 4328|\n",
            "| 50902| 4304|\n",
            "|220621| 4291|\n",
            "|227443| 4176|\n",
            "|225624| 4171|\n",
            "|220615| 4163|\n",
            "| 50882| 4153|\n",
            "|227073| 4150|\n",
            "| 51006| 4146|\n",
            "| 50912| 4141|\n",
            "| 50868| 4128|\n",
            "| 50931| 4082|\n",
            "|220635| 3993|\n",
            "| 50960| 3985|\n",
            "|224688| 3910|\n",
            "|224738| 3905|\n",
            "|224684| 3783|\n",
            "|223872| 3735|\n",
            "|225677| 3710|\n",
            "| 50970| 3698|\n",
            "|225625| 3687|\n",
            "| 50893| 3658|\n",
            "|227457| 3521|\n",
            "|220228| 3510|\n",
            "| 51265| 3496|\n",
            "| 51222| 3447|\n",
            "|220546| 3432|\n",
            "| 51301| 3410|\n",
            "| 51249| 3400|\n",
            "| 51279| 3399|\n",
            "| 51250| 3399|\n",
            "| 51277| 3399|\n",
            "| 51248| 3399|\n",
            "|226871| 3392|\n",
            "|226873| 3380|\n",
            "| 50820| 3211|\n",
            "|224686| 3181|\n",
            "|224701| 2993|\n",
            "| 50802| 2938|\n",
            "| 50804| 2938|\n",
            "| 50821| 2938|\n",
            "| 50818| 2938|\n",
            "|227466| 2852|\n",
            "| 51275| 2826|\n",
            "|223830| 2736|\n",
            "|220235| 2667|\n",
            "|220224| 2667|\n",
            "|225698| 2666|\n",
            "|224828| 2666|\n",
            "|227467| 2631|\n",
            "|227465| 2631|\n",
            "| 51237| 2596|\n",
            "| 51274| 2596|\n",
            "|220060| 2369|\n",
            "|220059| 2369|\n",
            "|220061| 2348|\n",
            "|224562| 2332|\n",
            "|224696| 2256|\n",
            "|224846| 2255|\n",
            "|227566| 2128|\n",
            "|227565| 2128|\n",
            "|220056| 1991|\n",
            "|220058| 1981|\n",
            "|225312| 1975|\n",
            "|225309| 1963|\n",
            "|225310| 1962|\n",
            "|224169| 1841|\n",
            "|225668| 1699|\n",
            "| 50813| 1658|\n",
            "|226531| 1598|\n",
            "|224154| 1593|\n",
            "|224153| 1593|\n",
            "|226457| 1567|\n",
            "|225183| 1560|\n",
            "|224191| 1549|\n",
            "|224842| 1503|\n",
            "|224144| 1495|\n",
            "|224149| 1488|\n",
            "|224151| 1487|\n",
            "|224150| 1487|\n",
            "|226329| 1484|\n",
            "|224152| 1483|\n",
            "|223772| 1482|\n",
            "|225667| 1476|\n",
            "| 50808| 1448|\n",
            "|224916| 1429|\n",
            "|224951| 1410|\n",
            "|224563| 1183|\n",
            "|226537| 1156|\n",
            "|223762| 1069|\n",
            "| 50817| 1054|\n",
            "|224172| 1030|\n",
            "|224700| 1020|\n",
            "|220072|  975|\n",
            "|220073|  973|\n",
            "|224639|  971|\n",
            "|225690|  940|\n",
            "|220587|  936|\n",
            "|220644|  936|\n",
            "| 50825|  931|\n",
            "| 50885|  927|\n",
            "| 50878|  920|\n",
            "| 50861|  919|\n",
            "|224417|  917|\n",
            "|225612|  917|\n",
            "| 50863|  902|\n",
            "|225634|  854|\n",
            "| 50910|  839|\n",
            "|227429|  783|\n",
            "|228005|  780|\n",
            "|228006|  777|\n",
            "|227464|  769|\n",
            "|220227|  754|\n",
            "| 50809|  738|\n",
            "|226512|  731|\n",
            "| 50822|  724|\n",
            "| 50800|  713|\n",
            "|227543|  711|\n",
            "| 50911|  699|\n",
            "|228004|  692|\n",
            "|227445|  660|\n",
            "| 51003|  659|\n",
            "| 50816|  659|\n",
            "|227546|  657|\n",
            "|224145|  589|\n",
            "|223773|  588|\n",
            "|220632|  586|\n",
            "| 50954|  576|\n",
            "|225640|  571|\n",
            "|225641|  571|\n",
            "|225643|  571|\n",
            "|225642|  571|\n",
            "|225639|  571|\n",
            "| 50819|  568|\n",
            "|227287|  560|\n",
            "|227456|  557|\n",
            "| 51146|  553|\n",
            "| 51256|  553|\n",
            "| 51244|  553|\n",
            "| 51254|  553|\n",
            "| 51200|  553|\n",
            "| 50862|  549|\n",
            "|224421|  499|\n",
            "|224422|  497|\n",
            "|224895|  475|\n",
            "| 50826|  464|\n",
            "|220765|  433|\n",
            "|220734|  425|\n",
            "|227066|  421|\n",
            "|227471|  419|\n",
            "| 51491|  407|\n",
            "| 51498|  405|\n",
            "| 51009|  391|\n",
            "|226707|  373|\n",
            "|226730|  373|\n",
            "|224751|  370|\n",
            "|223962|  369|\n",
            "|224839|  369|\n",
            "|224406|  355|\n",
            "|224404|  355|\n",
            "|227547|  339|\n",
            "|227468|  337|\n",
            "| 51214|  332|\n",
            "| 51519|  326|\n",
            "| 51492|  316|\n",
            "| 51493|  307|\n",
            "|220274|  306|\n",
            "| 51516|  306|\n",
            "| 51476|  295|\n",
            "|224329|  283|\n",
            "|224328|  283|\n",
            "|224330|  282|\n",
            "| 51484|  259|\n",
            "| 50812|  259|\n",
            "| 51478|  257|\n",
            "|224917|  254|\n",
            "|223763|  254|\n",
            "|224952|  254|\n",
            "| 51514|  245|\n",
            "|226540|  244|\n",
            "|224332|  242|\n",
            "|224663|  241|\n",
            "| 51508|  239|\n",
            "|226534|  237|\n",
            "| 51506|  234|\n",
            "| 51466|  234|\n",
            "| 51464|  234|\n",
            "| 51486|  234|\n",
            "| 51487|  234|\n",
            "|224918|  232|\n",
            "|224953|  230|\n",
            "|227454|  229|\n",
            "|225674|  228|\n",
            "|224331|  214|\n",
            "| 50811|  213|\n",
            "| 50810|  213|\n",
            "| 50824|  211|\n",
            "|225628|  207|\n",
            "| 50908|  205|\n",
            "| 51082|  200|\n",
            "|226846|  199|\n",
            "|224957|  197|\n",
            "|224922|  197|\n",
            "|225672|  196|\n",
            "|224845|  195|\n",
            "|225638|  194|\n",
            "| 50956|  190|\n",
            "| 51144|  189|\n",
            "|220063|  188|\n",
            "|220066|  186|\n",
            "| 51100|  184|\n",
            "| 51463|  183|\n",
            "|225806|  181|\n",
            "|224665|  179|\n",
            "|225807|  178|\n",
            "|225209|  177|\n",
            "|220581|  177|\n",
            "|226063|  175|\n",
            "|227632|  175|\n",
            "|223679|  175|\n",
            "|226062|  175|\n",
            "| 50867|  173|\n",
            "|227538|  171|\n",
            "|227537|  170|\n",
            "|226536|  165|\n",
            "| 50827|  161|\n",
            "|227455|  158|\n",
            "|224662|  155|\n",
            "|225637|  155|\n",
            "| 51255|  153|\n",
            "| 51251|  153|\n",
            "| 51143|  153|\n",
            "| 50806|  151|\n",
            "| 51104|  150|\n",
            "|224753|  149|\n",
            "|224755|  149|\n",
            "|227634|  147|\n",
            "|224955|  147|\n",
            "|224920|  147|\n",
            "|227627|  143|\n",
            "|224322|  139|\n",
            "| 51093|  139|\n",
            "|224654|  138|\n",
            "|224309|  138|\n",
            "|224310|  138|\n",
            "|224652|  138|\n",
            "|224311|  138|\n",
            "|227628|  137|\n",
            "|224919|  130|\n",
            "|224954|  128|\n",
            "|224754|  124|\n",
            "|225810|  117|\n",
            "|224661|  117|\n",
            "|220088|  115|\n",
            "|224897|  114|\n",
            "|226499|  112|\n",
            "|224901|  112|\n",
            "|224418|  111|\n",
            "+------+-----+\n",
            "only showing top 300 rows\n",
            "\n",
            "+--------+------+-----+-------------------+----------+--------------------+\n",
            "|      ID|ITEMID|VALUE|           TIME_OBS|  DATE_OBS|           TIME_SPAN|\n",
            "+--------+------+-----+-------------------+----------+--------------------+\n",
            "|165660.0|223834| 15.0|2134-05-12 12:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|223835|100.0|2134-05-12 12:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|224328| 0.37|2134-05-12 12:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|224329|  6.0|2134-05-12 12:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|224330|  2.5|2134-05-12 12:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|224331|  0.0|2134-05-12 12:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|224332|  3.0|2134-05-12 12:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|224663|  8.0|2134-05-12 12:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|224665| 1.11|2134-05-12 12:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|220224| 58.0|2134-05-12 12:35:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|220235| 60.0|2134-05-12 12:35:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|223830| 7.29|2134-05-12 12:35:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|224828|  0.0|2134-05-12 12:35:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|225668|  1.0|2134-05-12 12:35:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|225698| 30.0|2134-05-12 12:35:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|220045| 86.0|2134-05-12 13:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|220179|137.0|2134-05-12 13:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|220180| 72.0|2134-05-12 13:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|220181| 84.0|2134-05-12 13:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "|165660.0|220210| 21.0|2134-05-12 13:00:00|2134-05-12|{2134-05-12 00:00...|\n",
            "+--------+------+-----+-------------------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+--------------------+\n",
            "|ITEMID|                freq|\n",
            "+------+--------------------+\n",
            "| 51519| 0.09245585874799359|\n",
            "| 50800| 0.08378812199036918|\n",
            "| 51508| 0.06773675762439807|\n",
            "| 51464| 0.06613162118780096|\n",
            "| 51487| 0.06613162118780096|\n",
            "| 51486| 0.06613162118780096|\n",
            "| 51506| 0.06613162118780096|\n",
            "| 51466| 0.06613162118780096|\n",
            "| 51478| 0.06163723916532905|\n",
            "| 51484| 0.05971107544141252|\n",
            "| 51514|0.051043338683788124|\n",
            "| 51463|0.051043338683788124|\n",
            "| 50812| 0.04462279293739968|\n",
            "| 51516| 0.04044943820224719|\n",
            "| 51493|0.037881219903691817|\n",
            "| 51476|0.033386837881219905|\n",
            "| 51492|0.033386837881219905|\n",
            "| 50827| 0.02857142857142857|\n",
            "| 50828|0.015730337078651686|\n",
            "| 50920|0.015088282504012842|\n",
            "+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+------------------+\n",
            "|ITEMID|              freq|\n",
            "+------+------------------+\n",
            "|220045|0.9903691813804173|\n",
            "|220210|0.9897271268057785|\n",
            "|220277|0.9765650080256821|\n",
            "|220047|0.9508828250401284|\n",
            "|223769|0.9473515248796147|\n",
            "|224161|0.9447833065810594|\n",
            "|223761|0.9434991974317817|\n",
            "|224162|0.9380417335473515|\n",
            "|220046|0.8995184590690208|\n",
            "|223770|0.8789727126805779|\n",
            "|220179|0.8536115569823435|\n",
            "|220181|0.8520064205457464|\n",
            "|220180|0.8510433386837881|\n",
            "|227442|0.8507223113964687|\n",
            "|220602|0.8500802568218299|\n",
            "|226253|0.8475120385232745|\n",
            "| 50971|0.8462279293739968|\n",
            "|227443|0.8443017656500803|\n",
            "|220645|0.8439807383627609|\n",
            "| 50902|0.8430176565008025|\n",
            "+------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------+--------------------+--------------------+--------------------+\n",
            "|      ID|           TIME_SPAN|            features|  feature_aggregated|\n",
            "+--------+--------------------+--------------------+--------------------+\n",
            "|162718.0|{2163-04-22 00:00...|[{N_220615_TT -> ...|{N_223761_min -> ...|\n",
            "|112600.0|{2127-08-02 00:00...|[{N_50893_TT -> 0...|{N_51237_TT -> 0....|\n",
            "|117029.0|{2173-04-05 00:00...|[{N_51006_std -> ...|{N_223761_min -> ...|\n",
            "|191719.0|{2160-04-17 00:00...|[{N_51237_TT -> 0...|{N_220181_LT -> 0...|\n",
            "|148585.0|{2126-10-29 00:00...|[{N_220277_LT -> ...|{N_51237_TT -> 0....|\n",
            "|141389.0|{2204-09-28 00:00...|[{N_227443_avg ->...|{N_220181_LT -> 0...|\n",
            "|190711.0|{2127-08-12 00:00...|[{N_51221_TT -> 0...|{N_220181_LT -> 0...|\n",
            "|171130.0|{2159-04-20 00:00...|[{N_223751_max ->...|{N_223752_avg -> ...|\n",
            "|186086.0|{2204-08-06 00:00...|[{N_220047_avg ->...|{N_220181_LT -> 4...|\n",
            "|172739.0|{2137-10-26 00:00...|[{N_227073_LT -> ...|{N_51279_min -> 2...|\n",
            "|116367.0|{2143-11-04 00:00...|[{N_50983_TT -> 0...|{N_51237_TT -> 0....|\n",
            "|182566.0|{2134-06-14 00:00...|[{N_220045_LT -> ...|{N_220181_LT -> 0...|\n",
            "|176760.0|{2142-01-21 00:00...|[{N_220180_std ->...|{N_223752_avg -> ...|\n",
            "|126055.0|{2141-10-21 00:00...|[{N_51006_std -> ...|{N_220181_LT -> 0...|\n",
            "|153063.0|{2181-10-23 00:00...|[{N_220210_TT -> ...|{N_220181_LT -> 0...|\n",
            "|158767.0|{2185-04-05 00:00...|[{N_220046_max ->...|{N_51237_TT -> 0....|\n",
            "|128158.0|{2146-01-07 00:00...|[{N_50983_TT -> 0...|{N_220181_LT -> 1...|\n",
            "|107580.0|{2126-07-11 00:00...|[{N_50868_count -...|{N_220181_LT -> 0...|\n",
            "|149601.0|{2197-12-09 00:00...|[{N_220181_LT -> ...|{N_220181_LT -> 1...|\n",
            "|183794.0|{2176-07-20 00:00...|[{N_51277_max -> ...|{N_220181_LT -> 0...|\n",
            "+--------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGzCSF9FMa4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f14a6a0-24f5-4bdd-86e2-a9cf402f4e09"
      },
      "source": [
        "x = cur_preprocessed.toPandas()\n",
        "print(x.head())\n",
        "len(x)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         ID  ... N_220545_TT\n",
            "0  130108.0  ...    0.290789\n",
            "1  130108.0  ...    0.722685\n",
            "2  118007.0  ...    0.840266\n",
            "3  183762.0  ...    0.401749\n",
            "4  143047.0  ...    0.022046\n",
            "\n",
            "[5 rows x 350 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3104"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8nY4bz5unjq"
      },
      "source": [
        "def annotate_dataset(action_df, cur_df, terminal_outcome, annotation_method = \"p_val\", sel_top = 5):\n",
        "    '''\n",
        "    :param cur_df:\n",
        "    :param annotation_method:\n",
        "    :param postfix:\n",
        "    :param cur_top:\n",
        "    :param non_feature_column:\n",
        "    :param add_flag:\n",
        "    :return:\n",
        "    '''\n",
        "    if annotation_method == \"p_val\":\n",
        "        return annotate_pval_dataset(action_df, cur_df, terminal_outcome, sel_top = sel_top)\n",
        "\n",
        "    return \n",
        "def annotate_pval_dataset(action_df, cur_df, terminal_outcome, non_feature_column = [\"ID\", \"TIME_SPAN\"], sel_top = 5):\n",
        "    import pyspark\n",
        "    from pyspark.ml.feature import VectorAssembler\n",
        "    obs_df = cur_df\n",
        "    itemid = \"ITEMID\"\n",
        "    cur_cols = obs_df.columns\n",
        "    for i in non_feature_column:\n",
        "        cur_cols.remove(i)\n",
        "\n",
        "    cur_cols = sorted(cur_cols)\n",
        "    import json\n",
        "    #json.dump({\"non_demo_features\":cur_cols},open(self.json_feature_dump_loc,\"w\"))\n",
        "    obs_df = VectorAssembler(inputCols=cur_cols, outputCol=\"features_imputed\").transform(obs_df)\n",
        "\n",
        "    cur_time_list = obs_df.select(\"ID\",\"TIME_SPAN\")\n",
        "    of_annotated = obs_df\n",
        "    of_excl_training = dict()\n",
        "    demo_feature = add_demo()\n",
        "    #from pyspark.context import SparkContext\n",
        "    #from pyspark.sql.session import SparkSession\n",
        "    #sc = SparkContext.getOrCreate();\n",
        "    #spark = SparkSession(sc)\n",
        "    #action_df.TIME_OBS = action_df.TIME_OBS.astype(str)\n",
        "    #demo_feature = spark.createDataFrame(demo_feature)\n",
        "    \n",
        "    of_annotated = VectorAssembler(inputCols=[\"features_imputed\",\"demo_feature\"],outputCol=\"features\").transform(of_annotated.join(demo_feature,\"ID\"))\n",
        "    from pyspark.sql.functions import col,lit,when\n",
        "    cur_test_ids = get_target_test_id()\n",
        "    tr_inst,te_inst = prep_TR_TE(of_annotated,test_id_list = cur_test_ids)\n",
        "    train_data_ID = tr_inst.select(\"ID\").distinct().rdd.flatMap(list).collect()\n",
        "\n",
        "    testing_data_ID = te_inst.select(\"ID\").distinct().rdd.flatMap(list).collect()\n",
        "\n",
        "    train_action_df = action_df.where(col(\"ID\").isin(train_data_ID)).persist()\n",
        "    train_terminal_outcome = terminal_outcome.where(col(\"ID\").isin(train_data_ID)).persist()\n",
        "    intv_w_p_val = identify_relevant_action(train_action_df, train_terminal_outcome, tr_inst.select(\"ID\").distinct().count(), terminal_outcome)\n",
        "    #intv_w_p_val.join(def_df[def_df[\"SOURCE\"].isin([\"CPT\",\"MED\",\"PROC\"])], itemid).orderBy(\"p_val\").show(100, truncate=False)\n",
        "    from pyspark.sql.functions import sum,rand,max,lit\n",
        "    from pyspark.ml.feature import VectorAssembler\n",
        "    annot_df = action_df.join(terminal_outcome,\"ID\").persist()\n",
        "    pos_inst_dict = dict()\n",
        "    from pyspark.sql.functions import count\n",
        "    cur_annot_topk = sel_top\n",
        "    for cur_of in [target_disch_col]:\n",
        "        # For debug purpose, pass if target_of is not identified\n",
        "        intv_w_p_val.where(\"DISCH_DX == '{0}'\".format(cur_of)).orderBy(col(\"p_val\").cast(\"double\")).show(50,truncate=False)\n",
        "        target_annot_criteria = intv_w_p_val.where(\"DISCH_DX == '{0}'\".format(cur_of)).orderBy(col(\"p_val\").cast(\"double\")).limit(cur_annot_topk)\n",
        "       # target_annot_criteria.write.save(self.annot_intv_dir.format(cur_of,cur_annot_topk),mode=\"overwrite\")\n",
        "        target_annot_criteria = target_annot_criteria.select(itemid).rdd.flatMap(list).collect()\n",
        "        if len(target_annot_criteria) == 0:\n",
        "            pos_inst_dict[cur_of] = None\n",
        "            continue\n",
        "        print(\"checkpoint 10\")\n",
        "        #def_df[def_df[\"ITEMID\"].isin(target_annot_criteria)].show(cur_annot_topk,truncate=False)\n",
        "        print(\"checkpoint 11\")\n",
        "        pos_inst_dict[cur_of] = annot_df.where((col(itemid).isin(target_annot_criteria)) & (col(\"DISCH_DX\") == cur_of))\\\n",
        "            .select(\"ID\", col(\"TIME_OBS\").cast(\"date\").alias(\"TIME_OBS\"), lit(\"1\").cast(\"double\").alias(\"{0}_label\".format(cur_of)))\\\n",
        "            .distinct().persist()\n",
        "        print(\"checkpoint 12\")\n",
        "        #pos_inst_dict[cur_of].groupBy(\"{0}_label\".format(cur_of)).agg(count(\"*\")).show()\n",
        "        from pyspark.sql.functions import broadcast\n",
        "\n",
        "        true_inst = annot_df.where((col(itemid).isin(target_annot_criteria)) & (col(\"DISCH_DX\") == cur_of))\n",
        "        excl_id = annot_df.withColumn(\"IS_TARGET_OF\",when(col(\"DISCH_DX\") ==cur_of,lit(\"1\").cast(\"double\")).otherwise(lit(\"0\").cast(\"double\")))\\\n",
        "            .withColumn(\"IS_REL_INTV\", when(col(itemid).isin(target_annot_criteria), lit(\"1\").cast(\"double\")).otherwise(lit(\"0\").cast(\"double\")))\\\n",
        "            .groupBy(\"ID\").agg(sum(\"IS_TARGET_OF\").alias(\"SUM_IS_TARGET_OF\"),sum(\"IS_REL_INTV\").alias(\"SUM_IS_REL_INTV\"))\\\n",
        "            .where(\"(SUM_IS_TARGET_OF <> 0) AND (SUM_IS_REL_INTV == 0)\").select(\"ID\").distinct().rdd.flatMap(list).collect()\n",
        "        print(\"checkpoint 13\")\n",
        "        tr_inst = tr_inst.withColumn(\"TIME_OBS\",col(\"TIME_SPAN.TIME_TO\").cast(\"date\"))\\\n",
        "            .withColumn(\"{0}_excl\".format(cur_of), col(\"ID\").isin(excl_id).cast(\"double\")).repartition(\"ID\",\"TIME_OBS\")\\\n",
        "            .join(broadcast(pos_inst_dict[cur_of]),[\"ID\",\"TIME_OBS\"],\"left_outer\").fillna(value=0.0,subset=[\"{0}_label\".format(cur_of)]).persist()\n",
        "        print(tr_inst.count())\n",
        "        #tr_inst.groupBy(\"{0}_label\".format(cur_of),\"{0}_excl\".format(cur_of)).agg(count(\"*\")).show()\n",
        "        te_inst = te_inst.withColumn(\"TIME_OBS\",col(\"TIME_SPAN.TIME_TO\").cast(\"date\"))\\\n",
        "            .withColumn(\"{0}_excl\".format(cur_of), col(\"ID\").isin(excl_id).cast(\"double\")).repartition(\"ID\",\"TIME_OBS\")\\\n",
        "            .join(broadcast(pos_inst_dict[cur_of]),[\"ID\",\"TIME_OBS\"],\"left_outer\").fillna(value=0.0, subset=[\"{0}_label\".format(cur_of)]).persist()\n",
        "        print(te_inst.count())\n",
        "        #te_inst.groupBy(\"{0}_label\".format(cur_of),\"{0}_excl\".format(cur_of)).agg(count(\"*\")).show()\n",
        "\n",
        "        tr_inst.groupBy(\"ID\").agg(max(\"{0}_label\".format(cur_of)).alias(\"{0}_label\".format(cur_of)),max(\"{0}_excl\".format(cur_of)).alias(\"{0}_excl\".format(cur_of))).groupBy(\"{0}_label\".format(cur_of),\"{0}_excl\".format(cur_of)).agg(count(\"*\")).show()\n",
        "        te_inst.groupBy(\"ID\").agg(max(\"{0}_label\".format(cur_of)).alias(\"{0}_label\".format(cur_of)),max(\"{0}_excl\".format(cur_of)).alias(\"{0}_excl\".format(cur_of))).groupBy(\"{0}_label\".format(cur_of),\"{0}_excl\".format(cur_of)).agg(count(\"*\")).show()\n",
        "\n",
        "    #tr_inst.write.save(self.training_temp_dir, mode=\"overwrite\")\n",
        "    #te_inst.write.save(self.testing_temp_dir, mode=\"overwrite\")\n",
        "\n",
        "    #tr_inst = self.spark.read.parquet(self.training_temp_dir)\n",
        "    #te_inst = self.spark.read.parquet(self.testing_temp_dir)\n",
        "    #te_inst.show()\n",
        "    return (tr_inst,te_inst)\n",
        "\n",
        "def identify_relevant_action(action_df, terminal_df,cnt_pop, terminal_outcome):\n",
        "        from pyspark.sql.functions import col\n",
        "        def ret_p_val(obs,cnt_pop,p):\n",
        "            from scipy.stats import binom_test\n",
        "            return float(binom_test(obs,cnt_pop,p,alternative='greater'))\n",
        "\n",
        "        from pyspark.sql.functions import count, udf,col\n",
        "        from pyspark.sql.types import DoubleType\n",
        "\n",
        "        cur_dx_cnt = terminal_outcome.groupBy(\"DISCH_DX\").agg(count(\"*\").alias(\"DISCH_DX_CNT\")).cache()\n",
        "        distinct_action_df = action_df.select(\"ID\",\"ITEMID\").distinct().cache()\n",
        "        agg_action_df = distinct_action_df.groupBy(\"ITEMID\").agg(count(\"*\").alias(\"action_cnt\")).withColumn(\"action_prop\",col(\"action_cnt\")/float(cnt_pop))\n",
        "        merged_terminal_action = terminal_df.join(distinct_action_df,\"ID\").groupBy(\"DISCH_DX\",\"ITEMID\").agg(count(\"*\").alias(\"DISCH_DX_ACTION_CNT\")).join(cur_dx_cnt,\"DISCH_DX\").join(agg_action_df,\"ITEMID\").persist()\n",
        "\n",
        "        udf_binom_test = udf(ret_p_val,DoubleType())\n",
        "        cur_test = merged_terminal_action.withColumn(\"p_val\",udf_binom_test(\"DISCH_DX_ACTION_CNT\",\"DISCH_DX_CNT\",\"action_prop\")).cache()\n",
        "        return cur_test\n",
        "def prep_TR_TE(merged_df, per_instance=False, tr_prop=0.9,targetCol=\"ID\",test_id_list = []):\n",
        "    from pyspark.sql.functions import col\n",
        "    if len(test_id_list) != 0:\n",
        "        tr_inst = merged_df.where(~col(targetCol).isin(test_id_list))\n",
        "        te_inst = merged_df.where(col(targetCol).isin(test_id_list))\n",
        "        return (tr_inst,te_inst)\n",
        "    if per_instance:\n",
        "        tr_inst, te_inst = merged_df.randomSplit([tr_prop, 1-tr_prop])\n",
        "    else:\n",
        "        tr_id, te_id = merged_df.select(targetCol).distinct().randomSplit([tr_prop,1-tr_prop])\n",
        "        tr_id = tr_id.rdd.flatMap(list).collect()\n",
        "        te_id = te_id.rdd.flatMap(list).collect()\n",
        "        tr_inst = merged_df.where(col(targetCol).isin(tr_id))\n",
        "        te_inst = merged_df.where(col(targetCol).isin(te_id))\n",
        "    return (tr_inst,te_inst)\n",
        "\n",
        "def run_RF(tr_inst,te_inst, target_disch_col, eval_performance_criteria = \"AUROC\", eval_cv_or_tvt = \"CV\", model_of = [], cur_cv_fold = 2):\n",
        "        from pyspark.sql.functions import col\n",
        "\n",
        "        if model_of == []:\n",
        "            model_of = target_disch_col\n",
        "        if type(model_of) == str:\n",
        "            model_of = [model_of]\n",
        "\n",
        "        from pyspark.ml.classification import GBTClassifier as cur_model_selection\n",
        "\n",
        "        cur_classifier = cur_model_selection(featuresCol=\"features\",checkpointInterval=5)\n",
        "\n",
        "        from pyspark.ml import Pipeline\n",
        "        from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "        from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "        if eval_performance_criteria == \"AUPRC\":\n",
        "            target_metric=\"areaUnderPR\"\n",
        "        elif eval_performance_criteria == \"AUROC\":\n",
        "            target_metric=\"areaUnderROC\"\n",
        "        else:\n",
        "            raise Exception(\"eval_metric should be either 'AUPRC' or 'AUROC'\")\n",
        "\n",
        "\n",
        "        evaluator = BinaryClassificationEvaluator(metricName=target_metric)\n",
        "        paramGrid = get_param_grid(cur_model_selection) ########\n",
        "\n",
        "        if eval_cv_or_tvt == \"CV\":\n",
        "            pipeline = Pipeline(stages=[cur_classifier])\n",
        "            orig_tr_inst = tr_inst\n",
        "            orig_te_inst = te_inst\n",
        "            from pyspark.sql.functions import count, datediff\n",
        "            from pyspark.sql.functions import udf, log, sum, exp, max\n",
        "            udf_prob = udf(lambda x: x.toArray().tolist()[1])\n",
        "            from pyspark.sql.functions import corr, udf, isnan\n",
        "            for cur_of in model_of:\n",
        "                #should move this to back\n",
        "                te_inst = orig_te_inst.withColumn(\"label\", col(\"{0}_label\".format(cur_of)).cast(\"double\"))\n",
        "                te_inst.groupBy(\"label\").agg(count(\"*\")).show()\n",
        "\n",
        "                tr_inst.printSchema()\n",
        "                tr_val_pts_dict = get_target_tr_val_id() #####\n",
        "                orig_tr_inst = tr_inst\n",
        "\n",
        "                tr_pts = tr_val_pts_dict[\"TR\"]\n",
        "                val_pts = tr_val_pts_dict[\"VAL\"]\n",
        "\n",
        "                all_training_ids = tr_pts+val_pts\n",
        "                from random import shuffle\n",
        "                shuffle(all_training_ids)\n",
        "                import numpy as np\n",
        "                print(len(all_training_ids))\n",
        "                cv_id_list_full = np.array(all_training_ids)\n",
        "                perform_dict = dict()\n",
        "                for cur_cv_stage in range(cur_cv_fold):\n",
        "                    tr_pts = cv_id_list_full[np.linspace(0,cv_id_list_full.shape[0]-1,cv_id_list_full.shape[0])%cur_cv_fold != cur_cv_stage].tolist()\n",
        "                    val_pts = cv_id_list_full[np.linspace(0,cv_id_list_full.shape[0]-1,cv_id_list_full.shape[0])%cur_cv_fold == cur_cv_stage].tolist()\n",
        "                    print(np.linspace(0,cv_id_list_full.shape[0]-1,cv_id_list_full.shape[0])%cur_cv_fold == cur_cv_stage)\n",
        "                    print(cv_id_list_full[np.linspace(0,cv_id_list_full.shape[0]-1,cv_id_list_full.shape[0])%cur_cv_fold == cur_cv_stage])\n",
        "                    print(\"VAL_ROUND_{0}_TARGET IDS:{1}\".format(cur_cv_stage,val_pts))\n",
        "\n",
        "                    tr_inst = orig_tr_inst.where(col(\"ID\").isin(tr_pts))#.persist()\n",
        "                    val_inst = orig_tr_inst.where(col(\"ID\").isin(val_pts))#.persist()\n",
        "                    tr_inst = tr_inst.where(col(\"{0}_excl\".format(cur_of)) == 0).withColumn(\"label\", col(\n",
        "                        \"{0}_label\".format(cur_of)).cast(\"double\"))\n",
        "                    val_inst = val_inst.withColumn(\"label\", col(\n",
        "                        \"{0}_label\".format(cur_of)).cast(\"double\"))\n",
        "                    \n",
        "                    tr_inst.groupBy(\"label\").agg(count(\"*\")).show()\n",
        "                    pipeline_models = pipeline.fit(tr_inst, params=paramGrid)\n",
        "\n",
        "                    for cur_model in pipeline_models:\n",
        "                        val_pred = cur_model.transform(val_inst)\n",
        "                        agg_prob_val = val_pred.groupBy(\"ID\").agg(max(\"label\").alias(\"label\"),\n",
        "                                                                  sum(log(1.0 - udf_prob(\"Probability\"))).alias(\n",
        "                                                                      \"inverse_log_sum\")) \\\n",
        "                            .select(\"label\", (1.0 - exp(col(\"inverse_log_sum\"))).alias(\"rawPrediction\"))\n",
        "                        agg_prob_val.show(300, truncate=False)\n",
        "                        cur_pr = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\",\n",
        "                                                               metricName=target_metric).evaluate(agg_prob_val)\n",
        "                        if str(cur_model.stages[-1].extractParamMap()) not in perform_dict:\n",
        "                            perform_dict[str(cur_model.stages[-1].extractParamMap())] = dict()\n",
        "                            perform_dict[str(cur_model.stages[-1].extractParamMap())][\"PERF\"]=list()\n",
        "                            perform_dict[str(cur_model.stages[-1].extractParamMap())][\"PARAM\"] = cur_model.stages[-1].extractParamMap()\n",
        "\n",
        "                        perform_dict[str(cur_model.stages[-1].extractParamMap())][\"PERF\"].append(cur_pr)\n",
        "\n",
        "                best_pf_measure = -1\n",
        "                best_pf_param = None\n",
        "\n",
        "                for key in perform_dict:\n",
        "                    import numpy as np\n",
        "                    test_array = np.array(perform_dict[key][\"PERF\"])\n",
        "                    print(key, test_array.mean(), test_array.std())\n",
        "                    if best_pf_measure < test_array.mean():\n",
        "                        best_pf_measure = test_array.mean()\n",
        "                        best_pf_param = perform_dict[key][\"PARAM\"]\n",
        "\n",
        "\n",
        "                print(\"retrain model based on best hp from CV\")\n",
        "                print(\"PERF:{0}\".format(best_pf_measure))\n",
        "                print(\"HP:{0}\".format(best_pf_param))\n",
        "                tr_inst = orig_tr_inst.where(col(\"{0}_excl\".format(cur_of)) == 0).withColumn(\"label\", col(\n",
        "                    \"{0}_label\".format(cur_of)).cast(\"double\"))\n",
        "\n",
        "                bestModel = pipeline.fit(tr_inst.where(col(\"ID\").isin(cv_id_list_full.tolist())),params=[best_pf_param])[0]\n",
        "\n",
        "                #bestModel.save(self.model_dir_template.format(cur_of, best_pf_measure))\n",
        "\n",
        "                prediction = bestModel.transform(te_inst)\n",
        "                prediction.show()\n",
        "               # prediction.write.save(self.testing_result_dest_template.format(cur_of), mode=\"overwrite\")\n",
        "                tr_result = bestModel.transform(tr_inst).withColumn(\"Prob\",udf_prob(\"Probability\"))\n",
        "                #tr_result.write.save(self.training_result_dest_template.format(cur_of), mode=\"overwrite\")\n",
        "                return prediction, tr_result\n",
        "\n",
        "def get_param_grid(cur_model_selection):\n",
        "        from pyspark.ml.tuning import ParamGridBuilder\n",
        "        return ParamGridBuilder() \\\n",
        "            .addGrid(cur_model_selection.maxDepth, [2]) \\\n",
        "            .addGrid(cur_model_selection.subsamplingRate, [0.3,0.8]) \\\n",
        "            .addGrid(cur_model_selection.maxIter, [2]) \\\n",
        "            .build()\n",
        "def handle_missing(cur_df, non_feature_col = [\"ID\", \"TIME_SPAN\"]):\n",
        "      import pyspark\n",
        "      cur_cols = cur_df.columns\n",
        "      categorical_cols = list()\n",
        "      numerical_cols = list()\n",
        "      for i in non_feature_col:\n",
        "          cur_cols.remove(i)\n",
        "      for i in cur_cols:\n",
        "          if i.find(\"C_\") == 0:\n",
        "              categorical_cols.append(i)\n",
        "          else:\n",
        "              numerical_cols.append(i)\n",
        "\n",
        "      cur_df = cur_df.fillna(0,subset = categorical_cols).repartition(400)\n",
        "\n",
        "      from pyspark.ml.feature import Imputer\n",
        "      imputedCols = [\"imp_{0}\".format(x) for x in numerical_cols]\n",
        "      imputer = Imputer(inputCols = numerical_cols,outputCols = imputedCols).setStrategy(\"mean\")\n",
        "      imputer_model = imputer.fit(cur_df)\n",
        "      ret_data_frame = imputer_model.transform(cur_df)\n",
        "      #ret_data_frame.select(non_feature_col+imputedCols+categorical_cols).show()\n",
        "      #ret_data_frame.select(non_feature_col+imputedCols+categorical_cols).write.save(self.temp_missing_drop)\n",
        "      #ret_data_frame = self.spark.read.parquet(self.temp_missing_drop)\n",
        "      return ret_data_frame.select(non_feature_col+imputedCols+categorical_cols)\n",
        "def define_and_normalize_terminal_df(action_df, def_df):\n",
        "      '''\n",
        "      exclude action df that doesn't fit to current criteria\n",
        "      :return:\n",
        "      '''\n",
        "      from pyspark.context import SparkContext\n",
        "      from pyspark.sql.session import SparkSession\n",
        "      sc = SparkContext.getOrCreate();\n",
        "      spark = SparkSession(sc)\n",
        "      action_df.TIME_OBS = action_df.TIME_OBS.astype(str)\n",
        "      action_df = spark.createDataFrame(action_df)\n",
        "\n",
        "      cur_action_col = action_df\n",
        "      cur_def = def_df\n",
        "\n",
        "      original_def = cur_def\n",
        "      all_itemid =get_action_itemids()\n",
        "      return action_df.join(all_itemid,[\"ITEMID\",\"SOURCE\"]).persist()\n",
        "\n",
        "def flatten_terminal_outcome(action_df, cur_terminal_df, target_disch_col, target_disch_icd9):\n",
        "      from pyspark.sql.functions import max,col,lit\n",
        "      from pyspark.context import SparkContext\n",
        "      from pyspark.sql.session import SparkSession\n",
        "      sc = SparkContext.getOrCreate();\n",
        "      spark = SparkSession(sc)\n",
        "      action_df.TIME_OBS = action_df.TIME_OBS.astype(str)\n",
        "      action_df = spark.createDataFrame(action_df)\n",
        "      \n",
        "      terminal_action = action_df.select(\"ID\", \"ITEMID\").distinct()\n",
        "      cur_terminal_df = spark.createDataFrame(cur_terminal_df)\n",
        "      terminal_outcome = cur_terminal_df\n",
        "      from pyspark.sql.functions import when\n",
        "      cur_of_col = [target_disch_col]\n",
        "      terminal_outcome = terminal_outcome.withColumn(target_disch_col,when(col(\"ICD9_CODE\").isin(target_disch_icd9),lit(\"1\")).otherwise(lit(\"0\")))\\\n",
        "          .select([\"ID\"] + cur_of_col).groupBy(\"ID\").agg(\n",
        "          *(max(c).alias(c) for c in cur_of_col)).select(\n",
        "          *(col(c).cast(\"double\").alias(c) if c in cur_of_col else col(c) for c in [\"ID\"] + cur_of_col))\n",
        "      raw_terminal_outcome = terminal_outcome\n",
        "      from pyspark.sql.functions import rand\n",
        "      #cms_dx_def = self.cur_annotator.annotate_of_label()\n",
        "\n",
        "      target_terminal_outcome_table = terminal_outcome\n",
        "      flatten_of_list = list()\n",
        "      for cur_of in [target_disch_col]:\n",
        "          flatten_of_list.append(terminal_outcome.where(\"{0} == 1\".format(cur_of)).select(\"ID\",lit(\"{0}\".format(cur_of)).alias(\"DISCH_DX\")))\n",
        "\n",
        "\n",
        "\n",
        "      from functools import reduce as f_reduce\n",
        "      from pyspark.sql import DataFrame\n",
        "      terminal_outcome = f_reduce(DataFrame.union, flatten_of_list).persist()\n",
        "      return terminal_outcome\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_pL-uZvL1kc"
      },
      "source": [
        "#work on run_experiment\n",
        "def run_experiment(action_df, cur_terminal_df, target_disch_col, target_disch_icd9, cur_preprocesssed, num_intv = 5):\n",
        "        '''\n",
        "        print agg_prob, corr_predicted_risks and return following\n",
        "        :return: dict tr_instance df, dict te_instance df, dict model(CVModel)\n",
        "        '''\n",
        "        from pyspark.ml import PipelineModel\n",
        "        import pyspark\n",
        "        #self.set_top_intv_k(num_intv) -> does nothing - >Edit NEED TO INCLUDE FOR MULTIPLE INTERVENTIONS in the annotate_dataset method\n",
        "        sel_top = num_intv\n",
        "        terminal_outcome = flatten_terminal_outcome(action_df, cur_terminal_df, target_disch_col, target_disch_icd9)\n",
        "        from glob import glob\n",
        "        tr_result = dict()\n",
        "        te_result = dict()\n",
        "        ret_model = dict()\n",
        "        for cur_of in [target_disch_col]:\n",
        "            def_df = get_def_df()\n",
        "            action_df = define_and_normalize_terminal_df(action_df, def_df)\n",
        "            cur_df = cur_preprocessed \n",
        "            preprocessed_data = handle_missing(cur_df, non_feature_col = [\"ID\", \"TIME_SPAN\"]) \n",
        "            tr_inst, te_inst = annotate_dataset(action_df, preprocessed_data, terminal_outcome, sel_top = sel_top)\n",
        "            tr_inst.show()\n",
        "            te_inst.show()\n",
        "            return run_RF(tr_inst, te_inst, target_disch_col, model_of = cur_of)\n",
        "\n",
        "            #cur_model = glob(self.model_dir_template.format(cur_of,\"*\"))\n",
        "            #print(cur_model)\n",
        "\n",
        "            #cur_model = cur_model[0]\n",
        "            #ret_model[cur_of] = PipelineModel.load(cur_model)\n",
        "\n",
        "            #tr_result[cur_of] = self.spark.read.parquet(self.training_result_dest_template.format(cur_of))\n",
        "            #te_result[cur_of] = self.spark.read.parquet(self.testing_result_dest_template.format(cur_of))\n",
        "\n",
        "        return tr_result, te_result#, cur_model"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot1GsDmWgfQI"
      },
      "source": [
        "#double check whether this is correct\n",
        "#target disch is what is passed into data_run_experiment init\n",
        "# target disch icd9 is what is passed into mimic_hp_training_scale init\n",
        "#change back frorm only 1 icd9\n",
        "target_disch = [\"51881\", \"51851\", \"51884\", \"51853\"]\n",
        "target_disch_col = \"DISCH_{0}\".format(\"_\".join(target_disch))\n",
        "target_disch_icd9 = [\"51881\", \"51851\", \"51884\", \"51853\"]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nV-0jTiPRbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6213fc0-2149-4240-86cf-912882d7ac2f"
      },
      "source": [
        "#tr_result and te_result are backwards\n",
        "#deleted cell output as it was very long\n",
        "# REMEMBER TO USE 5 INTERVENTIONS WHEN CALLING RUN_EXPERIMENT -> USE A FOR LOOP PASSING numintv as the looping variable\n",
        "for cur_intv_num in [10]:\n",
        "  tr_result, te_result = run_experiment(action_df, terminal_df, target_disch_col, target_disch_icd9, cur_preprocessed, num_intv = cur_intv_num)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (4,5,7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "37878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 330712483 entries, 0 to 330712482\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   ID        int32 \n",
            " 1   ITEMID    int32 \n",
            " 2   TIME_OBS  object\n",
            " 3   VALUE     object\n",
            " 4   SOURCE    object\n",
            "dtypes: int32(2), object(3)\n",
            "memory usage: 9.9+ GB\n",
            "None\n",
            "Index              128\n",
            "ID          1322849932\n",
            "ITEMID      1322849932\n",
            "TIME_OBS    2645699864\n",
            "VALUE       2645699864\n",
            "SOURCE      2645699864\n",
            "dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27854055 entries, 0 to 27854054\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype  \n",
            "---  ------    -----  \n",
            " 0   ID        float64\n",
            " 1   ITEMID    int64  \n",
            " 2   TIME_OBS  object \n",
            " 3   VALUE     object \n",
            " 4   SOURCE    object \n",
            "dtypes: float64(1), int64(1), object(3)\n",
            "memory usage: 1.0+ GB\n",
            "None\n",
            "Index             128\n",
            "ID          222832440\n",
            "ITEMID      222832440\n",
            "TIME_OBS    222832440\n",
            "VALUE       222832440\n",
            "SOURCE      222832440\n",
            "dtype: int64\n",
            "check!!!\n",
            "(0, 1)\n",
            "         ID  ITEMID            TIME_OBS VALUE SOURCE    DBSOURCE DNR_TIME\n",
            "0  165660.0  223834 2134-05-12 12:00:00    15  VITAL  metavision      NaT\n",
            "1  165660.0  223835 2134-05-12 12:00:00   100  VITAL  metavision      NaT\n",
            "2  165660.0  224328 2134-05-12 12:00:00  0.37  VITAL  metavision      NaT\n",
            "3  165660.0  224329 2134-05-12 12:00:00     6  VITAL  metavision      NaT\n",
            "4  165660.0  224330 2134-05-12 12:00:00   2.5  VITAL  metavision      NaT\n",
            "+--------+-----------------------------+-------------------+------------+----------+---------------------+---------------------+\n",
            "|ITEMID  |DISCH_DX                     |DISCH_DX_ACTION_CNT|DISCH_DX_CNT|action_cnt|action_prop          |p_val                |\n",
            "+--------+-----------------------------+-------------------+------------+----------+---------------------+---------------------+\n",
            "|94003.0 |DISCH_51881_51851_51884_51853|99                 |144         |161       |0.25967741935483873  |8.386073610579165E-27|\n",
            "|225792.0|DISCH_51881_51851_51884_51853|87                 |144         |165       |0.2661290322580645   |1.783371314627232E-17|\n",
            "|221744.0|DISCH_51881_51851_51884_51853|70                 |144         |133       |0.21451612903225806  |5.400005282802787E-13|\n",
            "|221668.0|DISCH_51881_51851_51884_51853|65                 |144         |117       |0.18870967741935485  |5.860178422781299E-13|\n",
            "|227194.0|DISCH_51881_51851_51884_51853|63                 |144         |127       |0.20483870967741935  |2.560975950566969E-10|\n",
            "|225942.0|DISCH_51881_51851_51884_51853|35                 |144         |52        |0.08387096774193549  |7.745437007965284E-9 |\n",
            "|224385.0|DISCH_51881_51851_51884_51853|38                 |144         |72        |0.11612903225806452  |8.691810821972363E-7 |\n",
            "|221906.0|DISCH_51881_51851_51884_51853|48                 |144         |106       |0.17096774193548386  |1.7220423607226797E-6|\n",
            "|221794.0|DISCH_51881_51851_51884_51853|69                 |144         |186       |0.3                  |4.779480948569069E-6 |\n",
            "|222168.0|DISCH_51881_51851_51884_51853|49                 |144         |114       |0.18387096774193548  |5.759892062095549E-6 |\n",
            "|225907.0|DISCH_51881_51851_51884_51853|37                 |144         |79        |0.12741935483870967  |1.9962961969624624E-5|\n",
            "|225400.0|DISCH_51881_51851_51884_51853|19                 |144         |31        |0.05                 |1.1179386153034266E-4|\n",
            "|94002.0 |DISCH_51881_51851_51884_51853|36                 |144         |83        |0.1338709677419355   |1.3267636159617306E-4|\n",
            "|225794.0|DISCH_51881_51851_51884_51853|21                 |144         |39        |0.06290322580645161  |2.8211564683669417E-4|\n",
            "|221824.0|DISCH_51881_51851_51884_51853|17                 |144         |31        |0.05                 |9.150092462098607E-4 |\n",
            "|222062.0|DISCH_51881_51851_51884_51853|9                  |144         |11        |0.017741935483870968 |0.001157870602385187 |\n",
            "|225909.0|DISCH_51881_51851_51884_51853|16                 |144         |30        |0.04838709677419355  |0.001725071298492082 |\n",
            "|227522.0|DISCH_51881_51851_51884_51853|40                 |144         |114       |0.18387096774193548  |0.003722675239538144 |\n",
            "|227523.0|DISCH_51881_51851_51884_51853|55                 |144         |174       |0.2806451612903226   |0.005420187635254125 |\n",
            "|227536.0|DISCH_51881_51851_51884_51853|7                  |144         |10        |0.016129032258064516 |0.009206971462021544 |\n",
            "|221555.0|DISCH_51881_51851_51884_51853|7                  |144         |10        |0.016129032258064516 |0.009206971462021544 |\n",
            "|225154.0|DISCH_51881_51851_51884_51853|47                 |144         |149       |0.2403225806451613   |0.011983967037141507 |\n",
            "|225834.0|DISCH_51881_51851_51884_51853|24                 |144         |64        |0.1032258064516129   |0.012731550813286271 |\n",
            "|227525.0|DISCH_51881_51851_51884_51853|7                  |144         |11        |0.017741935483870968 |0.01485902921730372  |\n",
            "|225802.0|DISCH_51881_51851_51884_51853|7                  |144         |11        |0.017741935483870968 |0.01485902921730372  |\n",
            "|222011.0|DISCH_51881_51851_51884_51853|72                 |144         |255       |0.4112903225806452   |0.019399984462304863 |\n",
            "|225470.0|DISCH_51881_51851_51884_51853|12                 |144         |27        |0.043548387096774194 |0.024042956718823463 |\n",
            "|225440.0|DISCH_51881_51851_51884_51853|5                  |144         |7         |0.01129032258064516  |0.024363488159195607 |\n",
            "|221385.0|DISCH_51881_51851_51884_51853|28                 |144         |83        |0.1338709677419355   |0.02634595893318691  |\n",
            "|221456.0|DISCH_51881_51851_51884_51853|44                 |144         |145       |0.23387096774193547  |0.029188420914712885 |\n",
            "|222315.0|DISCH_51881_51851_51884_51853|12                 |144         |28        |0.04516129032258064  |0.03062012720795757  |\n",
            "|225835.0|DISCH_51881_51851_51884_51853|11                 |144         |25        |0.04032258064516129  |0.032067419020640905 |\n",
            "|225466.0|DISCH_51881_51851_51884_51853|3                  |144         |3         |0.004838709677419355 |0.0333677703084298   |\n",
            "|220995.0|DISCH_51881_51851_51884_51853|18                 |144         |49        |0.07903225806451612  |0.03571259436163487  |\n",
            "|221749.0|DISCH_51881_51851_51884_51853|24                 |144         |71        |0.11451612903225807  |0.038408777473585405 |\n",
            "|227526.0|DISCH_51881_51851_51884_51853|5                  |144         |8         |0.012903225806451613 |0.03967846879600332  |\n",
            "|225464.0|DISCH_51881_51851_51884_51853|5                  |144         |8         |0.012903225806451613 |0.03967846879600332  |\n",
            "|227529.0|DISCH_51881_51851_51884_51853|5                  |144         |8         |0.012903225806451613 |0.03967846879600332  |\n",
            "|221662.0|DISCH_51881_51851_51884_51853|14                 |144         |36        |0.05806451612903226  |0.04113927150926376  |\n",
            "|225906.0|DISCH_51881_51851_51884_51853|7                  |144         |14        |0.02258064516129032  |0.045840211123611564 |\n",
            "|221653.0|DISCH_51881_51851_51884_51853|4                  |144         |6         |0.00967741935483871  |0.052125051025092274 |\n",
            "|225152.0|DISCH_51881_51851_51884_51853|30                 |144         |98        |0.15806451612903225  |0.06562164364257796  |\n",
            "|225910.0|DISCH_51881_51851_51884_51853|54                 |144         |194       |0.31290322580645163  |0.06622576150772504  |\n",
            "|225166.0|DISCH_51881_51851_51884_51853|62                 |144         |228       |0.36774193548387096  |0.07090245424546236  |\n",
            "|221223.0|DISCH_51881_51851_51884_51853|8                  |144         |19        |0.03064516129032258  |0.07642995647846482  |\n",
            "|227690.0|DISCH_51881_51851_51884_51853|2                  |144         |2         |0.0032258064516129032|0.07938754193671878  |\n",
            "|225908.0|DISCH_51881_51851_51884_51853|2                  |144         |2         |0.0032258064516129032|0.07938754193671878  |\n",
            "|225150.0|DISCH_51881_51851_51884_51853|6                  |144         |13        |0.020967741935483872 |0.08373358036570613  |\n",
            "|221468.0|DISCH_51881_51851_51884_51853|9                  |144         |23        |0.037096774193548385 |0.08875057494854649  |\n",
            "|225402.0|DISCH_51881_51851_51884_51853|58                 |144         |216       |0.34838709677419355  |0.1007182211993006   |\n",
            "+--------+-----------------------------+-------------------+------------+----------+---------------------+---------------------+\n",
            "only showing top 50 rows\n",
            "\n",
            "checkpoint 10\n",
            "checkpoint 11\n",
            "checkpoint 12\n",
            "checkpoint 13\n",
            "2783\n",
            "321\n",
            "+-----------------------------------+----------------------------------+--------+\n",
            "|DISCH_51881_51851_51884_51853_label|DISCH_51881_51851_51884_51853_excl|count(1)|\n",
            "+-----------------------------------+----------------------------------+--------+\n",
            "|                                0.0|                               1.0|       9|\n",
            "|                                1.0|                               0.0|     113|\n",
            "|                                0.0|                               0.0|     498|\n",
            "+-----------------------------------+----------------------------------+--------+\n",
            "\n",
            "+-----------------------------------+----------------------------------+--------+\n",
            "|DISCH_51881_51851_51884_51853_label|DISCH_51881_51851_51884_51853_excl|count(1)|\n",
            "+-----------------------------------+----------------------------------+--------+\n",
            "|                                0.0|                               1.0|       1|\n",
            "|                                1.0|                               0.0|      12|\n",
            "|                                0.0|                               0.0|      55|\n",
            "+-----------------------------------+----------------------------------+--------+\n",
            "\n",
            "+--------+----------+--------------------+-------------------+-----------------+------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+--------------------+------------------+-----------------+-------------------+------------------+-------------------+--------------------+----------------+------------------+-----------------+-------------------+-------------------+-------------------+--------------------+------------------+-------------------+--------------------+------------------+------------------+------------------+------------------+-----------------+--------------------+-------------------+------------------+--------------------+--------------------+-----------------+-------------------+--------------------+-------------------+-----------------+--------------------+------------------+------------------+-----------------+--------------------+--------------------+--------------------+------------------+-------------------+-----------------+--------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+--------------------+----------------+-----------------+-----------------+-------------------+-------------------+--------------------+------------------+-------------------+------------------+------------------+-------------------+-----------------+----------------+--------------------+-----------------+-------------------+------------------+------------------+-------------------+----------------+-------------------+--------------------+------------------+------------------+--------------------+------------------+------------------+-------------------+-----------------+------------------+--------------------+------------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+------------------+-----------------+-----------------+------------------+------------------+-------------------+------------------+--------------------+-------------------+-------------------+--------------------+----------------+-----------------+--------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+-------------------+------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+----------------+-------------------+-----------------+--------------------+-----------------+--------------------+-------------------+--------------------+--------------------+--------------------+-----------------+------------------+-----------------+-------------------+------------------+------------------+------------------+------------------+--------------------+------------------+-------------------+------------------+--------------------+-----------------+-------------------+-------------------+------------------+-----------------+-------------------+-----------------+-----------------+-------------------+--------------------+--------------------+-------------------+------------------+------------------+------------------+-------------------+--------------------+--------------------+------------------+-------------------+--------------------+-------------------+--------------------+------------------+------------------+-----------------+--------------------+-----------------+-----------------+-----------------+--------------------+-----------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-------------------+-----------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+-----------------+-------------------+-------------------+-----------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-------------------+------------------+-----------------+-----------------+--------------------+------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+-----------------+-----------------+-------------------+--------------------+--------------------+-------------------+------------------+--------------------+-------------------+-----------------+--------------------+----------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+--------------------+-------------------+--------------------+------------------+-----------------+-----------------+--------------------+----------------+------------------+------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+--------------------+-----------------+--------------------+-----------------+-------------------+--------------------+--------------------+--------------------+----------------+-------------------+--------------------+------------------+-------------------+----------------+------------------+------------------+--------------------+-------------------+------------------+----------------+-------------------+-------------------+-----------------+-------------------+-----------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+------------------+-----------------+-------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-----------------+-----------------+--------------------+-----------------+------------------+-------------------+--------------------+--------------------+--------------------+----------------------------------+-----------------------------------+\n",
            "|      ID|  TIME_OBS|           TIME_SPAN|   imp_N_227465_std| imp_N_225625_avg|  imp_N_220179_max|  imp_N_227073_avg|    imp_N_51237_std|     imp_N_220047_TT|     imp_N_51222_LT|  imp_N_220621_min|  imp_N_220181_avg|      imp_N_50960_LT|   imp_N_51006_avg| imp_N_220180_min|    imp_N_223751_LT|  imp_N_227442_avg|   imp_N_220046_std|     imp_N_220181_TT|imp_N_220180_max|   imp_N_50960_min|  imp_N_51222_avg|    imp_N_220046_LT|   imp_N_220228_std|   imp_N_227442_std|      imp_N_50902_TT|   imp_N_51265_min|   imp_N_223761_std|      imp_N_50902_LT|   imp_N_50902_std|   imp_N_50912_avg|   imp_N_51274_max|   imp_N_51248_min| imp_N_227467_max|     imp_N_227073_TT|    imp_N_227465_LT|   imp_N_51237_avg|    imp_N_223769_std|     imp_N_220179_TT| imp_N_223761_min|    imp_N_51301_std|      imp_N_50893_TT|    imp_N_227465_TT| imp_N_220545_min|     imp_N_225664_TT|   imp_N_50902_min|   imp_N_50912_max| imp_N_223761_avg|      imp_N_51301_TT|     imp_N_220180_TT|     imp_N_227442_LT|   imp_N_51006_std|     imp_N_51221_TT|  imp_N_51279_avg|     imp_N_223770_TT| imp_N_220228_max|  imp_N_220179_std|  imp_N_220181_std| imp_N_227442_max|   imp_N_51221_min|  imp_N_220635_avg|      imp_N_50983_TT|imp_N_220546_avg|  imp_N_51250_max| imp_N_220179_min|    imp_N_227466_TT|    imp_N_50971_std|      imp_N_51248_TT|  imp_N_220046_max|   imp_N_227073_std|  imp_N_225677_avg|   imp_N_50960_avg|     imp_N_51221_LT| imp_N_224161_min|imp_N_223769_min|     imp_N_220635_TT| imp_N_220277_max|     imp_N_51277_LT|  imp_N_220615_max|  imp_N_225624_std|    imp_N_51249_std|imp_N_220045_min|    imp_N_227467_TT|    imp_N_220635_std|  imp_N_225624_min|  imp_N_227457_avg|     imp_N_225624_LT|  imp_N_220615_min|   imp_N_50971_max|     imp_N_51006_TT|  imp_N_51265_avg|  imp_N_225624_avg|     imp_N_225624_TT|   imp_N_224162_TT|  imp_N_227465_min|   imp_N_220277_std|     imp_N_50931_LT|     imp_N_51275_LT|   imp_N_51249_max|  imp_N_220602_max|  imp_N_51275_min|  imp_N_225664_avg| imp_N_220545_max|   imp_N_50882_min|     imp_N_220615_TT|     imp_N_220645_TT|  imp_N_225677_max|  imp_N_220179_avg|   imp_N_51279_min|   imp_N_223770_std|   imp_N_51221_max|  imp_N_51274_min|   imp_N_50970_min|     imp_N_220179_LT|  imp_N_224161_max| imp_N_220228_avg| imp_N_225625_max|   imp_N_50902_avg|  imp_N_220545_avg|    imp_N_227467_LT|  imp_N_223751_max|     imp_N_224161_TT|    imp_N_227457_TT|    imp_N_224161_LT|      imp_N_50912_TT|imp_N_220210_max| imp_N_220546_max|      imp_N_50971_LT|      imp_N_50868_TT|     imp_N_50893_std|  imp_N_220181_min|  imp_N_225664_max|  imp_N_50882_max|     imp_N_220181_LT|   imp_N_50912_min|   imp_N_51265_max|      imp_N_50882_TT|  imp_N_220180_avg|  imp_N_50893_max|  imp_N_220045_avg|   imp_N_220045_std|  imp_N_220047_min|   imp_N_226253_TT|  imp_N_220621_max|      imp_N_50971_TT|  imp_N_225664_min| imp_N_224162_max|   imp_N_224162_LT|   imp_N_50931_min|  imp_N_220621_avg|  imp_N_51250_min|  imp_N_225664_std|  imp_N_223769_max|    imp_N_226253_LT|   imp_N_51277_min| imp_N_51301_min|     imp_N_51222_TT| imp_N_226253_avg|     imp_N_51279_std|  imp_N_50893_min|      imp_N_50970_TT|    imp_N_51274_std|     imp_N_220277_TT|      imp_N_50960_TT|     imp_N_50960_std|  imp_N_51221_avg|   imp_N_51277_max| imp_N_225625_min|    imp_N_51277_std|  imp_N_220047_avg|   imp_N_50971_avg|  imp_N_227457_max|   imp_N_50970_max|     imp_N_220602_TT|   imp_N_50931_std|     imp_N_51301_LT|  imp_N_227467_min|     imp_N_220645_LT| imp_N_220277_min|    imp_N_220546_LT|     imp_N_50882_LT|   imp_N_51248_avg|  imp_N_51279_max|   imp_N_220602_std|  imp_N_50893_avg| imp_N_223770_avg|    imp_N_227073_LT|      imp_N_51249_TT|     imp_N_220635_LT|    imp_N_227443_LT|  imp_N_220602_avg|   imp_N_50931_avg|  imp_N_227466_avg|   imp_N_220545_std|     imp_N_227442_TT|     imp_N_220210_TT|  imp_N_224161_std|    imp_N_220228_LT|     imp_N_223761_TT|    imp_N_220545_LT|     imp_N_220046_TT|   imp_N_50983_std|  imp_N_223769_avg| imp_N_227443_min|      imp_N_50931_TT| imp_N_223770_max|  imp_N_51006_min| imp_N_220645_min|      imp_N_51249_LT| imp_N_223761_max|  imp_N_51250_avg|  imp_N_220645_std|   imp_N_51274_avg| imp_N_220635_min|  imp_N_50971_min|   imp_N_51275_avg|  imp_N_227443_avg|    imp_N_227466_LT| imp_N_220635_max|     imp_N_51274_LT|  imp_N_227073_max|     imp_N_220180_LT|  imp_N_227073_min|    imp_N_220602_LT|   imp_N_50931_max| imp_N_227466_max|    imp_N_51222_std|    imp_N_227457_LT| imp_N_227457_std|  imp_N_220180_std|     imp_N_50970_LT|  imp_N_220615_avg|  imp_N_51265_std|   imp_N_50882_std|    imp_N_226253_std|     imp_N_51279_LT|  imp_N_227442_min|  imp_N_220210_std|  imp_N_227443_max|  imp_N_220602_min| imp_N_226253_min|  imp_N_227466_min| imp_N_220546_min|  imp_N_51248_max| imp_N_223752_max|   imp_N_220546_std|  imp_N_227443_std| imp_N_225677_min|  imp_N_50983_min|     imp_N_220277_LT|   imp_N_50868_avg|     imp_N_225677_TT|    imp_N_50868_std|    imp_N_223752_LT|   imp_N_223752_TT|   imp_N_223751_std|    imp_N_220047_LT|  imp_N_51222_min| imp_N_220277_avg|     imp_N_51279_TT|      imp_N_50983_LT|      imp_N_50893_LT|    imp_N_51248_std|  imp_N_223751_min|     imp_N_225625_LT|     imp_N_51250_TT| imp_N_220181_max|      imp_N_51006_LT|imp_N_223752_avg|    imp_N_225677_LT|  imp_N_220046_avg|  imp_N_220047_max|  imp_N_51222_max|   imp_N_225625_std|     imp_N_51265_LT|    imp_N_223752_std|     imp_N_51237_TT|     imp_N_225625_TT|  imp_N_225624_max| imp_N_224161_avg|  imp_N_50983_max|     imp_N_220546_TT| imp_N_51275_max|   imp_N_223769_TT|   imp_N_50882_avg|     imp_N_220621_TT|      imp_N_51248_LT|  imp_N_220046_min|   imp_N_50868_min| imp_N_223752_min|    imp_N_224162_std|     imp_N_227443_TT|  imp_N_51301_max|      imp_N_51277_TT| imp_N_224162_min|    imp_N_223769_LT|      imp_N_51275_TT|     imp_N_223761_LT|     imp_N_225664_LT|imp_N_220210_min|    imp_N_220615_LT|     imp_N_220210_LT|   imp_N_50868_max|    imp_N_220621_LT|imp_N_220228_min|   imp_N_50970_avg|   imp_N_51006_max|    imp_N_227467_std|    imp_N_223770_LT|  imp_N_227465_max|imp_N_220045_max|     imp_N_51274_TT|     imp_N_51237_LT| imp_N_227457_min|     imp_N_50912_LT|  imp_N_51301_avg|   imp_N_51249_min|     imp_N_220045_TT|  imp_N_220621_std|  imp_N_227466_std|     imp_N_220045_LT| imp_N_223751_avg|  imp_N_220645_avg| imp_N_224162_avg|     imp_N_50868_LT|   imp_N_50902_max|     imp_N_50912_std|  imp_N_227465_avg|  imp_N_220645_max|    imp_N_51221_std|  imp_N_227467_avg|  imp_N_220210_avg|  imp_N_51249_avg|     imp_N_51250_LT|    imp_N_220228_TT|   imp_N_51237_min|   imp_N_225677_std|   imp_N_50983_avg|   imp_N_51250_std|   imp_N_223751_TT| imp_N_226253_max|    imp_N_51265_TT|   imp_N_51275_std|    imp_N_50970_std|   imp_N_51237_max|  imp_N_50960_max| imp_N_223770_min|    imp_N_220615_std|  imp_N_51277_avg|  imp_N_220047_std|    imp_N_220545_TT|    features_imputed|        demo_feature|            features|DISCH_51881_51851_51884_51853_excl|DISCH_51881_51851_51884_51853_label|\n",
            "+--------+----------+--------------------+-------------------+-----------------+------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+--------------------+------------------+-----------------+-------------------+------------------+-------------------+--------------------+----------------+------------------+-----------------+-------------------+-------------------+-------------------+--------------------+------------------+-------------------+--------------------+------------------+------------------+------------------+------------------+-----------------+--------------------+-------------------+------------------+--------------------+--------------------+-----------------+-------------------+--------------------+-------------------+-----------------+--------------------+------------------+------------------+-----------------+--------------------+--------------------+--------------------+------------------+-------------------+-----------------+--------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+--------------------+----------------+-----------------+-----------------+-------------------+-------------------+--------------------+------------------+-------------------+------------------+------------------+-------------------+-----------------+----------------+--------------------+-----------------+-------------------+------------------+------------------+-------------------+----------------+-------------------+--------------------+------------------+------------------+--------------------+------------------+------------------+-------------------+-----------------+------------------+--------------------+------------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+------------------+-----------------+-----------------+------------------+------------------+-------------------+------------------+--------------------+-------------------+-------------------+--------------------+----------------+-----------------+--------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+-------------------+------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+----------------+-------------------+-----------------+--------------------+-----------------+--------------------+-------------------+--------------------+--------------------+--------------------+-----------------+------------------+-----------------+-------------------+------------------+------------------+------------------+------------------+--------------------+------------------+-------------------+------------------+--------------------+-----------------+-------------------+-------------------+------------------+-----------------+-------------------+-----------------+-----------------+-------------------+--------------------+--------------------+-------------------+------------------+------------------+------------------+-------------------+--------------------+--------------------+------------------+-------------------+--------------------+-------------------+--------------------+------------------+------------------+-----------------+--------------------+-----------------+-----------------+-----------------+--------------------+-----------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-------------------+-----------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+-----------------+-------------------+-------------------+-----------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-------------------+------------------+-----------------+-----------------+--------------------+------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+-----------------+-----------------+-------------------+--------------------+--------------------+-------------------+------------------+--------------------+-------------------+-----------------+--------------------+----------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+--------------------+-------------------+--------------------+------------------+-----------------+-----------------+--------------------+----------------+------------------+------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+--------------------+-----------------+--------------------+-----------------+-------------------+--------------------+--------------------+--------------------+----------------+-------------------+--------------------+------------------+-------------------+----------------+------------------+------------------+--------------------+-------------------+------------------+----------------+-------------------+-------------------+-----------------+-------------------+-----------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+------------------+-----------------+-------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-----------------+-----------------+--------------------+-----------------+------------------+-------------------+--------------------+--------------------+--------------------+----------------------------------+-----------------------------------+\n",
            "|194216.0|2125-11-06|{2125-11-05 00:00...|0.13065475397959778|8.373489266198279|             122.0|              21.0| 0.0148147169883393| 0.04162341526443389|  0.822296133074232|              99.0| 59.18181818181818| 0.48713427104996304|              44.0|             31.0|  0.426930727592382|              4.75|                0.0|3.344460616693063E-6|            61.0|2.0192751891676624|             11.0|0.38319833098312733|                0.0|0.34999999999999964|  0.8929921841044993|             247.0|  0.698569967862917| 0.44649609205224966|               0.0|               2.4|16.326121062384175|              29.8|1.477589339794065|  0.0472437945735434| 0.4600024796048131|1.4608241195741203|                 0.0|0.021636414557959883|             96.9|                0.0|  0.4720913015670395|0.48651583403086374|             32.5|0.013776209569792777|             103.0|               2.4|             97.7| 0.32535196848662795|3.701415146197403...|  0.9594217588367184|               0.0|0.34673577057587834|             3.69| 0.29305270223556673|             11.0|11.398969599771196| 8.418790474756529|              5.1|              32.5|2.0541336843893307|   0.410331269470417|            13.8|             88.0|             80.0|0.47280115065897854|0.34999999999999964|  0.8115218050505427|             120.0|                0.0| 3.500057344901359| 2.056371584077676| 0.8266321147120608|             35.0|           100.0|  0.4663993967189891|            100.0|0.37402519287996616|               2.4|               0.0|                0.0|            80.0|0.48908889201931066| 0.03418278356819755|              44.0|             247.0|  0.7462139785469515|               2.4|               5.1|0.49611056913408624|            247.0|              44.0|   0.507572042906097|0.9738948671571004|16.087061323618695|  2.413791392993373|0.23945102402941437| 0.4142515026977065|              33.8|             103.0|36.91319672131147|              81.5|             32.5|              16.0|  0.3967122207033206|  0.4104026651917846|3.5965474209650576|105.66666666666667|              3.69|                1.0|              32.5|16.04014206300184|3.4006276150627603|0.010818207278979941|              40.0|             11.0|8.427499999999997|             103.0|              32.5| 0.4584105459263105|160.55733211512106| 0.08942376662488417| 0.6366982370766063| 0.9552881166875579|   0.396622181500598|            36.0|             13.8|  0.9601069217541016|0.044676182560648973|0.051237573780987374|              45.0|              98.0|             16.0|1.672230308346531...|               2.4|             247.0| 0.07903882459641288|41.857142857142854|8.429773195876288| 85.04347826086956| 3.1412855422936423|              60.0| 0.981301814901793|              99.0| 0.07978615649179678|              69.0|              8.0|0.5130525664214498|              99.0|              99.0|             88.0|10.452272480183437|             100.0| 0.4906509074508965|              15.6|            13.8| 0.3554077338515359|             85.0|                 0.0|8.320536082474234|   0.475782102493217|0.12965952398334926|  0.9028918120924412| 0.46459083063785256| 0.03490935761855885|             32.5|              15.6|8.319221311475417|                0.0|              60.0|              4.75|             247.0|3.5946443514644364|  0.8926262369839186|               0.0|  0.837324015756686|1.4457904300423992|  0.2052013325958923|             90.0|  0.829942801955639|0.03951941229820644|              29.8|             3.69|                0.0| 8.37549739813451|             91.0| 0.9763781027132283|  0.7563194810344582|  0.4867469154217031|0.04040852575860842|             103.0|              99.0| 37.70331834880121|                0.0| 0.08115648232656318|2.046613223364066...|               2.5| 0.8185935789393086| 0.37875243857093677| 0.8252217669265924|  0.7663966619662547|               0.0|             100.0|             16.0| 0.47890204805882874|             92.0|             44.0|            136.0|  0.6218402594827709|             98.8|             88.0|               0.0| 16.17945696932262|2.017717003567181|              4.4| 37.83908909055424|              16.0|0.41496732739917513|2.090566785572731| 0.4594330506661511|              21.0|1.850707573098701...|              21.0| 0.4463131184919593|              99.0|38.69393271461717|                0.0| 0.6816508814616968|              0.0| 6.526763321569299|0.47827446509141863|               2.4|              0.0|               0.0|                 0.0| 0.8170095252828056|               4.4| 4.257142690689248|              16.0|             103.0|             85.0|36.781171693735494|             13.8|             29.8|             90.0|                0.0|               0.0|3.405948419301164|            136.0|  0.4514459060462206|              21.0| 0.47673291112742694|                0.0| 0.4784520629105555| 0.956904125821111|0.12368084276523614|  0.979188292367783|             11.0|97.08333333333333|0.36598094943438886|  0.2051656347352085|  0.5084698186832426|                0.0|160.30150753768845|   0.509236331115962| 0.6613725803138346|             88.0|  0.7519447154329568|            90.0|0.47783318356312104|             120.0|              60.0|             11.0|0.05078673178396359| 0.6887212090234709|                 0.0| 0.4884661578947222|  0.4730871389194783|              44.0|             37.5|            136.0|  0.3401143960887222|38.8348594847775|0.9905790501718436|              16.0|  0.4739722956341428| 0.40576090252527136|             120.0|              21.0|             90.0|                 0.0| 0.08081705151721684|             13.8|  0.7480503857599323|              8.0| 0.4952895250859218|  0.4708701645239077| 0.18937621928546838|0.006888104784896388|            19.0| 0.8016438896483398|  0.9999999999998976|              21.0| 0.2369861478170714|            11.0|3.4959720063757715|              44.0|0.014632153041738868| 0.8534736488822167|16.373460837887045|            91.0|0.48486335344055065|0.45745215253325033|            247.0|  0.801688909249701|             13.8|              33.8|  0.9899958614463573|               0.0|0.8705195762144462|  0.5050020692768213|160.4163621135982|             136.0|              8.0| 0.9776619087196755|             103.0|                 0.0|16.227216656547245|             136.0|                0.0|1.4611558651322438|27.708333333333332|             33.8| 0.3306862901569173|0.36281284212138276|1.4453931203931218|0.08957582974112871|             136.0|               0.0|0.7269868524702858|             85.0|0.6225575819530582| 0.876945766580447| 0.0911977288017119|1.4776412776412784|2.093508562325766|             90.0|                 0.0|             15.6|               0.0|0.34955646614681524|[0.50500206927682...|(166,[0,2,10,24,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|170247.0|2156-09-17|{2156-09-16 00:00...|                0.0|              7.6|             183.0|               9.0|                0.0| 0.28527572776766313| 0.5406613435493994|             106.0|101.96774193548387|0.011833359535784821|              67.0|             62.0|  0.426930727592382|               4.5|                0.0|7.158138701118382...|           100.0|               1.4|              9.8| 0.9999999989335262|                0.0|                0.0| 0.01627151171795612|             237.0| 0.7940897382517259|  0.9918642441410219|               0.0|               1.7|              13.5|              34.3|              1.2| 0.18596858204010075|0.24414171259299255|               1.2|                 0.0|1.609251481842640...|             97.4|                0.0| 0.29947514561388683| 0.4882834251859851|             28.0|  0.6606598281630436|             119.0|               1.7|98.81818181818181|  0.3460690443073108|1.536029686690184...|  0.7827139078451968|               0.0| 0.8805470180227488|             2.87|  0.3897484515890689|              9.8| 13.99649190741329| 6.962961322958472|              4.5|              28.0|               1.4| 0.35087588798840197|             5.5|             97.0|            135.0|0.30739925019517594|                0.0|0.029632522710521532|             130.0|                0.0|               2.2|               1.4| 0.4402735090113744|             30.0|           100.0|0.024380599591135567|            100.0| 0.9959521122378114|               1.7|               0.0|                0.0|           106.0| 0.5425671583318119|                 0.0|              67.0|             237.0|  0.9686264786847246|               1.7|               4.5|0.05828922449816895|            237.0|              67.0|  0.0627470426305507|0.9680307246992478|              13.5|0.17668469596940842|0.29625508149420365|0.15244979997487215|              35.2|             119.0|             25.9|             125.0|             28.0|              20.0|  0.8610754681126909| 0.35067089967433296|               2.2|            160.25|              2.87|                0.0|              28.0|             13.5|               2.2|                 1.0|              30.0|              9.8|              7.6|             119.0|              28.0|0.27128357916590595|160.55733211512106| 0.21294704427559902| 0.7058594238009501|0.10647352213779951|  0.8615249073132796|            26.0|              5.5|   0.784103490487847| 0.18687580390398248|                 0.0|              83.0|             125.0|             20.0|                 1.0|               1.7|             237.0| 0.32497846684920384| 84.09677419354838|              7.6|115.44827586206897|  7.341831993947314|              50.0|0.9771005412364924|             106.0|  0.4317930190243059|             125.0|              8.0| 0.515984637650376|             106.0|             106.0|             97.0|               0.0|             100.0| 0.4885502706182462|              21.4|             5.5| 0.9186773129012011|             85.0|                 0.0|              7.6| 0.29246544858222323|                0.0|3.080420971840243...|0.023666719071569642|                 0.0|             28.0|              21.4|              7.6|                0.0|              50.0|               4.5|             237.0|               2.2|0.018135973792017472|               0.0| 0.1730345221536554|               1.2|  0.8246645501628336|             99.0|0.17319706514487687|0.16248923342460192|              34.3|             2.87|                0.0|              7.6|             90.0|0.09298429102005037| 0.23418802728176666|0.012190299795567783|0.16491838546125026|             119.0|             106.0|              25.9|                0.0|  0.4345721843096064| 0.14020870300249205|               0.0| 0.5371771054337386| 0.13464378049702352| 0.4391325987156166|2.132947513209930...|               0.0|             100.0|             20.0|  0.5925101629884073|             90.0|             67.0|            143.0|  0.8829059863591167|             99.9|             97.0|               0.0|              13.5|              1.4|              4.5|              25.9|              20.0|0.15369962509758797|              1.4|0.24367338397664057|               9.0|                 1.0|               9.0| 0.9909320131039913|             106.0|             25.9|                0.0| 0.6470702880995249|              0.0| 7.549214181321329|0.14623272429111162|               1.7|              0.0|               0.0|                 0.0| 0.2551375666840665|               4.5| 3.927543549735336|              20.0|             119.0|             85.0|              25.9|              5.5|             34.3|             90.0|                0.0|               0.0|              2.2|            143.0|   0.999999999845979|               9.0| 0.29175464787459454|                0.0|0.47361569343253623|0.9472313868650725|0.12368084276523614|0.14263786388383157|              9.8|99.96774193548387|  0.510275133368133|   0.824562056005799| 0.14973757280694341|                0.0|160.30150753768845| 0.15209882856419762|0.25898710002865066|            115.0|  0.9708553877509155|            90.0|0.14587732393729727|             130.0|              50.0|              9.8|                0.0| 0.6539715155524461|                 0.0| 0.5418579267502793| 0.30419765712839525|              67.0|             30.0|            143.0| 0.34639413028975374|            25.9|0.9836831939012491|              20.0|  0.5837869351218472|  0.9851837386447392|             130.0|               9.0|             90.0|                 0.0|  0.3298367709225005|              5.5|0.008095775524377038|              8.0|0.49184159695062457|  0.3048995999497443|  0.9326781097514882|  0.3303299140815218|             9.0| 0.5694622659436546| 0.07010435150124603|               9.0| 0.2918934675609236|             9.8|               2.2|              67.0|                 0.0|0.19487422579453445|              13.5|           129.0|0.48734676795328113|0.27092896337513966|            237.0| 0.5692375463433602|              5.5|              35.2|4.086259906247097...|               0.0|               0.0|                 1.0|160.4163621135982|             143.0|              8.0|0.09343790195199124|             119.0|                 0.0|              13.5|             143.0|                0.0|               1.2|18.161290322580644|             35.2| 0.8705064499856747| 0.9256457891325227|               1.2|                0.0|             143.0|               0.0|0.7269868524702858|             85.0|0.6920569688951076|               0.0|                0.0|               1.2|              1.4|             90.0|                 0.0|             21.4|               0.0| 0.8782651974312332|[1.0,4.0862599062...|(166,[0,2,10,14,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|147237.0|2152-06-13|{2152-06-12 00:00...|0.13065475397959778|8.373489266198279|138.94057916509965|              14.0| 0.0148147169883393|  0.1307658700463204|0.21520733780176288|             137.0| 74.77826247362239| 0.15182595654905978|              25.0|47.70463975858167|  0.426930727592382|               3.3|                0.0| 0.20718381381747253|78.0369671821954|               1.8|              8.5| 0.3034253128759712|                0.0|0.19999999999999996|0.028973530463161454|              73.0| 0.6693695209341091|  0.9855132347684192|               1.5|0.8500000000000001|16.326121062384175|              29.7|1.477589339794065|  0.9376499263725233| 0.4600024796048131|1.4608241195741203|                 0.0| 0.19619776364057873|             97.6|0.15238186232786088|  0.4720913015670395|0.48651583403086374|             26.5| 0.09795046655748423|             112.0|               0.9|98.41666666666664| 0.48196839886325465| 0.22323189276593913|0.024816956684938937|               1.0| 0.6072360034596276|             2.88| 0.22387339796893174|              8.5|11.487286830973543| 8.168515431713185|              3.5|              26.5|              1.85| 0.01685323535158738|9.43330216554195|             92.0|97.67732230161715|0.47280115065897854|0.19999999999999996|  0.7702010812541695|             120.0|                1.0|               2.8|              1.85| 0.3036180017298138|             30.0|           100.0| 0.30758219718721563|             94.0| 0.5757262206174368|               0.9|               1.0|                0.0|            95.0|0.48908889201931066| 0.04999999999999993|              24.0|              73.0| 0.32156666893000085|               0.8|               3.5| 0.6491979601525262|             73.0|              25.0|  0.6431333378600017|0.9548007145431963|16.087061323618695| 0.7347996703561833| 0.9558960208725681| 0.4142515026977065|              32.2|             115.0|36.91319672131147|             194.5|             26.5|              22.0| 0.36420341314945426|0.016817406602936857|               3.3|117.87633609613528|              2.88|                0.0|              26.5|16.04014206300184|               2.3|   0.472376144412589|              30.0|              8.5|8.427499999999997|             113.5|              26.5| 0.4584105459263105|160.55733211512106| 0.07818588218629802|0.23846468547719551|0.03909294109314901|  0.3631110187958403|            25.0|9.599003202562052| 0.02486546126526223|  0.9248097092647306|0.051237573780987374|60.782215523737754|             238.0|             23.0|  0.4711329744042347|               0.8|              73.0| 0.47805789584179803| 61.39591571522619|8.429773195876288|105.04761904761905|    8.5494427023954|              50.0|0.9676197184512532|             216.0| 0.04973092253052446|             141.0|              8.0|0.5225996427284019|             137.0|             176.5|             92.0|44.070965498840614|             100.0| 0.4838098592256266|              16.6|9.21408502024291|0.43041467560352575|             85.0|                 0.0|8.320536082474234| 0.43104644624894695|0.12965952398334926|3.131740115426275...| 0.30365191309811956| 0.04999999999999993|             26.5|              16.6|8.319221311475417|                0.0|              50.0|               3.3|              73.0|               3.3| 0.03182393228038295|              39.5| 0.4686834829104542|1.4457904300423992|  0.9915912966985315|             91.0|0.46784589154325545|0.23902894792089902|              29.7|             2.88|                1.5| 8.37549739813451|             90.0| 0.5311750368137383|  0.4872208418737004| 0.15379109859360782|0.24322836380550494|             113.5|             176.5| 37.70331834880121|                0.0| 0.04963391336987787| 4.84366912903392E-7|               0.0|0.21434056415542796|   0.717352974274486|0.30290980149227265|  0.6068506257519424|               1.5|             100.0|             22.0|  0.0882079582548639|             90.0|             24.0|            145.0|  0.2436104209368502|             99.4|             92.0|               1.5| 16.17945696932262|              1.8|              3.1| 37.83908909055424|              22.5|0.41496732739917513|              1.9| 0.4594330506661511|              15.0| 0.48581197505212126|              13.0| 0.9840880338598085|             216.0|38.69393271461717|                0.0|0.11923234273859776|              0.0| 8.132272964076716|0.21552322312447347|0.8500000000000001|              0.0|               0.5|                 0.0|0.26129564579518694|               3.1|3.4797124072974768|              23.0|             112.0|             85.0|36.781171693735494|9.271773418734984|             29.7|90.01611459265891|0.15403168443235046|               0.5|              2.3|            145.0|1.565870057713137...|              14.0|   0.428761110931966|                1.0|0.48009629871768866|0.9530305562536405|0.12368084276523614| 0.0653829350231602|              8.5|92.70833333333333| 0.5225912915903739|  0.9915733823242063|  0.5084698186832426|                0.0|160.30150753768845|   0.509236331115962| 0.7961109513546751|90.91899020346646|  0.3245989800762631|90.0066025067144|  0.214380555465983|             120.0|              50.0|              8.5|0.05078673178396359|  0.118808854935446|0.007491553859143...| 0.4884661578947222|  0.4730871389194783|              26.0|             30.0|            148.0|  0.4838445299068336|38.8348594847775|0.9769261585915691|              22.5| 0.10519204155559324| 0.38510054062708476|             120.0|              13.0|90.00044762757386|                 0.0|  0.4864567276110099|9.539477732793522|  0.8485475587651263|              8.0|0.48846307929578453|  0.4708701645239077|   0.641323512862757|  0.9510247667212579|            11.0|0.18210170657472713| 2.42183456451696E-7|              15.0| 0.9474039792222034|             8.5|               2.8|              26.0|0.014632153041738868|0.11193669898446587|16.373460837887045|           129.0|0.48486335344055065|0.45745215253325033|             73.0|0.18155550939792015|9.375520512820508|              32.2|1.372982874381969...|              39.5|0.8705195762144462|  0.9999999931350856|160.4163621135982|             146.5|              8.0| 0.5375951453676346|             115.0| 0.04999999999999999|16.227216656547245|             148.0|                0.0|1.4611558651322438|          14.78125|             32.2| 0.6019445243226624| 0.4286811283108559|1.4453931203931218|                0.5|             146.5|               0.0|0.7269868524702858|             85.0| 0.237617709870892| 0.876945766580447|                0.5|1.4776412776412784|              1.9|             90.0| 0.04999999999999999|             16.6|               0.0| 0.6058196029845453|[0.99999999313508...|(166,[0,1,10,14,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|133334.0|2118-03-08|{2118-03-07 00:00...|0.13065475397959778|              7.9|             130.0|              10.0| 0.0148147169883393| 0.21726593295394925| 0.7844044716975123|120.72483482316362| 77.82352941176471| 0.02733498597551311|               7.0|             48.0|   0.34133654226967|               4.0|                0.0| 0.30839532728896574|            76.0|               1.5|             10.8| 0.2761968333658741|                0.0|                0.0|  0.4928966794412242|             346.0| 0.5309190145398796|  0.7535516602793879|               0.0|               0.6|16.326121062384175|              29.2|1.477589339794065| 0.29507167004013984| 0.4600024796048131|1.4608241195741203|                 0.0|  0.9582276156665239|             97.7|                0.0|  0.5349205497187735|0.48651583403086374|             31.0|  0.3106337935266384|             108.0|               0.6|98.32499999999999|  0.4920567192256863| 0.37977789106483206|   0.451174902920182|               0.0| 0.5637892614098574|             3.69|  0.6194900007990161|             10.8| 8.092241654819757|7.9501039143608025|              4.0|              31.0|               1.5|  0.8813192766007132|             6.6|             84.0|            100.0|0.47280115065897854|                0.0|   0.575242294926473|             120.0|                0.0|               3.2|               1.5| 0.7181053692950713|             30.0|           100.0| 0.05596626020121088|             98.0| 0.1069334973417493|               0.6|               0.0|                0.0|            68.0|0.48908889201931066|                 0.0|               7.0|             346.0| 0.10282078410895883|               0.6|               4.0|0.20370663412382425|            346.0|               7.0| 0.20564156821791765|0.9630883535824493|16.087061323618695|  1.193987242952026|0.46314413213559713| 0.4142515026977065|              34.8|             108.0|36.91319672131147|             124.2|             31.0|              24.0|  0.3778842821632221|  0.8814588626735432|               3.2|           117.625|              3.69|                0.0|              31.0|16.04014206300184|               3.2|   0.520886192166738|              30.0|             10.8|              7.9|             108.0|              31.0| 0.4584105459263105|             160.0| 0.15038969889535822| 0.1580548588378559|0.07519484944767911|  0.3769522229544192|            24.0|              6.6|   0.452366173438544| 0.29713399209107455|                 0.0|              63.0|             211.0|             24.0|  0.8458023363555172|               0.6|             346.0|    0.83206748784093|           64.0625|              7.9| 80.05882352941177|  7.665588410209647|              50.0| 0.986777781674111|132.22386319471434|   0.904732346877088|              64.0|              8.0|0.5184558232087754|120.49256068911511|126.38537745451853|             84.0|58.982709330786086|             100.0| 0.4933888908370555|              13.8|             6.6| 0.4311910566049755|             85.0|                 0.0|              7.9|  0.8210842804217541|0.12965952398334926|0.007596372437944598| 0.05466997195102622|                 0.0|             31.0|              13.8|              7.9|                0.0|              50.0|               4.0|             346.0|               3.2|  0.5009539544603356| 4.798857346195361|0.24602835961284314|1.4457904300423992|  0.4407294313367716|             94.0|0.24496790674135016|  0.416033743920465|              29.2|             3.69|                0.0|              7.9|             90.0|0.14753583502006992|  0.3480216600444367| 0.02798313010060544|  0.419681718607656|             108.0|125.57075735540884| 37.70331834880121|                0.0|   0.902349805840364|  0.6253187239414137|               0.0| 0.7805093914544836|  0.8751887286410178| 0.7165414961095931|  0.5523936667317482|               0.0|             100.0|             24.0|  0.4831275084671001|             90.0|              7.0|            138.0|  0.8259891699777817|             99.1|             84.0|               0.0| 16.17945696932262|              1.5|              4.0| 37.83908909055424|              24.0|0.41496732739917513|              1.5| 0.4594330506661511|              10.0|   0.810111054467584|              10.0| 0.7495230227698322|130.73140172278778|38.69393271461717|                0.0| 0.9209725705810721|              0.0| 8.863328593141517|0.41054214021087704|               0.6|              0.0|               0.0|                 0.0| 0.8170095252828056|               4.0| 2.389423060187047|              24.0|             108.0|             85.0|36.781171693735494|              6.6|             29.2|             90.0|                0.0|               0.0|              3.2|            138.0|0.003798186218972299|              10.0|  0.8183048093200608|                0.0| 0.4695414356305627|0.9390828712611254|                0.0|0.10863296647697462|             10.8|95.52941176470588|0.36598094943438886|  0.4406596383003566|  0.2674602748593867|                0.0|             160.0|  0.2701445617849606| 0.2566583497865871|             90.0| 0.10185331706191213|            90.0| 0.4091524046600304|             120.0|              50.0|             10.8|                0.0| 0.9256414008647591|                 0.0| 0.4884661578947222|  0.5402891235699212|               7.0|             30.0|            138.0|  0.4899358134827003|38.8348594847775|0.9905790501718436|              24.0| 0.47954800041801254|  0.2876211474632365|             120.0|              10.0|             90.0|                 0.0|   0.839363437215312|              6.6|  0.2138669946834986|              8.0| 0.4952895250859218|  0.4708701645239077|  0.5624056356794911|  0.1553168967633192|            15.0|0.18894214108161106|  0.6873406380292931|              10.0| 0.4602773778694809|            10.8|               3.2|               7.0|0.014632153041738868|0.30974500039950803|16.373460837887045|            93.0|0.48486335344055065|0.45745215253325033|            346.0| 0.1884761114772096|              6.6|              34.8| 0.20788857398461924| 5.296645179203497|0.8705195762144462| 0.10394428699230962|            160.0|             138.0|              8.0|0.14856699604553728|             108.0|                 0.0|16.227216656547245|             138.0|                0.0|1.4611558651322438|20.235294117647058|             34.8|0.12832917489329354| 0.4389812170910329|1.4453931203931218|                0.0|             138.0|               0.0|  0.68267308453934|             85.0|0.1487171982704818| 0.876945766580447|                0.0|1.4776412776412784|              1.5|             90.0|                 0.0|             13.8|               0.0|  0.566917007780814|[0.10394428699230...|(166,[0,1,10,47,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|132067.0|2192-08-17|{2192-08-16 00:00...|                0.0|              9.5|             150.0|              20.0|                0.0|   0.382950425126365|  0.594492698538468|             110.0| 60.04761904761905|  0.8748530082093486|              45.0|             20.0|0.38626031753797635|               5.7|                0.0|1.890550374929288...|            78.0|               2.4|             10.0| 0.3371881483049508|                0.0|                0.0|  0.7088611790207303|             110.0| 0.4307615994440024|  0.6455694104896348|               0.0|1.4766575863383713|              18.2|              29.6|              1.7|   0.087511800672559| 0.6921947410875489|               1.7|                 0.0|  0.4733443794969092|             97.5|                0.0| 0.10876649212580644| 0.6156105178249022|             33.0|  0.3541999939324101|             106.0|1.5093973872734954|98.06666666666666| 0.38285721985430965|3.112222802167523...|  0.9984102233791884|               0.0|0.28815855141697755|             3.36|  0.4825208223441543|             10.0| 20.77241092303817| 15.64022953940739|              5.7|              33.0|               2.4| 0.35087588798840197|             5.8|             98.0|             68.0| 0.8628161443655887|                0.0|   0.729523003445461|             120.0|                0.0|               6.0|               2.4| 0.8559207242915112|             30.0|           100.0|  0.2506597246041944|            100.0| 0.6348119296991764|1.5046424090338784|               0.0|                0.0|            55.0| 0.5723090162781292|                 0.0|              45.0|             110.0|  0.7626143750957406|1.4406106231702211|               5.7| 0.4633331092563753|            110.0|              45.0|  0.4747712498085189|0.9815392365222636|              18.2|  1.257615689398881| 0.3312668735370495| 0.4268040256995427|              30.2|             106.0|             37.6|128.33333333333334|             33.0|              23.0|  0.4538385136849273| 0.35067089967433296|               6.0|113.91666666666667|              3.36|                0.0|              33.0|             18.2|               6.0|  0.2366721897484546|              30.0|             10.0|              9.5|             106.0|              33.0| 0.7138454918609354|             160.0|  0.4720685067091678| 0.4077968202829154| 0.2360342533545839| 0.45197895889384554|            22.0|              5.8|   0.998455237808071| 0.08353735150716596|                 0.0|              36.0|             155.0|             23.0|9.452751874646441E-6|1.4444584913611462|             110.0|  0.6853902501202309| 41.76190476190476|              9.5| 63.47826086956522|  3.763319131892591|              50.0| 0.981301814901793|             110.0|0.003089524383857...|             104.0|              8.0|0.5092303817388681|             110.0|             110.0|             98.0|17.801373230424918|             100.0| 0.4906509074508965|              16.9|             5.8| 0.8110146029230639|             85.0|                 0.0|              9.5| 0.03681121099106828|                0.0|5.156248157823244E-5| 0.25029398358130267|                 0.0|             33.0|              16.9|              9.5|                0.0|              50.0|               5.7|             110.0|               6.0|  0.7146464602556497|               0.0|0.19142860992715482|               1.7|  0.8246645501628336|             95.0|0.19130401083875476|0.34269512506011546|              29.6|             3.36|                0.0|              9.5|             90.0| 0.9562440996637205| 0.05110967858325768|  0.8746701376979028| 0.3461807922670562|             106.0|             110.0|              37.6|                0.0|0.003179553241623224|1.787203185250128E-8|               0.0| 0.5907398170442795|  0.7751134558568352| 0.8546053952999496|  0.6743762966099016|               0.0|             100.0|             23.0|   0.662533747074099|             90.0|             45.0|            143.0| 0.02555483929162884|             98.8|             98.0|               0.0|              18.2|              2.4|              5.7|              37.6|              23.0|0.43140807218279437|              2.4|  0.696496704276339|              20.0|1.556111401083761...|              20.0| 0.6426767698721751|             110.0|             37.6|                0.0| 0.2038984101414577|              0.0|14.703108715359878| 0.9815943945044658|1.4724647487602325|              0.0|               0.0|                 0.0| 0.6084436466379373|               5.7| 3.660743321603779|              23.0|             106.0|             85.0|              37.6|              5.8|             29.6|             90.0|                0.0|               0.0|              6.0|            143.0|  0.9999742187592109|              20.0| 0.03765218240540189|                0.0| 0.4784520629105555| 0.956904125821111|                0.0| 0.1914752125631825|             10.0|99.20833333333333| 0.7831127067241254|   0.824562056005799|  0.9456167539370968|                0.0|             160.0|  0.9453660969317313|0.19263200419169912|            112.0|  0.7683334453718124|            90.0|  0.981173908797299|             120.0|              50.0|             10.0|                0.0|0.20462301216897005|                 0.0| 0.5766368313274335| 0.10926780613653737|              45.0|             30.0|            143.0|  0.3826080216775095|            37.6|0.9866770743020669|              23.0|  0.6514403098293393|  0.3647615017227305|             120.0|              20.0|             90.0|                 0.0|  0.6923615845341125|              5.8|  0.7303761406016471|              8.0|0.49333853715103343|  0.8536080513990854|  0.3875567279284176| 0.17709999696620504|             7.0| 0.4335548314340772| 8.93601592625064E-9|              20.0|0.32572015491466966|            10.0|               6.0|              45.0|                 0.0|0.24126041117207714|              18.2|            74.0| 0.6070065914473219| 0.7116815843362833|            110.0| 0.4343233352150944|              5.8|              30.2|1.788692612164041...|               0.0|               0.0|8.943463060820205...|            160.0|             143.0|              8.0|  0.958231324246417|             106.0|  0.0302482200664027|              18.2|             143.0|                0.0|               1.7|            13.375|             30.2| 0.9036839979041504| 0.8185203659114411|               1.7|                0.0|             143.0|               0.0|0.7725206350759527|             85.0|0.4092460243379401|               0.0|                0.0|               1.7|              2.4|             90.0|0.029776204513543382|             16.9|               0.0| 0.2907892094001008|[8.94346306082020...|(166,[0,1,10,14,5...|(514,[0,1,2,3,4,5...|                               1.0|                                0.0|\n",
            "|160561.0|2142-08-21|{2142-08-20 00:00...|                0.0|              8.3|138.94057916509965|              11.0|                0.0| 0.04162341526443389| 0.4049927972222716|             117.0| 74.77826247362239| 0.41470501562248785|              18.0|47.70463975858167|  0.426930727592382|3.5250000000000004|                2.5| 0.20718381381747253|78.0369671821954|               2.0|              9.3| 0.8182224138364953|                0.0| 0.3418698582794335|  0.3315501678565399|             327.0| 0.6039223643997806| 0.16577508392826995|2.0615528128088303|               0.6|              12.4|              29.2|              1.1| 0.44041539336489754|0.16535095388854582|               1.1|                 0.0| 0.19619776364057873|             97.8|                0.0|  0.9486646067167785|0.33070190777709163|             26.9|  0.6344653497933412|              99.0|               0.6|98.78333333333332|  0.8780959765512513| 0.22323189276593913|0.024851369957896306|               0.0| 0.6766599116391201|              3.2|0.005037189085355657|              9.3|11.487286830973543| 8.168515431713185|              4.0|              26.9|               2.0|3.964026174873484...|             8.9|             84.0|97.67732230161715| 0.5290971303958827| 0.3418698582794335|   0.575242294926473|             125.0|                0.0|               2.9|               2.0|0.33832995581956005|             35.0|           100.0|  0.8325609870254145|             97.0| 0.3935826055075569|               0.6|               0.0|                0.0|            78.0| 0.3988801527810958|                 0.0|              18.0|             327.0| 0.24433171174814533|               0.6|               4.0| 0.4896311250315337|            327.0|              18.0| 0.48866342349629066|0.9738948671571004|              12.4|  1.165922381636102| 0.3960667509725702| 0.2618524192518651|              34.7|             104.0|             31.3|             123.0|             26.9|              24.0|  0.3778842821632221|3.959275852023523E-4|               2.9|117.87633609613528|               3.2|                0.0|              26.9|             12.4|               2.9|   0.472376144412589|              35.0|              9.3|              8.3|             100.5|              26.9| 0.1994400763905479|160.55733211512106| 0.42752968906694533|0.21817299261840692| 0.7862351554665273|  0.3769522229544192|            20.0|              8.9|0.025010834787842242| 0.44409857365799355|                 0.0|60.782215523737754|             123.0|             24.0|  0.4711329744042347|               0.6|             327.0|    0.83206748784093| 61.39591571522619|              8.3| 99.16666666666667| 12.572014777097406|              60.0| 0.986777781674111|             117.0|0.050021669575684484|             123.0|              8.0|0.5130525664214498|             117.0|             117.0|             84.0|               0.0|             100.0| 0.4933888908370555|              15.7|             8.9| 0.8099855944445432|             85.0|                 0.0|              8.3|  0.6353988240798489|                0.0|7.327278774037015E-5|  0.8294100312449757|                 0.0|             26.9|              15.7|              8.3|                0.0|              60.0|3.5250000000000004|             327.0|               2.9| 0.33742689451695695|               0.0|0.43904798827562563|               1.1|1.979637926011761...|             93.0| 0.4344216204281218|  0.416033743920465|              29.2|              3.2| 2.0615528128088303|              8.3|             92.0|0.22020769668244877| 0.38123253524434286| 0.41628049351270724|  0.419681718607656|             100.5|             117.0|              31.3|                0.0| 0.04970273991579261|0.001293770387052...|               0.0| 0.4024593678809968|  0.2980994338137761|0.33750459298105906|  0.3635551723270093|1.8027756377319946|             100.0|             24.0|  0.7921335019451404|             92.0|             18.0|            128.0|  0.8093837323778286|             99.8|             84.0|1.8027756377319946|              12.4|              2.0|              3.2|              31.3|              24.0|0.26454856519794134|              2.0|0.16418215675110087|              11.0| 0.48581197505212126|              11.0|0.16871344725847848|             117.0|             31.3|                0.0| 0.8909135036907966|              0.0| 8.132272964076716|0.31769941203992447|               0.6|              0.0|               0.0|                 0.0| 0.4881873346355987|               3.2| 1.790697412245358|              24.0|              99.0|             85.0|              31.3|              8.9|             29.2|90.01611459265891|                0.0|               0.0|              2.9|            128.0|3.663639387018507...|              11.0|  0.6332838797950224|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.979188292367783|              9.3|           95.125| 0.9763746692711974|1.982013087436742...|  0.4743323033583893|                0.0|160.30150753768845| 0.47653626657293524| 0.2566583497865871|90.91899020346646| 0.24481556251576686|90.0066025067144| 0.3166419398975112|             122.5|              60.0|              9.3|                0.0| 0.8964234864027955|0.007491553859143...|0.39887236892500944|  0.9530725331458705|              18.0|             35.0|            133.0|  0.8688432408562436|            31.3|0.9866770743020669|              24.0|  0.7767286700672127|  0.2876211474632365|             120.0|              11.0|90.00044762757386|                 0.0|   0.839363437215312|              8.9|  0.7871652110151138|              8.0|0.49333853715103343|  0.5237048385037302|  0.8509502830931119|  0.3172326748966706|            12.0|0.18894214108161106|6.468851935260766E-4|              11.0|0.38836433503360634|             9.3|               2.9|              18.0|                 0.0| 0.9974814054573222|              12.4|           128.0|0.32836431350220174|0.19943618446250472|            327.0| 0.1884761114772096|              8.9|              34.7|1.800556783332397E-5|               0.0|               0.0|  0.9999909972160833|160.4163621135982|             130.5|              8.0|0.22204928682899677|             104.0|                 0.0|              12.4|             133.0|                0.0|               1.1|16.041666666666668|             34.7|0.12832917489329354| 0.8049187357619936|               1.1|                0.0|             130.5|               0.0|0.7269868524702858|             85.0|0.2071530271944091|               0.0|                0.0|               1.1|              2.0|             92.0|                 0.0|             15.7|               0.0| 0.6750091859621181|[0.99999099721608...|(166,[0,2,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|148585.0|2126-10-28|{2126-10-27 00:00...| 0.5557777333511025|8.833333333333334|138.94057916509965|18.666666666666668|0.08164965809277258|   0.382950425126365| 0.7946170658031151|             123.0| 74.77826247362239|  0.2842646806247229|37.333333333333336|47.70463975858167|  0.426930727592382|               4.3|                0.0| 0.20718381381747253|78.0369671821954|               1.9|             10.5| 0.3371881483049508|0.40000000000000036|0.14142135623730984|0.025230879745253044|             201.0| 0.3391164991562619|0.012615439872626522| 1.247219128924647|1.4766575863383713|              19.2|              29.8|              1.8|0.020199910827945724|  0.834554271316777|1.7000000000000002|                 0.0| 0.19619776364057873|             99.2| 1.1999999999999993| 0.24095952735787052| 0.3308914573664461|             29.2|  0.7303485059488729|              94.0|1.5093973872734954|             99.7|0.003375049439258...| 0.22323189276593913|  0.7663983556666206|5.2493385826745405| 0.3242730396289095|             3.45|  0.6194900007990161|             10.9|11.487286830973543| 8.168515431713185|              4.4|              29.2|1.9666666666666668|  0.6110960548731599|            18.5|             93.0|97.67732230161715|0.42776926948456995|0.14142135623730984|  0.8462865200595537|             120.0| 1.8856180831641267| 5.966666666666666|1.9666666666666668| 0.8378634801855452|             30.0|           100.0|  0.5737684010378854|             99.0| 0.9004275331707398|1.5046424090338784|5.2493385826745405|                0.5|            77.0|0.32810881235106526| 0.04714045207910321|              30.0|             204.5|  0.7074284265822608|1.4406106231702211|               4.4| 0.5688448429895496|            204.5|37.333333333333336|  0.5851431468354783|0.9738948671571004|              17.9| 1.4043582955293932| 0.6176257926325177| 0.2090922946300331|              33.5|              97.0|             32.6|             168.0|             32.6|              26.0|  0.4538385136849273|  0.6112752259265097|               6.0|117.87633609613528|              3.39|                0.0|              32.6|             17.9|               5.9|   0.472376144412589|              30.0|             10.5|              9.5| 95.33333333333333| 30.96666666666667| 0.8359455938244673|160.55733211512106|  0.3091690311323449| 0.9222677065797455|0.15458451556617245| 0.45197895889384554|            29.0|             19.7|  0.7685384383228415|0.018452099986626107|  0.4714045207910317|60.782215523737754|             168.0|             29.0|  0.4711329744042347|1.4444584913611462|             208.0| 0.45483470114596347| 61.39591571522619|              9.5| 89.29166666666667|  7.328478506635755|              50.0| 0.981301814901793|             141.0| 0.46292312335431707|             168.0|              8.0|0.5130525664214498|             123.0|134.66666666666666|             92.0|               0.0|             100.0| 0.4906509074508965|              18.0|            17.3|0.41076586839376994|             85.0| 0.05999999999999983|              8.5|3.618573243979420...| 0.5557777333511024| 0.34732354177834524|  0.5685293612494458|0.047140452079103216|30.96666666666667|              18.0|              8.5|                0.0|              50.0|               4.3|             208.0|               6.0| 0.02741637913844324| 8.259674462242577| 0.9983124752803709|               1.6| 0.30563761296325487|             95.0| 0.9979178419404058| 0.7725826494270183|              30.5|             3.51|  1.247219128924647|8.833333333333334|             90.0| 0.9899000445860271|  0.7857485492233416|  0.2868842005189427| 0.7772222094296404| 95.33333333333333|134.66666666666666|33.666666666666664|  1.391242450313948| 0.46720328866675875|  0.6165986461641741|               0.0| 0.7897970943261818|0.001578621568323...| 0.8358984681272682|  0.6743762966099016|0.9428090415820634|             100.0|             26.0|  0.7647484147349647|             90.0|             30.0|            136.0|  0.3928742746116708|            100.3|             92.5|0.9428090415820634|18.433333333333334|              1.9|              4.1|33.666666666666664|27.333333333333332|0.21388463474228497|              2.0|  0.840070784178116|              20.0| 0.48581197505212126|              16.0|0.01370818956922162|             141.0|             34.6|0.40000000000000036| 0.5388661467101272|              3.5| 8.132272964076716|  0.999819071337801|1.4724647487602325|              3.5| 1.247219128924647|                 0.0| 0.7362400908500616|               4.1| 4.015378424120059|              29.0|              94.0|             85.0|              32.6|             17.3|             31.2|90.01611459265891| 1.1999999999999993| 1.247219128924647|              5.9|            136.0| 0.17366177088917262|18.666666666666668|3.843434816572716E-4| 1.8856180831641267|0.48009629871768866|0.9530305562536405|0.12368084276523614| 0.1914752125631825|             10.1|96.66666666666667| 0.5275198182998768| 0.30554802743657994|  0.8795202363210648| 0.6999999999999993|160.30150753768845|  0.8802365256110225| 0.6251879141399462|90.91899020346646|  0.7155775785052252|90.0066025067144| 0.9998078282591714|             120.0|              50.0|             10.9| 0.4714045207910317| 0.5470139847168616|0.007491553859143...|0.33357762131743696| 0.23952694877795497|              42.0|             30.0|            138.0| 0.00416431611918833|            34.6|0.9866770743020669|27.333333333333332|  0.8072343432351455|  0.5768567399702231|             120.0|              16.0|90.00044762757386|                 0.0| 0.44555558114071914|             19.7| 0.19914493365852057|              8.0|0.49333853715103343|  0.4181845892600662|  0.9992106892158382|  0.6348257470255636|            13.0| 0.4335548314340772|  0.3082993230820871|              20.0| 0.5963828283824273|            10.1| 5.966666666666666|              42.0| 0.08164965809277258|0.30974500039950803|              19.2|           107.0| 0.3198584316437681| 0.8332111893412815|            201.0| 0.4343233352150944|             18.5|              32.5| 0.19394083989654207| 8.259674462242577|0.8219218670625299|   0.903029580051729|160.4163621135982|137.33333333333334|              8.0|  0.990773950006687|              97.0|  0.0302482200664027|18.433333333333334|             138.0|  1.391242450313948|               1.7|19.041666666666668|             33.0| 0.6874060429300268| 0.4204058113476362|               1.6|  0.047140452079103|137.33333333333334|               0.5|0.7269868524702858|             85.0|0.9059720305662767|0.8219218670625299|  0.047140452079103|               1.8|              2.0|             90.0|0.029776204513543382|             18.0|               0.0| 0.3282030637454636|[0.90302958005172...|(166,[0,2,10,13,5...|[0.90302958005172...|                               0.0|                                1.0|\n",
            "|165242.0|2175-01-19|{2175-01-18 00:00...|                0.0|              9.1|138.94057916509965|              15.0|                0.0| 0.21726593295394925| 0.8039053867579353|              97.0| 74.77826247362239|  0.8164491986350839| 30.34493907672786|47.70463975858167|0.38626031753797635|              3.45|                0.0| 0.20718381381747253|78.0369671821954|               2.2|             10.9| 0.2761968333658741|                0.0|               0.25|  0.8440108095101704|             128.0| 0.5314132102234557|  0.5779945952449148|               0.5|              2.75|              16.3|              30.0|              1.5|  0.6398032789348693| 0.5075555782973176|               1.5|                 0.0| 0.19619776364057873|             96.7|                0.0| 0.29471885349913585| 0.9848888434053649|             31.4| 0.41545845588492925|             104.0|               2.8|            97.66|  0.6160700940303655| 0.22323189276593913|0.057085243342856876|0.7100483349760915|0.25343492096709586|             3.63|  0.3206524691616188|             10.9|11.487286830973543| 8.168515431713185|              3.7|              31.4|              2.25|  0.4794734999816147|             7.4|             90.0|97.67732230161715| 0.7434329890031635|               0.25|  0.8956446710242635|             120.0|                2.0|               4.7|              2.25| 0.8732825395164521|             35.0|           100.0| 0.36638060759102997|            100.0| 0.3935826055075569|               2.8|               0.0|                0.0|            60.0|  0.924140058910544| 0.04999999999999982|              89.0|             128.0|  0.9986777943420719|               2.7|               3.7|0.43250070550679126|            128.0|              89.0|0.002644411315856...|0.9630883535824493|              16.3| 1.7564356414542746|0.36120983522411454| 0.6223996683956413|              33.4|             105.0|             44.5|151.38370222803474|             32.5|              23.0| 0.09415802965877565| 0.47920205019697537|               4.7|117.87633609613528|              3.63|                0.0|              32.5|             16.3|               4.7|   0.472376144412589|              35.0|             10.9|              9.1|             104.5|             31.95|  0.537929970544728|             160.0| 0.26184166554512145| 0.5111966203433471| 0.8690791672274393| 0.09401153539639512|            25.0|              7.4| 0.05726491734854485|  0.6265517303751333|                 0.0|60.782215523737754|178.49948822927328|             27.0|  0.4711329744042347|               2.7|             128.0|  0.9785866066324402| 61.39591571522619|              9.1| 60.04347826086956|0.20393111999232302|              50.0|0.9735591921327245|             138.0|  0.1145298346970897|127.71084953940634|              8.0|0.5184558232087754|              97.0|             117.5|             90.0| 19.70452579251507|             100.0|0.48677959606636223|              15.7|             7.4|0.39218922648412924|             85.0|                 0.0|              9.1|  0.3106952740846647|                0.0|2.659708650471714E-4| 0.36710160272983217| 0.04999999999999982|            31.95|              15.7|              9.1|                0.0|              50.0|              3.45|             128.0|               4.7|  0.8484903578968401|              20.5|0.30803504701518275|               1.5|  0.7603989749015123|             92.0| 0.3058282609166615| 0.4892933033162201|              30.0|             3.63|                0.5|              9.1|             90.0| 0.6800983605325653|  0.9529126020201582|  0.8168096962044851|0.49449347247769315|             104.5|             117.5|              44.5| 0.5500000000000007| 0.11417048668571375|  0.7092154158266986|               0.0| 0.8000968958120739| 0.34324109254002433| 0.8717561544517125|  0.5523936667317482|               0.0|             100.0|             23.0|  0.7224196704482291|             90.0|29.59090909090909|            141.0|  0.5235436989899209|             98.3|             90.0|               0.0|              16.3|              2.2|              3.2|              44.5|              25.0| 0.6282835054984183|              2.3| 0.5102304101033464|              17.0| 0.48581197505212126|              13.0| 0.5757548210515799|             138.0|             44.5|                0.0|0.25559831017167356|              0.0| 8.132272964076716| 0.8446523629576677|              2.75|              0.0|               2.0|                 0.0| 0.7851530583907647|               3.2|3.7492280238800166|              27.0|             104.0|             85.0|              44.5|              7.4|             30.0|             90.0|                0.0|               2.0|              4.7|            141.0|  0.9998670145674764|              15.0| 0.31386007690499296|                2.0| 0.4784520629105555| 0.956904125821111|                0.0|0.10863296647697462|             10.9|99.04347826086956| 0.4296938832184708|  0.7602632500091926|  0.8526405732504321|                0.0|             160.0|  0.8527168007896625| 0.9284301130900702|90.91899020346646|  0.4533263359134597|            90.0| 0.8430699615475035|             120.0|              50.0|             10.9|                0.0| 0.2571554357993772|                 0.0| 0.9275073699266075|   0.294566398420675|              89.0|             35.0|            141.0|   0.611656521833323|            44.5|0.9811594126206338|              25.0|  0.7009433313177554| 0.44782233551213174|             120.0|              13.0|             90.0|                 0.0|  0.9889869449553863|              7.4|  0.7871652110151138|              8.0| 0.4905797063103169|  0.7552006632087174| 0.17162054627001216| 0.48473795362972405|            10.0| 0.9529209851706122|  0.3546077079133493|              17.0| 0.3504716656588777|            10.9|               4.7|31.112068965517242|                 0.0| 0.1603262345808094|              16.3|            61.0| 0.9795391797933073| 0.5362463150366963|            128.0| 0.9529942323018025|              7.4|              33.4|1.402528429831561...|              20.5|               0.0|7.012642149157805...|            160.0|             141.0|              8.0| 0.6867241348124333|             105.0| 0.04999999999999982|              16.3|             141.0| 0.5500000000000007|               1.5| 19.17391304347826|             33.4| 0.4642150565450351|0.39980620837585223|               1.5|                0.0|             141.0|               0.0|0.7725206350759527|             85.0|0.5143108715987544|               0.0|                0.0|               1.5|              2.3|             90.0| 0.04999999999999982|             15.7|               0.0| 0.2564876910965749|[7.01264214915780...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|\n",
            "|114849.0|2201-05-18|{2201-05-17 00:00...|0.13065475397959778|8.373489266198279|             170.0|13.597910537212597| 0.0148147169883393|  0.5372745772832075| 0.5007014305921953|120.72483482316362|              85.0| 0.48713427104996304| 30.34493907672786|             62.0|  0.419016389184504| 4.068208670260556|                0.0| 0.14775742178089854|            75.0|2.0192751891676624|9.720783890168976|0.38319833098312733| 0.0720476814472478|0.08476868946084137| 0.46900135508873325|204.55184887459808|0.04999999999999716|  0.4976453997824787|0.4203854376206732|1.4766575863383713|16.326121062384175|30.123507616302994|1.477589339794065|  0.4634458150587124| 0.4600024796048131|1.4608241195741203|                 0.0|0.016292917121629755|             97.0|0.15238186232786088|  0.4720913015670395|0.48651583403086374|28.88809523809525|  0.5225174154345646|103.13290175171363|1.5093973872734954|            97.05| 0.48196839886325465| 0.28223929343979276|  0.4833624831267787|0.7100483349760915|0.45219772949982334|3.250759740695953|  0.6194900007990161|9.798362619808303| 21.44032415799724|  8.74642784226795|4.159509433962263|28.889421157684648|2.0541336843893307| 0.47292877765230995|9.43330216554195|90.84011276681434|            111.0|0.47280115065897854|0.08596788964012393| 0.47373916357820256|             120.0|0.35617271464321204| 3.500057344901359| 2.056371584077676| 0.5286978729187907|             30.0|           100.0|  0.4663993967189891|            100.0| 0.4709935406778632|1.5046424090338784|0.7101219703082332|0.06995517975068115|            62.0|0.48908889201931066| 0.03418278356819755|29.739518633540374|207.85274463007156| 0.45239924008322013|1.4406106231702211|4.1610394537177555|0.43250070550679126|206.9605004019292| 30.49398892709258|  0.4340986688551613|0.9815392365222636|16.087061323618695|  2.494438257849294|0.46314413213559713| 0.4142515026977065|33.248717948717946|104.03776435045317|36.91319672131147|             114.0|29.72134920634922|25.074626865671643|  0.4538385136849273|  0.4721770330141089|3.5965474209650576|            145.25|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|3.4006276150627603|  0.9918535414391851|              30.0| 9.71992725924236|8.427499999999997|103.59088827838833|29.305063649533878| 0.4584105459263105|             160.0|  0.4720685067091678| 0.4886900771438565| 0.2360342533545839| 0.45197895889384554|            23.0|9.599003202562052| 0.48414255054546573| 0.46370842439089255|0.051237573780987374|              73.0|             114.0|25.83084577114428|  0.9261212891095507|1.4444584913611462|209.46905144694534|  0.4752646286819739|             68.75|8.429773195876288|              66.0|  3.265986323710904|              50.0| 0.986777781674111|132.22386319471434|  0.4773693026559077|             114.0|              8.0|0.5092303817388681|120.49256068911511|126.38537745451853|90.55054369714055|               0.0|             100.0| 0.4933888908370555|16.114291481631014|9.21408502024291|0.47109294943321767|             85.0|0.022153573700935885|8.320536082474234|   0.475782102493217|0.12965952398334926|   0.896297429533023| 0.46459083063785256| 0.03490935761855885|29.31268022684791|16.177069035123125|8.319221311475417|0.02918013555493569|              50.0| 4.068660082014597|210.35680190930788|3.5946443514644364|  0.4725160905620611| 4.798857346195361| 0.4686834829104542|1.4457904300423992|  0.5004475598958745|             94.0|0.46784589154325545|   0.51281308899984|30.178889460683365|3.274385328496573|0.42341805053519455| 8.37549739813451|             90.0| 0.4678802538173802|  0.4894464120957203|  0.4867469154217031| 0.5128391320600281|103.58733500575462|125.57075735540884| 37.70331834880121| 0.3685342915673636| 0.47723030968144614|  0.7314040713183034|               0.0| 0.4983362270214471| 0.21087178458708905| 0.5276163794601939|  0.7663966619662547|0.3717226033966161|             100.0|25.03422053231939|  0.4831275084671001|             90.0|29.59090909090909|138.3575503993914|  0.4729044061266951|             97.1|90.69301248489731|0.3680998820137272| 16.17945696932262|2.017717003567181|3.977200303490134| 37.83908909055424|25.418643852978445|0.41496732739917513|2.090566785572731| 0.4594330506661511|13.981693363844393|  0.8588803532801036|13.220061022120518| 0.4974772493116622|130.73140172278778|38.69393271461717|0.07060400796808293| 0.5049095001727325|2.305587200599279|5.0682837331783235|0.47827446509141863|1.4724647487602325|2.297622738931195|0.3525454384054092|                 0.0| 0.5043438780045272|3.9778867924528267|2.0548046676563256|25.786311787072243|103.12537764350454|             85.0|36.781171693735494|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|0.3502247669689524|3.405948419301164|138.3512996941896|  0.5518512852334885| 13.55895896170368| 0.47673291112742694|0.36128275365036766|0.48475960000217266|0.9695192000043453|                0.0|0.26863728864160374|9.644677419354842|97.33333333333333|0.46473433340591286|  0.5004252396055716|  0.5084698186832426|0.05272455247871184|             160.0|   0.509236331115962|0.47024088066356073|             96.0|  0.4533263359134597|            90.0|0.47783318356312104|             120.0|              50.0|9.796491935483868|0.05078673178396359|  0.506758958686583|                 0.0| 0.4884661578947222|  0.4730871389194783|31.267468944099377|             30.0|139.1452599388379|  0.4838445299068336|38.8348594847775|0.9905790501718436| 25.46104914985511| 0.47954800041801254| 0.49055292792469574|             120.0|13.177351247600768|             90.0|                 0.0|  0.4762329257056399|9.539477732793522|  0.4579845075940477|              8.0| 0.4952895250859218|  0.4708701645239077| 0.10543589229354453|  0.2612587077172823|            18.0| 0.4335548314340772|  0.6342979643408483|13.949328214971208| 0.4602773778694809|9.64237220447285|3.4959720063757715|31.112068965517242|0.014632153041738868|0.30974500039950803|16.373460837887045|            70.0|0.48486335344055065|0.45745215253325033|205.4315831344471| 0.4343233352150944|9.375520512820508|33.100986193293885| 0.04195163914256888| 5.296645179203497|0.8705195762144462| 0.02097581957128444|            160.0| 138.7550739009944|              8.0|0.46799099320339343|104.03693830921554|  0.0302482200664027|16.227216656547245|139.14416127805248| 0.3720366581314043|1.4611558651322438|20.666666666666668|33.17546745562131| 0.4987639065100168| 0.4707463743072148|1.4453931203931218|0.08957582974112871|138.75297937600118|0.1363245068214134| 0.838032778369008|             85.0|0.4866650863530708| 0.876945766580447| 0.0911977288017119|1.4776412776412784|2.093508562325766|             90.0|0.029776204513543382|16.14547301843629|               0.0|0.45356404462486793|[0.02097581957128...|(166,[0,2,10,13,5...|[0.02097581957128...|                               0.0|                                0.0|\n",
            "|165590.0|2122-04-30|{2122-04-29 00:00...|0.13065475397959778|              8.4|             155.0|              12.0| 0.0148147169883393|  0.5372745772832075| 0.5007014305921953|             106.0|              69.5| 0.05700811392212522|               6.0|             41.0|  0.419016389184504|               4.0|                0.0| 0.45378854627835763|            89.0|               1.6|9.720783890168976|0.38319833098312733| 0.0720476814472478|                0.0|  0.3182754809203519|204.55184887459808|                0.0|  0.8408622595398241|               0.0|               0.5|16.326121062384175|30.123507616302994|1.477589339794065|  0.6199638177152004| 0.4600024796048131|1.4608241195741203|                 0.0|  0.9642670029981145|             97.8|0.15238186232786088|  0.9404912526956775|0.48651583403086374|28.88809523809525| 0.41545845588492925|             110.0|               0.5|             97.8| 0.48196839886325465|  0.4004975111710627|   0.451174902920182|               0.0|0.45219772949982334|3.250759740695953|  0.6194900007990161|9.798362619808303|32.234472610697324|15.074813431681335|              4.0|28.889421157684648|               1.6| 0.35087588798840197|9.43330216554195|90.84011276681434|             60.0|0.47280115065897854|                0.0| 0.47373916357820256|             120.0|                0.0|               2.8|               1.6| 0.5286978729187907|             30.0|           100.0| 0.11608214361493663|            100.0| 0.4709935406778632|               0.5|               0.0|0.06995517975068115|            88.0|0.48908889201931066|                 0.0|               6.0|207.85274463007156| 0.09379466520671997|               0.5|               4.0|0.18557035072839792|206.9605004019292|               6.0| 0.18758933041343995|0.9815392365222636|16.087061323618695| 2.3123448651769496|0.29625508149420365| 0.4142515026977065|33.248717948717946|             110.0|36.91319672131147|151.38370222803474|29.72134920634922|              25.0|  0.3281425073977985| 0.35067089967433296|               2.8|117.71428571428571|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|               2.8|  0.5178664985009427|              30.0| 9.71992725924236|              8.4|             110.0|29.305063649533878| 0.4584105459263105|             160.0|  0.4720685067091678| 0.4886900771438565| 0.2360342533545839|  0.3272384810295713|            36.0|9.599003202562052|   0.452366173438544|   0.625578218093795|                 0.0|              46.0|178.49948822927328|             25.0| 0.22689427313917881|               0.5|209.46905144694534|   0.984857258566092|56.142857142857146|              8.4|             100.0|  7.091242083423347|              50.0| 0.986777781674111|             106.0|   0.904732346877088|127.71084953940634|              8.0|0.5092303817388681|             106.0|             106.0|90.55054369714055| 19.70452579251507|             100.0| 0.4933888908370555|16.114291481631014|9.21408502024291|0.47109294943321767|             85.0|0.022153573700935885|              8.4|  0.5776620057840788|0.12965952398334926| 0.22682221035556605| 0.11401622784425045|                 0.0|29.31268022684791|16.177069035123125|              8.4|0.02918013555493569|              50.0|               4.0|210.35680190930788|               2.8|  0.3269214354740668|               0.0| 0.4686834829104542|1.4457904300423992|  0.8246645501628336|             93.0|0.46784589154325545|  0.492428629283046|30.178889460683365|3.274385328496573|                0.0|              8.4|             90.0| 0.3099819088576002|  0.4894464120957203|0.058041071807468314|0.49610616460362017|             110.0|             106.0| 37.70331834880121| 0.3685342915673636|   0.902349805840364|3.754044293074736...|               0.0| 0.4983362270214471|  0.7504064262432225| 0.5276163794601939|  0.7663966619662547|               0.0|             100.0|             25.0|  0.5925101629884073|             90.0|              6.0|            143.0|  0.4729044061266951|             97.8|90.69301248489731|               0.0| 16.17945696932262|              1.6|              4.0| 37.83908909055424|              25.0|0.41496732739917513|              1.6| 0.4594330506661511|              12.0| 0.20024875558553135|              12.0| 0.8365392822629666|             106.0|38.69393271461717|0.07060400796808293| 0.5049095001727325|2.305587200599279|15.018356115373058| 0.2888310028920394|               0.5|2.297622738931195|               0.0|                 0.0| 0.5043438780045272|               4.0|5.1536394906900505|              25.0|             110.0|             85.0|36.781171693735494|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|               0.0|              2.8|            143.0|  0.8865888948222169|              12.0|  0.5757735937263659|                0.0|0.48475960000217266|0.9695192000043453|                0.0|0.26863728864160374|9.644677419354842|98.28571428571429|0.46473433340591286|   0.824562056005799|  0.5297543736521613|0.05272455247871184|             160.0|  0.5316972155492664|0.47024088066356073|             94.0| 0.09278517536419896|            90.0|0.28788679686318297|             120.0|              50.0|9.796491935483868|                0.0|  0.506758958686583|                 0.0| 0.4884661578947222|  0.9366055689014672|               6.0|             30.0|            143.0|  0.4838445299068336|38.8348594847775|0.9905790501718436|              25.0|  0.5837869351218472| 0.49055292792469574|             120.0|              12.0|             90.0|                 0.0|  0.9922123292072403|9.539477732793522|  0.4579845075940477|              8.0| 0.4952895250859218|  0.4708701645239077| 0.37520321312161126| 0.48473795362972405|            20.0|0.16407125369889924|  0.9998122977853463|              12.0| 0.2918934675609236|9.64237220447285|               2.8|               6.0|0.014632153041738868|0.30974500039950803|16.373460837887045|           112.0|0.48486335344055065|0.45745215253325033|205.4315831344471|0.16361924051478566|9.375520512820508|33.100986193293885|0.014186526515704753|               0.0|0.8705195762144462|  0.9929067367421476|            160.0|             143.0|              8.0| 0.3127891090468975|             110.0|                 0.0|16.227216656547245|             143.0| 0.3720366581314043|1.4611558651322438|              28.2|33.17546745562131| 0.4987639065100168| 0.4707463743072148|1.4453931203931218|                0.0|             143.0|0.1363245068214134| 0.838032778369008|             85.0|0.4866650863530708| 0.876945766580447|                0.0|1.4776412776412784|              1.6|             90.0|                 0.0|16.14547301843629|               0.0|0.45356404462486793|[0.99290673674214...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|158767.0|2185-04-25|{2185-04-24 00:00...|0.13065475397959778|8.373489266198279|             165.0|13.597910537212597| 0.0148147169883393|  0.1307658700463204| 0.5007014305921953|120.72483482316362|              91.0| 0.48713427104996304| 30.34493907672786|             53.0|   0.34133654226967| 4.068208670260556|  4.714045207910317|5.232090274430767E-7|           102.0|2.0192751891676624|9.720783890168976| 0.9903032969018329| 0.0720476814472478|0.08476868946084137| 0.46900135508873325|204.55184887459808| 0.4749736834815178|  0.4976453997824787|0.4203854376206732|1.4766575863383713|16.326121062384175|30.123507616302994|1.477589339794065|  0.4634458150587124| 0.4600024796048131|1.4608241195741203|                 0.0| 4.63839093727985E-5|             96.0|0.15238186232786088|  0.4720913015670395|0.48651583403086374|28.88809523809525|  0.2796575358744478|103.13290175171363|1.5093973872734954|            96.78| 0.48196839886325465| 0.01078696538495602|  0.4833624831267787|0.7100483349760915|0.45219772949982334|3.250759740695953| 0.22387339796893174|9.798362619808303|17.508870712676416| 13.86722755275906|4.159509433962263|28.889421157684648|2.0541336843893307| 0.47292877765230995|9.43330216554195|90.84011276681434|            108.0|0.47280115065897854|0.08596788964012393| 0.47373916357820256|             130.0|0.35617271464321204| 3.500057344901359| 2.056371584077676| 0.5286978729187907|             30.0|           100.0|  0.4663993967189891|            100.0| 0.4709935406778632|1.5046424090338784|0.7101219703082332|0.06995517975068115|            67.0|0.48908889201931066| 0.03418278356819755|29.739518633540374|207.85274463007156| 0.45239924008322013|1.4406106231702211|4.1610394537177555|0.43250070550679126|206.9605004019292| 30.49398892709258|  0.4340986688551613|0.9548007145431963|16.087061323618695| 1.7248787237282068|0.46314413213559713| 0.4142515026977065|33.248717948717946|104.03776435045317|36.91319672131147|            178.75|29.72134920634922|25.074626865671643|  0.4538385136849273|  0.4721770330141089|3.5965474209650576| 140.2941176470588|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|3.4006276150627603|  0.9999768080453136|              30.0| 9.71992725924236|8.427499999999997|103.59088827838833|29.305063649533878| 0.4584105459263105|             160.0| 0.07818588218629802| 0.4886900771438565|0.03909294109314901| 0.45197895889384554|            30.0|9.599003202562052| 0.48414255054546573| 0.46370842439089255|0.051237573780987374|              68.0|             199.0|25.83084577114428|  0.9999997383954863|1.4444584913611462|209.46905144694534|  0.4752646286819739| 69.94117647058823|8.429773195876288|  78.8695652173913|  7.035959486659983|              50.0|0.9745232284758952|132.22386319471434|  0.4773693026559077|             146.0|              8.0|0.5225996427284019|120.49256068911511|126.38537745451853|90.55054369714055|19.954636052807377|             100.0|  0.491807068783402|16.114291481631014|9.21408502024291|0.47109294943321767|85.00246212121212|0.022153573700935885|8.320536082474234|   0.475782102493217|0.12965952398334926|0.008525176537474574| 0.46459083063785256| 0.03490935761855885|29.31268022684791|16.177069035123125|8.319221311475417|0.02918013555493569|              50.0| 4.068660082014597|210.35680190930788|3.5946443514644364|  0.4725160905620611| 4.798857346195361| 0.4686834829104542|1.4457904300423992|  0.5004475598958745|             92.0|0.46784589154325545|   0.51281308899984|30.178889460683365|3.274385328496573|0.42341805053519455| 8.37549739813451|             90.0| 0.4678802538173802|  0.4894464120957203|  0.4867469154217031| 0.5128391320600281|103.58733500575462|125.57075735540884| 37.70331834880121| 0.3685342915673636| 0.47723030968144614| 0.31029135471612956|               0.0| 0.4983362270214471|0.014925207825926165| 0.5276163794601939|0.019393406196334225|0.3717226033966161|             100.0|25.03422053231939|  0.4831275084671001|             90.0|29.59090909090909|138.3575503993914|  0.4729044061266951|             97.4|90.69301248489731|0.3680998820137272| 16.17945696932262|2.017717003567181|3.977200303490134| 37.83908909055424|25.418643852978445|0.41496732739917513|2.090566785572731| 0.4594330506661511|13.981693363844393|   0.994606517307522|13.220061022120518| 0.4974772493116622|130.73140172278778|38.69393271461717|0.07060400796808293| 0.5049095001727325|2.305587200599279| 14.83029724122129|0.47827446509141863|1.4724647487602325|2.297622738931195|0.3525454384054092|0.002728073736398...| 0.5043438780045272|3.9778867924528267|3.5900513657987854|25.786311787072243|103.12537764350454|84.99962121212121|36.781171693735494|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|0.3502247669689524|3.405948419301164|138.3512996941896|  0.9957374117312627| 13.55895896170368| 0.47673291112742694|0.36128275365036766|0.46271416494026707|0.9254283298805341|                0.0| 0.0653829350231602|9.644677419354842|98.54545454545455|0.46473433340591286|  0.5004252396055716|  0.5084698186832426|0.05272455247871184|             160.0|   0.509236331115962|0.47024088066356073|            116.0|  0.4533263359134597|            90.0|0.47783318356312104|123.33333333333333|              50.0|9.796491935483868|0.05078673178396359|  0.506758958686583|                 0.0| 0.4884661578947222|  0.4730871389194783|31.267468944099377|             30.0|139.1452599388379|  0.4838445299068336|38.8348594847775|0.9769261585915691| 25.46104914985511| 0.47954800041801254| 0.49055292792469574|             120.0|13.177351247600768|             90.0|                 0.0|  0.4762329257056399|9.539477732793522|  0.4579845075940477|              8.0|0.48846307929578453|  0.4708701645239077|0.007462603912963083|  0.8601712320627761|            14.0| 0.4335548314340772|  0.8448543226419352|13.949328214971208| 0.4602773778694809|9.64237220447285|3.4959720063757715|31.112068965517242|0.014632153041738868|0.11193669898446587|16.373460837887045|            94.0|0.48486335344055065|0.45745215253325033|205.4315831344471| 0.4343233352150944|9.375520512820508|33.100986193293885| 0.06916444470922062| 5.296645179203497|0.8705195762144462| 0.03458222235461031|            160.0| 138.7550739009944|              8.0|0.46799099320339343|104.03693830921554|  0.0302482200664027|16.227216656547245|139.14416127805248| 0.3720366581314043|1.4611558651322438| 20.73913043478261|33.17546745562131| 0.4987639065100168| 0.4707463743072148|1.4453931203931218|0.08957582974112871|138.75297937600118|0.1363245068214134|  0.68267308453934|85.00530303030303|0.4866650863530708| 0.876945766580447| 0.0911977288017119|1.4776412776412784|2.093508562325766|             90.0|0.029776204513543382|16.14547301843629|               0.0|0.45356404462486793|[0.03458222235461...|(166,[0,1,10,13,5...|[0.03458222235461...|                               0.0|                                1.0|\n",
            "|147191.0|2168-04-18|{2168-04-17 00:00...|                0.0|              8.6|             142.0|              12.0|                0.0| 0.28527572776766313|  0.855686629460921|             119.0|             73.75|  0.4747357932740503|              36.0|             42.0|  0.419016389184504|               3.9|                0.0|  0.9082343786446219|            74.0|               2.0|             11.2| 0.3034253128759712|                0.0|                0.0|  0.8064977665700788|              95.0| 1.1460075625114075|  0.4032488832850394|               0.5|              1.35|              13.2|              31.9|              1.1|  0.6199638177152004| 0.2208527735218423|               1.1|                 0.0| 0.23146588555393624|             96.0|                0.0|  0.7242968595418335| 0.4417055470436846|             31.9|  0.4752571650878614|             102.0|               1.4|97.40000000000002|  0.2154618705722416| 0.12142596419302899|  0.3338771576625803|               0.0| 0.4263476888853164|             3.49|  0.3897484515890689|             11.2|10.424330514074594|  8.51591647054698|              3.9|              31.9|              2.05|  0.7157189452432999|            14.9|             91.0|             98.0| 0.3108459245307781|                0.0| 0.37447565918465553|             120.0|                0.0|               3.7|              2.05| 0.7868261555573418|             30.0|           100.0|    0.95332818101418|            100.0| 0.2170647612594137|               1.4|               0.0|                0.0|            46.0| 0.3988801527810958|0.050000000000000044|              36.0|              95.0|  0.5970377157797275|               1.3|               3.9| 0.7959261507219185|             95.0|              36.0|  0.8059245684405449|0.9680307246992478|              13.2| 1.7672758383707081| 0.4152161228494273|0.15415080324129485|              35.0|             103.0|             26.0|             129.5|             31.9|              26.0|  0.8195970853595984|  0.7158825115872107|               3.7|             123.0|              3.49|                0.0|              31.9|             13.2|               3.7|  0.8842670572230319|              30.0|             11.2|              8.6|             102.5|              31.9| 0.1994400763905479|             160.0| 0.21294704427559902|0.33199492889042537|0.10647352213779951|  0.8185650615308983|            33.0|             14.9|  0.3352481789652994|   0.625578218093795|                 0.0|              58.0|             163.0|             26.0| 0.45411718932231093|               1.3|              95.0|  0.8617935932847937|56.166666666666664|              8.6|             73.25| 13.485331537143114|              50.0| 0.981301814901793|             119.0|  0.6704963579305988|             103.0|              8.0| 0.515984637650376|             119.0|             119.0|             91.0|21.788758569500924|             100.0| 0.4906509074508965|              14.7|            14.9|0.28862674107815794|             85.0|                 0.0|              8.6|  0.8515211735758799|                0.0|2.745884054260026...|  0.9494715865481006|0.050000000000000044|             31.9|              14.7|              8.6|                0.0|              50.0|               3.9|              95.0|               3.7|  0.8074966408144618|               0.0| 0.8922690647138792|               1.1| 0.35794125579360536|             92.0| 0.8859188503161307| 0.5691032033576031|              31.9|             3.49|                0.5|              8.6|             90.0| 0.3099819088576002|  0.2873104051984716|    0.47666409050709| 0.5726742796766917|             102.5|             119.0|              26.0|                0.0|  0.6677543153251606|  0.9918731067201854|               0.0| 0.8522459219939933| 0.12871163722275783| 0.7853276039752664|  0.6068506257519424|               0.5|             100.0|             26.0|  0.8304322456988547|             90.0|             36.0|            137.0|  0.8563447974007642|             98.9|             91.0|               0.5|              13.2|              2.0|              3.9|              26.0|              26.0|0.15542296226538904|              2.1|0.22014965352027815|              12.0|0.060712982096514496|              12.0| 0.4037483204072309|             119.0|             26.0|                0.0|0.16599746444521268|              0.0| 7.323857514239943| 0.5742394132120601|              1.35|              0.0|               0.0|                 0.0| 0.6995028990719382|               3.9|3.8396686778360913|              26.0|             102.0|             85.0|              26.0|             14.9|             31.9|             90.0|                0.0|               0.0|              3.7|            137.0|1.372942027130013...|              12.0|  0.8551190038239849|                0.0|0.47361569343253623|0.9472313868650725|                0.0|0.14263786388383157|             11.2|95.29166666666667| 0.6009942018561236| 0.35785947262164997|  0.6378515702290832|                0.0|             160.0|  0.6391940422251249| 0.9328320323108141|             97.0|  0.6020369246390407|            90.0| 0.5724404980880076|             120.0|              50.0|             11.2|                0.0| 0.1661610418597041|                 0.0|0.39887236892500944|  0.7216119155497502|              36.0|             30.0|            138.0| 0.22816229936773863|            26.0|0.9836831939012491|              26.0|  0.8137947948089239|  0.8127621704076722|             120.0|              12.0|             90.0|                 0.0|  0.8546514406466165|             14.9|  0.4341295225188274|              8.0|0.49184159695062457|  0.3083016064825897| 0.06435581861137891|  0.2376285825439307|            15.0| 0.4097985426797992|  0.4959365533600927|              12.0|0.40689739740446196|            11.2|               3.7|              36.0|                 0.0|0.19487422579453445|              13.2|           104.0| 0.4402993070405563|0.19943618446250472|             95.0| 0.4092825307654491|             14.9|              35.0|  3.7450612546703E-4|               0.0|               0.0| 1.87253062733515E-4|            160.0|             137.5|              8.0| 0.3127891090468975|             103.0| 0.04999999999999993|              13.2|             138.0|                0.0|               1.1|19.583333333333332|             35.0| 0.5335839838445929| 0.2955081560120135|               1.1|                0.0|             137.5|               0.0| 0.838032778369008|             85.0|0.3323220837194082|               0.0|                0.0|               1.1|              2.1|             90.0| 0.04999999999999993|             14.7|               0.0| 0.4293447920494673|[1.87253062733515...|(166,[0,4,10,15,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|154530.0|2110-06-01|{2110-05-31 00:00...|                0.0|              9.6|             148.0|              24.0|                0.0| 0.28527572776766313|  0.378678793232161|             170.0| 67.42857142857143| 0.48713427104996304|              63.0|             37.0|0.36165156269653376|               3.9|                0.0| 0.24071046718311084|            53.0|2.0192751891676624|              9.2| 0.3034253128759712|                0.0|0.19999999999999973| 0.11645007388788563|             157.0|0.23151673805580458|0.058225036943942814|               1.5|               3.9|              13.5|              28.8|              1.2|0.004953359941364171|0.24414171259299255|               1.2|                 0.0|0.004063537840172...|             97.6|                0.0| 0.08138316266373945| 0.4882834251859851|             29.6|  0.6259633867772381|              95.0|               3.9|97.97999999999999|  0.2899493992878918| 0.01129799145673504| 0.33387948890766295|               0.0| 0.8120918107247819|             3.18|  0.3897484515890689|              9.2| 2.718042512920064| 5.205962045225314|              4.1|              29.6|2.0541336843893307|   0.953680176792207|             5.0|             93.0|            138.0| 0.9431427938324677|0.19999999999999973| 0.43838496349695233|             120.0|                0.0|               4.8| 2.056371584077676| 0.5939540946376091|             35.0|           100.0|  0.4663993967189891|             98.0| 0.4334657180999039|               3.9|               0.0|                0.0|            66.0| 0.5425671583318119| 0.03418278356819755|              63.0|             157.0|  0.9507962509274448|               3.9|               4.1|0.09244578755863095|            157.0|              63.0| 0.09840749814511045|0.9680307246992478|              13.5| 1.8136220534447136| 0.8520663897046223| 0.4666010269332571|              30.9|              98.0|             39.0|             168.0|             29.6|              22.0|0.022142665925252155|  0.9539042386874428|               4.8|142.57142857142858|              3.18|                0.0|              29.6|             13.5|               4.8|  0.9979682310799138|              35.0|              9.2|              9.6|              96.5|              29.6|0.27128357916590595|             160.0|  0.3311830982240087| 0.7026254558861105| 0.8344084508879956|0.022042201881228428|            25.0|              5.0|  0.3352505124591709|0.004528003762408486|                 0.0|              59.0|             194.0|             22.0| 0.12035523359155542|               3.9|             157.0|  0.5497190532886032|46.714285714285715|              9.6|            78.875|  7.534987834540058|              50.0|0.9771005412364924|             170.0|  0.6705010249183418|             142.0|              8.0| 0.515984637650376|             170.0|             170.0|             93.0|              26.0|             100.0| 0.4885502706182462|              15.9|             5.0|  0.757357586464322|             85.0|                 0.0|              9.6|  0.2728991070532044|                0.0|0.002396882501108461| 0.46459083063785256| 0.03490935761855885|             29.6|              15.9|              9.6|                0.0|              50.0|               3.9|             157.0|               4.8| 0.12173306093175318|               0.0| 0.1449746996439459|               1.2|  0.4769521193437214|             90.0|0.14553486893706977| 0.2748595266443016|              28.8|             3.18|                1.5|              9.6|             90.0| 0.9975233200293179| 0.13075498154629434|  0.4867469154217031|  0.278067730126483|              96.5|             170.0|              39.0|                0.0|  0.6677589778153259|0.053055852358175976|               0.0|0.37636274025936367|  0.6838507110416914| 0.5924732625832826|  0.6068506257519424|               1.5|             100.0|             22.0| 0.29586722059075526|             90.0|             63.0|            137.0| 0.06537749077314717|             98.3|             93.0|               1.5|              13.5|2.017717003567181|              3.7|              39.0|              22.0|0.47157139691623384|2.090566785572731|0.24367338397664057|              24.0| 0.00564899572836752|              24.0|0.06086653046587659|             170.0|             39.0|                0.0|0.35131272794305524|              0.0| 5.872801368884133| 0.8635504464733978|               3.9|              0.0|               0.0|                 0.0| 0.4730025257783376|               3.7|3.0954155168930426|              22.0|              95.0|             85.0|              39.0|              5.0|             28.8|             90.0|                0.0|               0.0|              4.8|            137.0|0.001198441250554...|              24.0| 0.27588943185752257|                0.0|0.47361569343253623|0.9472313868650725|                0.0|0.14263786388383157|              9.2|95.56521739130434| 0.9460050515566752|  0.4768400883961035|  0.9593084186681303|                0.0|             160.0|  0.9590527053417746| 0.6653917172247079|             73.0|  0.9537771062206846|            90.0| 0.8620552840712388|             120.0|              50.0|              9.2|                0.0| 0.3544738638226932|                 0.0| 0.5418579267502793| 0.08189458931645097|              63.0|             35.0|            140.0| 0.29106973787413953|            39.0|0.9836831939012491|              22.0| 0.32230593853981615| 0.21919248174847616|             120.0|              24.0|             90.0|                 0.0|   0.556135460252966|              5.0|  0.8669314361998078|              8.0|0.49184159695062457|  0.9332020538665142|  0.3419253555208457|   0.687018306611381|            13.0| 0.9889286670373739|0.026527926179087988|              24.0| 0.8388470307300919|             9.2|               4.8|              63.0|                 0.0|0.19487422579453445|              13.5|            92.0|0.48734676795328113|0.27092896337513966|            157.0| 0.9889788990593857|              5.0|              30.9| 0.06362847591929036|               0.0|               0.0| 0.03181423795964518|            160.0|             138.5|              8.0| 0.9977359981187958|              98.0|                 0.0|              13.5|             140.0|                0.0|               1.2|17.458333333333332|             30.9|  0.667304141387646| 0.7527254805187273|               1.2|                0.0|             138.5|               0.0|0.7233031253930675|             85.0|0.7089477276453864|               0.0|                0.0|               1.2|2.093508562325766|             90.0|                 0.0|             15.9|               0.0| 0.8150534748334348|[0.03181423795964...|(166,[0,4,12,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|172484.0|2191-01-26|{2191-01-25 00:00...|0.13065475397959778|8.373489266198279|138.94057916509965|13.597910537212597| 0.0148147169883393| 0.29698077487343505| 0.5007014305921953|120.72483482316362| 74.77826247362239| 0.48713427104996304| 30.34493907672786|47.70463975858167|  0.426930727592382| 4.068208670260556|0.20128960898888473| 0.20718381381747253|78.0369671821954|2.0192751891676624|9.720783890168976|0.39375853276170225| 0.0720476814472478|0.08476868946084137| 0.46900135508873325|204.55184887459808|  0.570643557622579|  0.4976453997824787|0.4203854376206732|1.4766575863383713|16.326121062384175|30.123507616302994|1.477589339794065|  0.4634458150587124| 0.4600024796048131|1.4608241195741203|1.694340901389359...| 0.19619776364057873|97.29775093569233|0.15238186232786088|  0.4720913015670395|0.48651583403086374|28.88809523809525| 0.41545845588492925|103.13290175171363|1.5093973872734954|98.08017781384638| 0.48196839886325465| 0.22323189276593913|  0.4833624831267787|0.7100483349760915|0.45219772949982334|3.250759740695953|  0.3738713374251535|9.798362619808303|11.487286830973543| 8.168515431713185|4.159509433962263|28.889421157684648|2.0541336843893307| 0.47292877765230995|9.43330216554195|90.84011276681434|97.67732230161715|0.47280115065897854|0.08596788964012393| 0.47373916357820256|120.86295503211991|0.35617271464321204| 3.500057344901359| 2.056371584077676| 0.5286978729187907|32.15018688413184|           100.0|  0.4663993967189891|99.22550953320184| 0.4709935406778632|1.5046424090338784|0.7101219703082332|0.06995517975068115|            48.0|0.48908889201931066| 0.03418278356819755|29.739518633540374|207.85274463007156| 0.45239924008322013|1.4406106231702211|4.1610394537177555|0.43250070550679126|206.9605004019292| 30.49398892709258|  0.4340986688551613| 0.964593531955711|16.087061323618695| 1.5454214717430281|0.46314413213559713| 0.4142515026977065|33.248717948717946|104.03776435045317|36.91319672131147|151.38370222803474|29.72134920634922|25.074626865671643|  0.4538385136849273|  0.4721770330141089|3.5965474209650576|117.87633609613528|3.2267190648931874|0.06445004758462232|29.732255489021973|16.04014206300184|3.4006276150627603|   0.472376144412589|33.498131158681616| 9.71992725924236|8.427499999999997|103.59088827838833|29.305063649533878| 0.4584105459263105|160.55733211512106| 0.37029854772356713| 0.4886900771438565|  0.454664934364283| 0.45197895889384554|            22.0|9.599003202562052| 0.48414255054546573| 0.46370842439089255|0.051237573780987374|60.782215523737754|178.49948822927328|25.83084577114428|  0.4711329744042347|1.4444584913611462|209.46905144694534|  0.4752646286819739| 61.39591571522619|8.429773195876288|              55.9|  9.787236586493655|52.581026333558405|0.9745232284758952|132.22386319471434|  0.4773693026559077|127.71084953940634|8.001711156741958|0.5122275324512284|120.49256068911511|126.38537745451853|90.55054369714055| 19.70452579251507|100.00033886818028|  0.491807068783402|16.114291481631014|9.21408502024291|0.47109294943321767|85.00246212121212|0.022153573700935885|8.320536082474234|   0.475782102493217|0.12965952398334926|  0.1744965172426682| 0.46459083063785256| 0.03490935761855885|29.31268022684791|16.177069035123125|8.319221311475417|0.02918013555493569|53.196657663740694| 4.068660082014597|210.35680190930788|3.5946443514644364|  0.4725160905620611| 4.798857346195361| 0.4686834829104542|1.4457904300423992|  0.5004475598958745|93.80013149243918|0.46784589154325545|   0.51281308899984|30.178889460683365|3.274385328496573|0.42341805053519455| 8.37549739813451|90.44908692476263| 0.4678802538173802|  0.4894464120957203|  0.4867469154217031| 0.5128391320600281|103.58733500575462|125.57075735540884| 37.70331834880121| 0.3685342915673636| 0.47723030968144614| 0.02591128524312968|0.6456096427150202| 0.4983362270214471| 0.32834702258044673| 0.5276163794601939|  0.6091078933059159|0.3717226033966161|100.00016943409014|25.03422053231939|  0.4831275084671001|90.51460920379839|29.59090909090909|138.3575503993914|  0.4729044061266951|98.87376658727456|90.69301248489731|0.3680998820137272| 16.17945696932262|2.017717003567181|3.977200303490134| 37.83908909055424|25.418643852978445|0.41496732739917513|2.090566785572731| 0.4594330506661511|13.981693363844393| 0.48581197505212126|13.220061022120518| 0.4974772493116622|130.73140172278778|38.69393271461717|0.07060400796808293| 0.5049095001727325|2.305587200599279| 8.132272964076716|0.47827446509141863|1.4724647487602325|2.297622738931195|0.3525454384054092|0.002728073736398...| 0.5043438780045272|3.9778867924528267| 1.729161646579058|25.786311787072243|103.12537764350454|84.99962121212121|36.781171693735494|9.271773418734984|30.23589954713873|90.01611459265891|0.15403168443235046|0.3502247669689524|3.405948419301164|138.3512996941896|  0.5188029566070709| 13.55895896170368| 0.47673291112742694|0.36128275365036766|0.48009629871768866|0.9530305562536405|0.12368084276523614| 0.4623844484669175|9.644677419354842|97.08895231254782|0.46473433340591286|  0.5004252396055716|  0.5084698186832426|0.05272455247871184|160.30150753768845|   0.509236331115962|0.47024088066356073|90.91899020346646|  0.4533263359134597|90.0066025067144|0.47783318356312104|120.64921739573775|53.803173531397704|9.796491935483868|0.05078673178396359|  0.506758958686583|0.007491553859143...| 0.4884661578947222|  0.4730871389194783|31.267468944099377|32.81576379787387|139.1452599388379|  0.4838445299068336|38.8348594847775|0.9855858203961294| 25.46104914985511| 0.47954800041801254| 0.49055292792469574|120.43861527480371|13.177351247600768|90.00044762757386|0.003037197636785...|  0.4762329257056399|9.539477732793522|  0.4579845075940477|7.995208761122519| 0.4931317783783426|  0.4708701645239077| 0.43721795594277313| 0.48473795362972405|            15.0| 0.4335548314340772| 0.01295564262156484|13.949328214971208| 0.4602773778694809|9.64237220447285|3.4959720063757715|31.112068965517242|0.014632153041738868| 0.4225132067981789|16.373460837887045|            88.0|0.48486335344055065|0.45745215253325033|205.4315831344471| 0.4343233352150944|9.375520512820508|33.100986193293885|8.89299440303214E-16| 5.296645179203497|0.8705195762144462|4.44649720151607E-16|160.4163621135982| 138.7550739009944|7.997900981063198|0.46799099320339343|104.03693830921554|  0.0302482200664027|16.227216656547245|139.14416127805248| 0.3720366581314043|1.4611558651322438|              16.9|33.17546745562131| 0.4987639065100168| 0.4707463743072148|1.4453931203931218|0.08957582974112871|138.75297937600118|0.1363245068214134|0.7269868524702858|85.00530303030303|0.4866650863530708| 0.876945766580447| 0.0911977288017119|1.4776412776412784|2.093508562325766|90.38166544923301|0.029776204513543382|16.14547301843629|0.5871509133786607|0.45356404462486793|[4.44649720151607...|(166,[0,1,10,13,5...|[4.44649720151607...|                               0.0|                                0.0|\n",
            "|146062.0|2120-10-12|{2120-10-11 00:00...|0.13065475397959778|8.373489266198279|             167.0|13.597910537212597| 0.0148147169883393|   0.382950425126365| 0.5007014305921953|120.72483482316362| 86.11111111111111| 0.48713427104996304| 30.34493907672786|             60.0|0.38626031753797635| 4.068208670260556|                0.0|  0.0167300611561019|            76.0|2.0192751891676624|9.720783890168976| 0.3371881483049508| 0.0720476814472478|0.08476868946084137| 0.46900135508873325|204.55184887459808| 0.7000000000000028|  0.4976453997824787|0.4203854376206732|1.4766575863383713|16.326121062384175|30.123507616302994|1.477589339794065|  0.4634458150587124| 0.4600024796048131|1.4608241195741203|                 0.0|0.006149844809322624|             99.0|0.15238186232786088|  0.4720913015670395|0.48651583403086374|28.88809523809525| 0.41545845588492925|103.13290175171363|1.5093973872734954|             99.7| 0.48196839886325465| 0.07558389364401447|  0.4833624831267787|0.7100483349760915|0.45219772949982334|3.250759740695953|  0.4825208223441543|9.798362619808303|14.080018237923094| 7.723620976436784|4.159509433962263|28.889421157684648|2.0541336843893307| 0.47292877765230995|9.43330216554195|90.84011276681434|            115.0|0.47280115065897854|0.08596788964012393| 0.47373916357820256|             120.0|0.35617271464321204| 3.500057344901359| 2.056371584077676| 0.5286978729187907|             30.0|           100.0|  0.4663993967189891|            100.0| 0.4709935406778632|1.5046424090338784|0.7101219703082332|0.06995517975068115|            68.0|0.48908889201931066| 0.03418278356819755|29.739518633540374|207.85274463007156| 0.45239924008322013|1.4406106231702211|4.1610394537177555|0.43250070550679126|206.9605004019292| 30.49398892709258|  0.4340986688551613|0.9738948671571004|16.087061323618695|0.45825756949558405|0.46314413213559713| 0.4142515026977065|33.248717948717946|104.03776435045317|36.91319672131147|151.38370222803474|29.72134920634922|25.074626865671643|  0.4538385136849273|  0.4721770330141089|3.5965474209650576|138.55555555555554|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|3.4006276150627603|  0.9969250775953387|              30.0| 9.71992725924236|8.427499999999997|103.59088827838833|29.305063649533878| 0.4584105459263105|             160.0|  0.3091690311323449| 0.4886900771438565|0.15458451556617245| 0.45197895889384554|            23.0|9.599003202562052| 0.48414255054546573| 0.46370842439089255|0.051237573780987374|              71.0|178.49948822927328|25.83084577114428|  0.9916349694219491|1.4444584913611462|209.46905144694534|  0.4752646286819739| 69.55555555555556|8.429773195876288|              74.7|                4.1|              50.0| 0.981301814901793|132.22386319471434|  0.4773693026559077|127.71084953940634|              8.0|0.5130525664214498|120.49256068911511|126.38537745451853|90.55054369714055| 19.70452579251507|             100.0| 0.4906509074508965|16.114291481631014|9.21408502024291|0.47109294943321767|             85.0|0.022153573700935885|8.320536082474234|   0.475782102493217|0.12965952398334926|0.001210866574244...| 0.46459083063785256| 0.03490935761855885|29.31268022684791|16.177069035123125|8.319221311475417|0.02918013555493569|              50.0| 4.068660082014597|210.35680190930788|3.5946443514644364|  0.4725160905620611| 4.798857346195361| 0.4686834829104542|1.4457904300423992|  0.5004475598958745|             99.0|0.46784589154325545|   0.51281308899984|30.178889460683365|3.274385328496573|0.42341805053519455| 8.37549739813451|             90.0| 0.4678802538173802|  0.4894464120957203|  0.4867469154217031| 0.5128391320600281|103.58733500575462|125.57075735540884| 37.70331834880121| 0.3685342915673636| 0.47723030968144614|  0.7234131878926482|               0.0| 0.4983362270214471| 0.11408224900841603| 0.5276163794601939|  0.6743762966099016|0.3717226033966161|             100.0|25.03422053231939|  0.4831275084671001|             90.0|29.59090909090909|138.3575503993914|  0.4729044061266951|            100.4|90.69301248489731|0.3680998820137272| 16.17945696932262|2.017717003567181|3.977200303490134| 37.83908909055424|25.418643852978445|0.41496732739917513|2.090566785572731| 0.4594330506661511|13.981693363844393|  0.9622080531779927|13.220061022120518| 0.4974772493116622|130.73140172278778|38.69393271461717|0.07060400796808293| 0.5049095001727325|2.305587200599279| 4.645454435637083|0.47827446509141863|1.4724647487602325|2.297622738931195|0.3525454384054092|                 0.0| 0.5043438780045272|3.9778867924528267|2.5612496949731396|25.786311787072243|103.12537764350454|             85.0|36.781171693735494|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|0.3502247669689524|3.405948419301164|138.3512996941896|  0.9993945667128776| 13.55895896170368| 0.47673291112742694|0.36128275365036766| 0.4784520629105555| 0.956904125821111|                0.0| 0.1914752125631825|9.644677419354842|             99.7|0.46473433340591286|  0.5004252396055716|  0.5084698186832426|0.05272455247871184|             160.0|   0.509236331115962|0.47024088066356073|             97.0|  0.4533263359134597|            90.0|0.47783318356312104|             120.0|              50.0|9.796491935483868|0.05078673178396359|  0.506758958686583|                 0.0| 0.4884661578947222|  0.4730871389194783|31.267468944099377|             30.0|139.1452599388379|  0.4838445299068336|38.8348594847775|0.9866770743020669| 25.46104914985511| 0.47954800041801254| 0.49055292792469574|             120.0|13.177351247600768|             90.0|                 0.0|  0.4762329257056399|9.539477732793522|  0.4579845075940477|              8.0|0.49333853715103343|  0.4708701645239077|  0.9429588754957919| 0.48473795362972405|            16.0| 0.4335548314340772|  0.6382934060536759|13.949328214971208| 0.4602773778694809|9.64237220447285|3.4959720063757715|31.112068965517242|0.014632153041738868|0.24126041117207714|16.373460837887045|            82.0|0.48486335344055065|0.45745215253325033|205.4315831344471| 0.4343233352150944|9.375520512820508|33.100986193293885|0.044089573603692506| 5.296645179203497|0.8705195762144462|0.022044786801846253|            160.0| 138.7550739009944|              8.0|0.46799099320339343|104.03693830921554|  0.0302482200664027|16.227216656547245|139.14416127805248| 0.3720366581314043|1.4611558651322438|              20.2|33.17546745562131| 0.4987639065100168| 0.4707463743072148|1.4453931203931218|0.08957582974112871|138.75297937600118|0.1363245068214134|0.7725206350759527|             85.0|0.4866650863530708| 0.876945766580447| 0.0911977288017119|1.4776412776412784|2.093508562325766|             90.0|0.029776204513543382|16.14547301843629|               0.0|0.45356404462486793|[0.02204478680184...|(166,[0,1,10,22,5...|[0.02204478680184...|                               0.0|                                1.0|\n",
            "|146062.0|2120-10-13|{2120-10-12 00:00...|                0.0|9.266666666666667|             169.0|11.333333333333334|                0.0| 0.21726593295394925| 0.5764555237377678|             121.0| 90.29166666666667|  0.5862491365701604|12.333333333333334|             51.0|   0.34133654226967| 4.266666666666667|                0.0|1.393382716115670...|            97.0|               1.7|9.850000000000001| 0.2761968333658741|0.04999999999999982|0.18856180831641287|   0.272435290649737|             154.0|  0.405859855396198|  0.8637823546751315|0.4714045207910317|0.8000000000000002|              14.9|              26.8|              1.3|  0.2391625192246876|0.36803427972191166|               1.3|                 0.0|9.197729271868016E-6|             99.1| 1.0500000000000007|0.026717751798493075| 0.7360685594438233|             32.3|  0.8743570348937935|             107.0|               0.8|99.61666666666667| 0.02187842078225815|6.581581847677506E-7|  0.7332399504201453| 2.494438257849294|  0.156679376323228|             3.68|  0.3206524691616188|              9.9| 15.12396690686673|11.759673913657451|              4.4|              32.3|               2.1|3.938798894246063E-5|           16.55|             91.0|            100.0|0.33568435353847426|0.18856180831641287|0.010048933348823676|             120.0| 0.4714045207910317| 2.533333333333333|               2.1|  0.921660311838386|             30.0|           100.0|   0.823714468667149|             99.0|0.32482274748006507|               0.8| 2.494438257849294| 0.5499999999999989|            64.0| 0.7082352766381776| 0.28284271247461895|               9.0|             166.5|0.043577607275828954|               0.8|               4.4|0.08650316982134783|            166.5|12.333333333333334| 0.08715521455165791|0.9630883535824493|              14.9| 1.0467393492680603| 0.6176251875203743|0.16640829241286065|              30.7|             108.0|             26.7|            144.75|             33.2|              34.0| 0.23229490259432356|3.918242771529596...|               3.2|           138.375|              3.66|                0.0|              33.2|             14.9|               1.9|  0.9999954011353641|              30.0|9.850000000000001|              9.4|107.66666666666667|             32.75| 0.3541176383190888|             160.0| 0.15038969889535822| 0.6800341553682516|0.07519484944767911| 0.23127086867498398|            22.0|             17.6|  0.7354718183210909| 0.24388204197653232| 0.09428090415820685|              62.0|             165.0|             35.0|  0.9999999303308642|               0.8|             179.0|0.001385103897311...| 75.79166666666667|              9.4|  76.1304347826087|  6.215718838600191|              50.0|0.9735591921327245|             145.0|  0.5290563633578181|             127.0|              8.0|0.5184558232087754|             121.0|134.66666666666666|             88.0|14.042346669983617|             100.0|0.48677959606636223|              15.2|            15.5| 0.8470889525244645|             85.0|0.020000000000000018|              9.2| 0.17830106229185208|                0.0|  0.6000180878298547|  0.8275017268596792| 0.28284271247461895|            32.75|              16.0|              9.2|0.40000000000000036|              50.0| 4.266666666666667|             179.0|               3.2|  0.2815360890486461|10.077477638553981| 0.9890607896088709|               1.3|  0.9999804087861424|             96.0| 0.9873419036679347| 0.9993074480513444|             26.85|              3.7| 0.4714045207910317|9.266666666666667|             90.0| 0.1195812596123438|0.005078443320474383|  0.5881427656664255|  0.999340051430651|107.66666666666667|134.66666666666666|              26.7|0.45000000000000284|  0.5335200991597093|0.022964471075312045|               0.0| 0.5714660206405983|0.009810630775108579| 0.9204881186894996|  0.5523936667317482|0.9428090415820634|             100.0|             34.0|  0.7647496249592514|             90.0|              9.0|            149.0|0.002539221660237...|            100.3|             89.5|0.9428090415820634|              14.9|              1.7|              4.0|              26.7|34.666666666666664|0.16784217676923713|              2.3|0.36901699133895616|              12.0|  0.9999996709209076|              11.0|  0.859231955475677|             145.0|             26.7|0.04999999999999982| 0.3400170776841258|             12.5|11.273047379578523|0.08915053114592604|0.8000000000000002|             12.5|0.4714045207910317|                 0.0| 0.8946185400414242|               4.0|3.2004773949452536|              35.0|             107.0|             85.0|              26.7|             15.5|             26.9|             90.0| 1.0500000000000007|0.4714045207910317|              1.9|            149.0|  0.6999909560850727|11.333333333333334| 0.17706090187907908| 0.4714045207910317| 0.4695414356305627|0.9390828712611254|                0.0|0.10863296647697462|              9.8|97.39285714285714|0.21076291991715176|  0.9999803060055288|  0.9866411241007534|0.04999999999999894|             160.0|  0.9865964618212197| 0.8024865683266896|            111.0|0.043251584910673914|            90.0|0.08853045093953954|             120.0|              50.0|              9.9|0.09428090415820685|0.34506407973087005|                 0.0| 0.7066539121412764| 0.02680707635756046|              15.0|             30.0|            151.0|0.025316192664130453|            26.7|0.9811594126206338|34.666666666666664|  0.8072352433386024|0.005024466674411838|             120.0|              11.0|             90.0|                 0.0|0.001319897138698147|             17.6|  0.6496454949601301|              8.0| 0.4905797063103169|  0.3328165848257213|  0.9950946846124457| 0.43717851744689673|             8.0|0.11614745129716178|0.011482235537656022|              12.0| 0.5963823783306987|             9.8| 2.533333333333333|              15.0|                 0.0| 0.1603262345808094|              14.9|            93.0| 0.7380339826779123| 0.3533269560706382|            154.0|0.11563543433749199|            16.55|              29.6|0.008559179883051828|10.077477638553981|               0.0|0.004279589941525914|            160.0|149.66666666666666|              8.0|0.12194102098826616|             108.0|1.110223024625156...|              14.9|             151.0|0.45000000000000284|               1.3|17.083333333333332|            30.15| 0.4012432841633448| 0.8570679587188035|               1.3| 0.5312459150169744|149.66666666666666|               1.5|  0.68267308453934|             85.0|0.6901281594617401|               0.0| 0.5312459150169744|               1.3|              2.3|             90.0|1.110223024625156...|             15.6|               0.0|0.15902376262100062|[0.00427958994152...|(166,[0,1,10,22,5...|[0.00427958994152...|                               0.0|                                1.0|\n",
            "|104994.0|2155-07-24|{2155-07-23 00:00...|0.13065475397959778|             7.85|             152.0|              13.0| 0.0148147169883393|  0.5372745772832075| 0.5007014305921953|             181.0| 69.66666666666667|0.012719981637978413|              35.0|             57.0|  0.419016389184504|               5.3|                0.0| 0.47028918602745917|            65.0|               1.6|9.720783890168976|0.38319833098312733| 0.0720476814472478|                0.0| 0.28008924435710464|204.55184887459808|                0.0|  0.8599553778214477|               0.5|               2.2|16.326121062384175|30.123507616302994|1.477589339794065|  0.7553851617823153| 0.4600024796048131|1.4608241195741203|                 0.0|   0.804785191614481|             97.3|0.15238186232786088|  0.3291751981881297|0.48651583403086374|28.88809523809525|0.021772603983801046|             108.0|               2.2|             97.3| 0.48196839886325465|  0.9484295355327206|  0.9870386614888194|               1.0|0.45219772949982334|3.250759740695953|  0.6194900007990161|9.798362619808303|14.794894014114766|12.736648783028533|              5.3|28.889421157684648|               1.6|   0.410331269470417|9.43330216554195|90.84011276681434|            109.0|0.47280115065897854|                0.0| 0.47373916357820256|             120.0|                0.0|               2.8|               1.6| 0.5286978729187907|             30.0|           100.0|0.026284196196583356|            100.0| 0.4709935406778632|               2.2|               1.0|0.06995517975068115|            66.0|0.48908889201931066|                 0.0|              34.0|207.85274463007156|  0.6078601524517152|               2.2|               5.3| 0.7709403565646127|206.9605004019292|              35.0|  0.7842796950965696|0.9815392365222636|16.087061323618695| 0.7284313590846836| 0.9852333247477647| 0.4142515026977065|33.248717948717946|             109.0|36.91319672131147|             275.0|29.72134920634922|              20.0|  0.3540236412050074|  0.4104026651917846|               2.9|119.66666666666667|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|               2.7|  0.5976074041927595|              30.0| 9.71992725924236|              8.2|             108.5|29.305063649533878| 0.4584105459263105|             160.0|  0.4720685067091678| 0.4886900771438565| 0.2360342533545839| 0.35405888857450707|            23.0|9.599003202562052|  0.9872867266812559|  0.7658143613562591| 0.34999999999999964|              44.0|             275.0|             20.0| 0.23514459301372959|               2.2|209.46905144694534| 0.16395339086435168|              60.4|              8.2| 71.57142857142857|  7.326217945690334|              50.0| 0.986777781674111|             199.0|0.025426546637488213|             275.0|              8.0|0.5092303817388681|             181.0|             190.0|90.55054369714055|               0.0|             100.0| 0.4933888908370555|16.114291481631014|9.21408502024291|0.47109294943321767|             85.0|0.022153573700935885|              7.5|  0.4310357596002874|0.12965952398334926|0.010127657911334034|0.025439963275956826|                 0.0|29.31268022684791|16.177069035123125|              7.5|0.02918013555493569|              50.0|               5.3|210.35680190930788|               2.9| 0.28897116345678453|               9.0| 0.4686834829104542|1.4457904300423992|  0.2052013325958923|             98.0|0.46784589154325545|0.08197669543217584|30.178889460683365|3.274385328496573|                0.5|             7.85|             90.0|0.37769258089115765|  0.4894464120957203|0.013142098098291678|0.08410314387031852|             108.5|             190.0| 37.70331834880121| 0.3685342915673636|0.025922677022361194| 0.15893169163293142|               0.0| 0.4983362270214471| 0.48652157580661437| 0.5276163794601939|  0.7663966619662547|               0.0|             100.0|             20.0| 0.02953335050447055|             90.0|             34.0|            136.0|  0.4729044061266951|             97.3|90.69301248489731|               0.0| 16.17945696932262|              1.6|              5.3| 37.83908909055424|              20.0|0.41496732739917513|              1.6| 0.4594330506661511|              13.0|  0.4742147677663603|              13.0| 0.8555144182716077|             199.0|38.69393271461717|0.07060400796808293| 0.5049095001727325|2.305587200599279| 2.870540018881465| 0.2155178798001437|               2.2|2.297622738931195|               0.0|                 0.0| 0.5043438780045272|               5.3|2.8642768079662035|              20.0|             108.0|             85.0|36.781171693735494|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|               0.0|              2.7|            136.0|   0.994936171044333|              13.0|  0.4287504867113322|                0.0|0.48475960000217266|0.9695192000043453|                0.0|0.26863728864160374|9.644677419354842|99.57142857142857|0.46473433340591286|  0.2051656347352085| 0.16458759909406484|0.05272455247871184|             160.0| 0.16757003867596765|0.47024088066356073|             86.0|  0.6145298217176937|            90.0| 0.2143752433556661|             120.0|              50.0|9.796491935483868|0.34999999999999964|  0.506758958686583|                 0.0| 0.4884661578947222|  0.3351400773519353|              36.0|             30.0|            136.0|  0.4838445299068336|38.8348594847775|0.9905790501718436|              20.0| 0.03763901705937761| 0.49055292792469574|             120.0|              13.0|             90.0|                 0.0| 0.16820628774063703|9.539477732793522|  0.4579845075940477|              8.0| 0.4952895250859218|  0.4708701645239077| 0.24326078790330719|  0.9891136980080995|            13.0| 0.8229881793974962| 0.07946584581646571|              13.0| 0.9811804914703112|9.64237220447285|               2.8|              36.0|0.014632153041738868|0.30974500039950803|16.373460837887045|            89.0|0.48486335344055065|0.45745215253325033|205.4315831344471| 0.8229705557127465|9.375520512820508|33.100986193293885|0.028095645405670475|               9.0|0.8705195762144462|0.014047822702835238|            160.0|             136.0|              8.0|0.38290718067812957|             109.0|                 0.0|16.227216656547245|             136.0| 0.3720366581314043|1.4611558651322438|16.714285714285715|33.17546745562131| 0.4987639065100168| 0.4707463743072148|1.4453931203931218|0.09999999999999987|             136.0|0.1363245068214134| 0.838032778369008|             85.0|0.4866650863530708| 0.876945766580447|0.09999999999999987|1.4776412776412784|              1.6|             90.0|                 0.0|16.14547301843629|               0.0|0.45356404462486793|[0.01404782270283...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|106374.0|2127-09-26|{2127-09-25 00:00...|0.13065475397959778|8.373489266198279|             148.0|13.597910537212597| 0.0148147169883393|   0.382950425126365| 0.5007014305921953|120.72483482316362|              92.0| 0.48713427104996304| 30.34493907672786|             69.0|0.38626031753797635|               5.1|                0.0|3.625873941170441E-4|            88.0|2.0192751891676624|9.720783890168976| 0.3371881483049508| 0.0720476814472478|                0.0| 0.46900135508873325|204.55184887459808| 0.5500000000000043|  0.4976453997824787|0.4203854376206732|1.4766575863383713|16.326121062384175|30.123507616302994|1.477589339794065|  0.4634458150587124| 0.4600024796048131|1.4608241195741203|                 0.0|0.016813010679842807|             95.1|0.15238186232786088|  0.4720913015670395|0.48651583403086374|28.88809523809525|  0.7693650288370278|103.13290175171363|1.5093973872734954|            95.65| 0.48196839886325465| 4.34420165500475E-4|  0.9689781329832746|0.7100483349760915|0.45219772949982334|3.250759740695953|  0.4825208223441543|9.798362619808303|12.381033882515627| 7.788880963698615|              5.1|28.889421157684648|2.0541336843893307| 0.47292877765230995|9.43330216554195|90.84011276681434|            105.0|0.47280115065897854|                0.0| 0.47373916357820256|             120.0|0.35617271464321204| 3.500057344901359| 2.056371584077676| 0.5286978729187907|             30.0|           100.0|  0.4663993967189891|            100.0| 0.4709935406778632|1.5046424090338784|0.7101219703082332|0.06995517975068115|            63.0|0.48908889201931066| 0.03418278356819755|29.739518633540374|207.85274463007156| 0.45239924008322013|1.4406106231702211|               5.1|0.43250070550679126|206.9605004019292| 30.49398892709258|  0.4340986688551613|0.9738948671571004|16.087061323618695| 1.5779733838059498|0.46314413213559713| 0.4142515026977065|33.248717948717946|104.03776435045317|36.91319672131147|             133.0|29.72134920634922|25.074626865671643|  0.4538385136849273|  0.4721770330141089|3.5965474209650576|             134.9|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|3.4006276150627603|  0.9915934946600786|              30.0| 9.71992725924236|8.427499999999997|103.59088827838833|29.305063649533878| 0.4584105459263105|             160.0|  0.3091690311323449| 0.4886900771438565|0.15458451556617245| 0.45197895889384554|            19.0|9.599003202562052|  0.9694511024055178| 0.46370842439089255|0.051237573780987374|              78.0|             133.0|25.83084577114428|  0.9998187063029415|1.4444584913611462|209.46905144694534|  0.4752646286819739| 78.11111111111111|8.429773195876288|              68.0|   2.32379000772445|              50.0| 0.981301814901793|132.22386319471434| 0.06109779518896449|             133.0|              8.0|0.5130525664214498|120.49256068911511|126.38537745451853|90.55054369714055|               0.0|             100.0| 0.4906509074508965|16.114291481631014|9.21408502024291|0.47109294943321767|             85.0|0.022153573700935885|8.320536082474234|   0.475782102493217|0.12965952398334926|0.026231062864512628| 0.46459083063785256| 0.03490935761855885|29.31268022684791|16.177069035123125|8.319221311475417|0.02918013555493569|              50.0|               5.1|210.35680190930788|3.5946443514644364|  0.4725160905620611| 4.798857346195361| 0.4686834829104542|1.4457904300423992|  0.5004475598958745|             95.0|0.46784589154325545|   0.51281308899984|30.178889460683365|3.274385328496573|0.42341805053519455| 8.37549739813451|             90.0| 0.4678802538173802|  0.4894464120957203|  0.4867469154217031| 0.5128391320600281|103.58733500575462|125.57075735540884| 37.70331834880121| 0.3685342915673636| 0.06204373403345079| 0.04722329818130949|               0.0| 0.4983362270214471|0.006019991821992265| 0.5276163794601939|  0.6743762966099016|0.3717226033966161|             100.0|25.03422053231939|  0.4831275084671001|             90.0|29.59090909090909|138.3575503993914|  0.4729044061266951|             96.2|90.69301248489731|0.3680998820137272| 16.17945696932262|2.017717003567181|              5.1| 37.83908909055424|25.418643852978445|0.41496732739917513|2.090566785572731| 0.4594330506661511|13.981693363844393|  0.9997827899172498|13.220061022120518| 0.4974772493116622|130.73140172278778|38.69393271461717|0.07060400796808293| 0.5049095001727325|2.305587200599279| 6.607141665474891|0.47827446509141863|1.4724647487602325|2.297622738931195|0.3525454384054092|                 0.0| 0.5043438780045272|               5.1| 2.749545416973504|25.786311787072243|103.12537764350454|             85.0|36.781171693735494|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|0.3502247669689524|3.405948419301164|138.3512996941896|  0.9868844685677437| 13.55895896170368| 0.47673291112742694|0.36128275365036766| 0.4784520629105555| 0.956904125821111|                0.0| 0.1914752125631825|9.644677419354842|             98.9|0.46473433340591286|  0.5004252396055716|  0.5084698186832426|0.05272455247871184|             160.0|   0.509236331115962|0.47024088066356073|             99.0|  0.4533263359134597|            90.0|0.47783318356312104|             120.0|              50.0|9.796491935483868|0.05078673178396359|  0.506758958686583|                 0.0| 0.4884661578947222|  0.4730871389194783|31.267468944099377|             30.0|139.1452599388379|  0.4838445299068336|38.8348594847775|0.9866770743020669| 25.46104914985511| 0.47954800041801254| 0.49055292792469574|             120.0|13.177351247600768|             90.0|                 0.0|  0.4762329257056399|9.539477732793522|  0.4579845075940477|              8.0|0.49333853715103343|  0.4708701645239077|0.003009995910996...|  0.3846825144185139|            10.0| 0.4335548314340772|0.023611649090654746|13.949328214971208| 0.4602773778694809|9.64237220447285|3.4959720063757715|31.112068965517242|0.014632153041738868|0.24126041117207714|16.373460837887045|            71.0|0.48486335344055065|0.45745215253325033|205.4315831344471| 0.4343233352150944|9.375520512820508|33.100986193293885|8.918287734798392E-4| 5.296645179203497|0.8705195762144462|4.459143867399196E-4|            160.0| 138.7550739009944|              8.0|0.46799099320339343|104.03693830921554|  0.0302482200664027|16.227216656547245|139.14416127805248| 0.3720366581314043|1.4611558651322438|              16.2|33.17546745562131| 0.4987639065100168| 0.4707463743072148|1.4453931203931218|0.08957582974112871|138.75297937600118|0.1363245068214134|0.7725206350759527|             85.0|0.4866650863530708| 0.876945766580447| 0.0911977288017119|1.4776412776412784|2.093508562325766|             90.0|0.029776204513543382|16.14547301843629|               0.0|0.45356404462486793|[4.45914386739919...|(166,[0,1,10,14,5...|[4.45914386739919...|                               0.0|                                0.0|\n",
            "|118470.0|2117-07-28|{2117-07-27 00:00...|                0.0|8.833333333333334|138.94057916509965|              16.0|                0.0|   0.382950425126365|0.10241132686275844|             133.0| 74.77826247362239|  0.4300936849966269|              22.0|47.70463975858167|  0.426930727592382|             4.725|                0.0| 0.20718381381747253|78.0369671821954|               2.0|              7.8| 0.3371881483049508|                0.0|0.12990381056766606| 0.15004100917836852|             275.0| 0.6077622890571609| 0.07502050458918426|1.5811388300841898|              2.15|              15.7|              30.1|              1.4| 0.22515777840322562|0.42505130200202146|               1.4|                 0.0| 0.19619776364057873|             96.4|                0.0|  0.2409033215469037| 0.8501026040040429|             26.1|0.014346549336464412|              97.0|               2.6|           97.275|  0.9148077398159835| 0.22323189276593913|  0.9912428580628836|  4.06201920231798| 0.4263168912709361|              2.6|  0.4825208223441543|              7.8|11.487286830973543| 8.168515431713185|              4.9|              26.1| 2.033333333333333| 0.11026638444995694|             9.1|            100.0|97.67732230161715| 0.5498595813446315|0.12990381056766606|  0.9382132371331686|             120.0|                1.0|3.4666666666666663| 2.033333333333333|0.21315844563546804|             30.0|           100.0|   0.865128702458111|            100.0| 0.9579285543070151|               2.6|  4.06201920231798|                0.0|            63.0| 0.8435998902297972|0.047140452079103216|              17.0|             275.0| 0.16655013186498124|               1.7|               4.9|0.33718467776264527|            275.0|              22.0|  0.3331002637299625|0.9738948671571004|              15.7|  0.705878097754059| 0.9852224324379829| 0.2703122173712452|              30.0|             101.0|             33.6|             209.2|             26.5|              24.0|  0.2245418446784262| 0.11028615378162474|               4.1|117.87633609613528|               2.6|                0.0|              26.5|             15.7|               2.8|   0.472376144412589|              30.0|              7.8|              8.9|              99.0|              26.3| 0.4217999451148986|160.55733211512106|  0.3091690311323449|0.46050116196756086|0.15458451556617245| 0.22461870505672532|            23.0|              9.1|  0.9915008043774955| 0.21397074487786935|   0.047140452079103|60.782215523737754|             307.0|             26.0|  0.4711329744042347|               1.7|             275.0|  0.9697201741032277| 61.39591571522619|              8.9| 74.70833333333333|  8.857572874225886|              50.0| 0.981301814901793|             225.0| 0.01699839124500894|             147.0|              8.0|0.5130525664214498|             133.0|            171.75|            100.0|56.534591180975205|             100.0| 0.4906509074508965|              19.6|             9.1| 0.2048226537255169|             85.0|                 0.0|              8.8|  0.9921110068894929|                0.0|2.067003456139535...|  0.8601873699932538|0.047140452079103216|             26.3|              19.6|              8.8|                0.0|              50.0|             4.725|             275.0|               4.1| 0.15554300570834906| 33.74444398712179|0.45740386990799176|               1.4| 0.05514307689081237|             97.0|0.45245970971703037| 0.4848600870516139|              30.1|              2.6| 1.5811388300841898|8.833333333333334|             90.0| 0.8874211107983871| 0.03788666196245041|  0.4325643512290555|0.49221275170082657|              99.0|            171.75|34.150000000000006| 0.1999999999999993|0.017514283874232907| 0.06302290387498388|               0.0|0.10243922576911767|0.043240262861317734|0.21237339702018854|  0.6743762966099016| 1.224744871391589|             100.0|             24.0|0.029555135124034203|             90.0|             17.0|            133.0|0.018943330981225207|             98.4|            100.0| 1.224744871391589|              15.7|              2.0|              4.6|34.150000000000006|              25.0|0.27492979067231577|              2.1| 0.4277959359535912|              17.0| 0.48581197505212126|              15.0|0.07777150285417453|             225.0|             34.7|                0.0| 0.7697494190162195|              0.0| 8.132272964076716|0.49605550344474647|2.1500000000000004|              0.0|0.7071067811865476|                 0.0|0.12043896455206399|               4.6|2.6922599965250176|              26.0|              97.0|             85.0|              33.6|              9.1|             30.1|90.01611459265891|                0.0|0.7071067811865476|              2.8|            133.0|  0.9999998966498272|              16.0|  0.9864252123669421|                1.0|0.48009629871768866|0.9530305562536405|0.12368084276523614| 0.1914752125631825|              7.8|99.79166666666667|0.24087792910412797| 0.05513319222497847|  0.8795483392265482|                0.0|160.30150753768845|  0.8802642483287222|0.09876634693969201|90.91899020346646| 0.16859233888132263|90.0066025067144|0.49321260618347107|             120.0|              50.0|              7.8|  0.047140452079103| 0.7768133478926319|0.007491553859143...| 0.8400794622369812| 0.23947150334255557|              28.0|             30.0|            136.0|  0.9049194194340607|            34.7|0.9866770743020669|              25.0|0.039148188742445494|  0.4691066185665843|             120.0|              15.0|90.00044762757386|                 0.0|  0.9844255034016531|              9.1| 0.08414289138596992|              8.0|0.49333853715103343|  0.5406244347424904|0.021620131430658867|  0.9928267253317677|            12.0| 0.8877290776607869| 0.03151145193749194|              17.0| 0.9804259056287773|             7.8|3.4666666666666663|              28.0|                 0.0|0.24126041117207714|              15.7|            95.0| 0.8555918719071824| 0.4200397311184906|            275.0| 0.8876906474716373|              9.1|              30.0|0.001832139355812...| 33.74444398712179|0.5500000000000007|9.160696779063222E-4|160.4163621135982|             135.0|              8.0| 0.8930146275610653|             101.0| 0.33541019662496846|              15.7|             136.0| 0.1999999999999993|               1.4|17.541666666666668|             30.0|  0.950616826530154|0.20487845153823533|               1.4| 0.5312459150169743|             135.0|               0.0|0.7269868524702858|             85.0|0.4463733042147362|0.5500000000000007| 0.5312459150169742|               1.4|              2.1|             90.0| 0.33541019662496846|             19.6|               0.0| 0.4247467940403771|[9.16069677906322...|(166,[0,4,12,14,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|\n",
            "|188386.0|2169-01-24|{2169-01-23 00:00...|                0.0|              7.0|              99.0|              19.0|                0.0|0.003967696775815827|  0.513398317855795|             152.0|58.916666666666664|  0.5706241283112277|              42.0|             42.0|  0.426930727592382|              3.95|                0.0| 7.74663911326642E-7|            54.0|               2.1|              9.7| 0.2761968333658741|                0.0|               0.25| 0.09291225691555141|             187.0| 0.6238322424070952|0.046456128457775706|               1.0|               4.7|              17.1|              30.6|              1.6|0.042713675385068844| 0.5879879700195085|               1.6|                 0.0|1.179648625380105...|             95.7|                0.0|0.008147487126147143|  0.824024059960983|             29.3|  0.4719094044209271|              95.0|               4.7|            96.45|   0.395634142953349|1.862116460210566E-4| 0.38156724688933574|               5.0| 0.6606042038848076|             3.17|7.334922296539729E-5|              9.7| 6.132223631495076|2.9568658332016953|              4.2|              29.3|               2.1| 0.15118971754012475|             5.9|             96.0|             77.0|0.01097116503342885|               0.25|  0.8487362437179414|             120.0|                2.0| 5.300000000000001|               2.1| 0.6696978980575963|             40.0|           100.0|  0.8556339172934234|            100.0| 0.7897505544799583|               4.7|               5.0|                0.0|            81.0| 0.7414431983910541|                 0.0|              37.0|             187.0|   0.785137846657219|               4.7|               4.2| 0.4160309312723275|            187.0|              42.0| 0.42972430668556216|0.9630883535824493|              17.1| 0.5070392952039391| 0.8977303433430062| 0.9939857821540893|              31.8|              97.0|             75.1|             177.0|             30.5|              22.0|0.002247404350113068| 0.15118985211583363|               5.4|             90.25|              3.17|                0.0|              30.5|             17.1|               5.2|5.898243126900527E-9|              40.0|              9.7|              7.1|              96.0|              29.9|  0.629278400804473|160.55733211512106|2.325979744201577...| 0.9226635042845899| 0.9998837010127899|0.002228309158510...|            27.0|              5.9| 0.38309675563590584| 0.03988583895762363| 0.09999999999999964|              50.0|             192.0|             24.0| 3.87331955663321E-7|               4.7|             187.0|  0.5667015549842709|49.583333333333336|              7.1| 84.95833333333333|  2.950694362725869|              60.0| 0.986777781674111|             176.0|  0.7661935112718117|             162.0|              8.0|0.5184558232087754|             152.0|             164.0|             96.0|              15.0|             100.0| 0.4933888908370555|              17.8|             5.9|   0.97320336428841|             85.0|                 0.0|              6.9|0.032798782305312656|                0.0|4.051504183505949...|  0.8587517433775447|                 0.0|             29.9|              17.8|              6.9|                0.0|              60.0|              3.95|             187.0|               5.4| 0.09768703168586838|              12.0| 0.1978170714766745|               1.6| 0.07559492605791682|             98.0|0.19758876830251432|0.28335077749213544|              30.6|             3.17|                1.0|              7.0|             92.0| 0.9786431623074656| 0.34416496387477413|  0.5721830413532882|  0.287900398142081|              96.0|             164.0|              75.1| 0.5999999999999996|  0.7631344937786715|  0.6434187961159507|               0.0| 0.5100770567314884|0.001049733633138...|  0.667651317995436|  0.5523936667317482|               2.0|             100.0|             22.0| 0.20453931331398767|             92.0|             37.0|            132.0| 0.17208248193738707|             97.6|             96.0|               2.0|              17.1|              2.1|              3.7|              75.1|              23.0| 0.9945144174832856|              2.1| 0.5915063899092545|              21.0| 9.31058230105283E-5|              17.0|0.04884351584293419|             176.0|             75.1|                0.0|0.46133175214229494|              0.0|2.5806437612003372| 0.9836006088473437|               4.7|              0.0|               1.0|                 0.0| 0.4654234346257759|               3.7| 4.999305507323547|              24.0|              95.0|             85.0|              75.1|              5.9|             30.6|90.01611459265891|                0.0|               1.0|              5.2|            132.0|  0.9999997974247908|              19.0| 0.03371323763136008|                2.0|0.48009629871768866|0.9530305562536405|0.12368084276523614| 0.9980161516120921|              9.7|99.78260869565217| 0.9308468692515518| 0.07559485877006238|0.004073743563073572|                0.0|160.30150753768845|0.004317948591896079|0.33971479065121646|             62.0|  0.7919845343638363|90.0066025067144|   0.98314338118432|             120.0|              60.0|              9.7|0.09999999999999964|0.46622221528282615|0.007491553859143...| 0.7454472637669882|0.008635897183792159|              47.0|             40.0|            136.0| 0.39517753660502863|            75.1|0.9811594126206338|              23.0|  0.2317785949964598|  0.5756318781410292|             120.0|              17.0|90.00044762757386|                 0.0|   0.575800796284162|              5.9|  0.4204988910400834|              8.0| 0.4905797063103169|0.012028435691821531|5.248668165692271E-4|  0.7640452977895364|            10.0| 0.9988762978249435|  0.3217093980579753|              21.0|   0.88411070250177|             9.7| 5.300000000000001|              47.0|                 0.0| 0.9999633253885173|              17.1|            92.0| 0.8169872201814908| 0.6272763681165059|            187.0| 0.9988858454207448|              5.9|              31.8|  0.9896506206235995|              12.0|               0.0| 0.49482531031179977|160.4163621135982|             134.0|              8.0| 0.9800570805211882|              97.0|                 0.0|              17.1|             136.0| 0.5999999999999996|               1.6|19.083333333333332|             31.8| 0.8301426046743918| 0.9798458865370232|               1.6|0.10000000000000009|             134.0|               0.0|0.7269868524702858|             85.0|0.9324444305656523|               0.0|0.10000000000000009|               1.6|              2.1|             92.0|                 0.0|             17.8|               0.0|  0.664697364009128|[0.49482531031179...|(166,[0,2,10,14,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "+--------+----------+--------------------+-------------------+-----------------+------------------+------------------+-------------------+--------------------+-------------------+------------------+------------------+--------------------+------------------+-----------------+-------------------+------------------+-------------------+--------------------+----------------+------------------+-----------------+-------------------+-------------------+-------------------+--------------------+------------------+-------------------+--------------------+------------------+------------------+------------------+------------------+-----------------+--------------------+-------------------+------------------+--------------------+--------------------+-----------------+-------------------+--------------------+-------------------+-----------------+--------------------+------------------+------------------+-----------------+--------------------+--------------------+--------------------+------------------+-------------------+-----------------+--------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+--------------------+----------------+-----------------+-----------------+-------------------+-------------------+--------------------+------------------+-------------------+------------------+------------------+-------------------+-----------------+----------------+--------------------+-----------------+-------------------+------------------+------------------+-------------------+----------------+-------------------+--------------------+------------------+------------------+--------------------+------------------+------------------+-------------------+-----------------+------------------+--------------------+------------------+------------------+-------------------+-------------------+-------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+------------------+------------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+------------------+-----------------+-----------------+------------------+------------------+-------------------+------------------+--------------------+-------------------+-------------------+--------------------+----------------+-----------------+--------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+-------------------+------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+----------------+-------------------+-----------------+--------------------+-----------------+--------------------+-------------------+--------------------+--------------------+--------------------+-----------------+------------------+-----------------+-------------------+------------------+------------------+------------------+------------------+--------------------+------------------+-------------------+------------------+--------------------+-----------------+-------------------+-------------------+------------------+-----------------+-------------------+-----------------+-----------------+-------------------+--------------------+--------------------+-------------------+------------------+------------------+------------------+-------------------+--------------------+--------------------+------------------+-------------------+--------------------+-------------------+--------------------+------------------+------------------+-----------------+--------------------+-----------------+-----------------+-----------------+--------------------+-----------------+-----------------+------------------+------------------+-----------------+-----------------+------------------+------------------+-------------------+-----------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+-----------------+-------------------+-------------------+-----------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-------------------+------------------+-----------------+-----------------+--------------------+------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+-----------------+-----------------+-------------------+--------------------+--------------------+-------------------+------------------+--------------------+-------------------+-----------------+--------------------+----------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+--------------------+-------------------+--------------------+------------------+-----------------+-----------------+--------------------+----------------+------------------+------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+--------------------+-----------------+--------------------+-----------------+-------------------+--------------------+--------------------+--------------------+----------------+-------------------+--------------------+------------------+-------------------+----------------+------------------+------------------+--------------------+-------------------+------------------+----------------+-------------------+-------------------+-----------------+-------------------+-----------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+------------------+-----------------+-------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-----------------+-----------------+--------------------+-----------------+------------------+-------------------+--------------------+--------------------+--------------------+----------------------------------+-----------------------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------+----------+--------------------+-------------------+----------------+------------------+------------------+--------------------+--------------------+--------------------+------------------+------------------+-------------------+-----------------+-----------------+-------------------+-----------------+-----------------+--------------------+----------------+------------------+-----------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------+----------------+--------------------+-----------------+-------------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+-------------------+------------------+--------------------+-----------------+--------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-----------------+-----------------+--------------------+-------------------+--------------------+----------------+-------------------+------------------+------------------+--------------------+-----------------+----------------+-------------------+----------------+--------------------+------------------+----------------+-------------------+----------------+-------------------+--------------------+----------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+----------------+--------------------+------------------+------------------+-------------------+-------------------+-------------------+------------------+----------------+-----------------+------------------+-----------------+------------------+--------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+--------------------+--------------------+-------------------+--------------------+----------------+-----------------+-------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+----------------+------------------+------------------+----------------+--------------------+-----------------+--------------------+-----------------+--------------------+-------------------+--------------------+-------------------+--------------------+------------------+------------------+----------------+-------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+------------------+-------------------+----------------+-------------------+-------------------+------------------+-----------------+-----------------+----------------+-----------------+--------------------+--------------------+--------------------+-------------------+----------------+------------------+-----------------+-------------------+-------------------+--------------------+------------------+--------------------+--------------------+--------------------+-------------------+------------------+----------------+----------------+--------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+------------------+------------------+----------------+-----------------+-----------------+----------------+-------------------+----------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+-----------------+-------------------+-------------------+-----------------+------------------+--------------------+-------------------+-----------------+------------------+--------------------+--------------------+------------------+------------------+----------------+----------------+-----------------+------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+-----------------+--------------------+-----------------+--------------------+-------------------+-------------------+------------------+-------------------+--------------------+-----------------+-----------------+-------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+-----------------+--------------------+----------------+--------------------+------------------+----------------+-----------------+-------------------+--------------------+--------------------+-------------------+-------------------+----------------+------------------+-----------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+-----------------+--------------------+-----------------+-------------------+--------------------+--------------------+-------------------+----------------+--------------------+--------------------+------------------+--------------------+----------------+------------------+------------------+--------------------+-------------------+------------------+----------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+-----------------+-----------------+--------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+-----------------+--------------------+------------------+--------------------+------------------+-----------------+-----------------+--------------------+------------------+-----------------+-------------------+--------------------+--------------------+--------------------+----------------------------------+-----------------------------------+\n",
            "|      ID|  TIME_OBS|           TIME_SPAN|   imp_N_227465_std|imp_N_225625_avg|  imp_N_220179_max|  imp_N_227073_avg|     imp_N_51237_std|     imp_N_220047_TT|      imp_N_51222_LT|  imp_N_220621_min|  imp_N_220181_avg|     imp_N_50960_LT|  imp_N_51006_avg| imp_N_220180_min|    imp_N_223751_LT| imp_N_227442_avg| imp_N_220046_std|     imp_N_220181_TT|imp_N_220180_max|   imp_N_50960_min|  imp_N_51222_avg|    imp_N_220046_LT|  imp_N_220228_std|   imp_N_227442_std|     imp_N_50902_TT|   imp_N_51265_min|   imp_N_223761_std|     imp_N_50902_LT|   imp_N_50902_std|    imp_N_50912_avg|   imp_N_51274_max|   imp_N_51248_min| imp_N_227467_max|    imp_N_227073_TT|    imp_N_227465_LT|   imp_N_51237_avg|imp_N_223769_std|     imp_N_220179_TT| imp_N_223761_min|    imp_N_51301_std|     imp_N_50893_TT|    imp_N_227465_TT| imp_N_220545_min|     imp_N_225664_TT|   imp_N_50902_min|   imp_N_50912_max|  imp_N_223761_avg|      imp_N_51301_TT|     imp_N_220180_TT|    imp_N_227442_LT|   imp_N_51006_std|      imp_N_51221_TT|  imp_N_51279_avg|     imp_N_223770_TT| imp_N_220228_max|  imp_N_220179_std|  imp_N_220181_std| imp_N_227442_max|   imp_N_51221_min|  imp_N_220635_avg|     imp_N_50983_TT|  imp_N_220546_avg|  imp_N_51250_max| imp_N_220179_min|     imp_N_227466_TT|    imp_N_50971_std|      imp_N_51248_TT|imp_N_220046_max|   imp_N_227073_std|  imp_N_225677_avg|   imp_N_50960_avg|      imp_N_51221_LT| imp_N_224161_min|imp_N_223769_min|    imp_N_220635_TT|imp_N_220277_max|      imp_N_51277_LT|  imp_N_220615_max|imp_N_225624_std|    imp_N_51249_std|imp_N_220045_min|    imp_N_227467_TT|    imp_N_220635_std|imp_N_225624_min|  imp_N_227457_avg|     imp_N_225624_LT|  imp_N_220615_min|   imp_N_50971_max|      imp_N_51006_TT|  imp_N_51265_avg|imp_N_225624_avg|     imp_N_225624_TT|   imp_N_224162_TT|  imp_N_227465_min|   imp_N_220277_std|     imp_N_50931_LT|     imp_N_51275_LT|   imp_N_51249_max|imp_N_220602_max|  imp_N_51275_min|  imp_N_225664_avg| imp_N_220545_max|   imp_N_50882_min|     imp_N_220615_TT|    imp_N_220645_TT|  imp_N_225677_max|  imp_N_220179_avg|   imp_N_51279_min|   imp_N_223770_std|   imp_N_51221_max|  imp_N_51274_min|   imp_N_50970_min|     imp_N_220179_LT|  imp_N_224161_max|  imp_N_220228_avg|imp_N_225625_max|   imp_N_50902_avg|  imp_N_220545_avg|    imp_N_227467_LT|  imp_N_223751_max|     imp_N_224161_TT|     imp_N_227457_TT|    imp_N_224161_LT|      imp_N_50912_TT|imp_N_220210_max| imp_N_220546_max|     imp_N_50971_LT|      imp_N_50868_TT|     imp_N_50893_std|  imp_N_220181_min|  imp_N_225664_max|  imp_N_50882_max|     imp_N_220181_LT|   imp_N_50912_min|   imp_N_51265_max|      imp_N_50882_TT|  imp_N_220180_avg|  imp_N_50893_max|  imp_N_220045_avg|  imp_N_220045_std|imp_N_220047_min|   imp_N_226253_TT|  imp_N_220621_max|     imp_N_50971_TT|  imp_N_225664_min| imp_N_224162_max|   imp_N_224162_LT|   imp_N_50931_min|  imp_N_220621_avg|  imp_N_51250_min|  imp_N_225664_std|imp_N_223769_max|   imp_N_226253_LT|   imp_N_51277_min| imp_N_51301_min|      imp_N_51222_TT| imp_N_226253_avg|     imp_N_51279_std|  imp_N_50893_min|      imp_N_50970_TT|    imp_N_51274_std|     imp_N_220277_TT|     imp_N_50960_TT|     imp_N_50960_std|   imp_N_51221_avg|   imp_N_51277_max|imp_N_225625_min|    imp_N_51277_std|  imp_N_220047_avg|  imp_N_50971_avg|  imp_N_227457_max|   imp_N_50970_max|    imp_N_220602_TT|   imp_N_50931_std|     imp_N_51301_LT|  imp_N_227467_min|    imp_N_220645_LT|imp_N_220277_min|    imp_N_220546_LT|     imp_N_50882_LT|   imp_N_51248_avg|  imp_N_51279_max| imp_N_220602_std| imp_N_50893_avg| imp_N_223770_avg|     imp_N_227073_LT|      imp_N_51249_TT|     imp_N_220635_LT|    imp_N_227443_LT|imp_N_220602_avg|   imp_N_50931_avg| imp_N_227466_avg|   imp_N_220545_std|    imp_N_227442_TT|     imp_N_220210_TT|  imp_N_224161_std|     imp_N_220228_LT|     imp_N_223761_TT|     imp_N_220545_LT|    imp_N_220046_TT|   imp_N_50983_std|imp_N_223769_avg|imp_N_227443_min|      imp_N_50931_TT| imp_N_223770_max|  imp_N_51006_min| imp_N_220645_min|     imp_N_51249_LT| imp_N_223761_max|  imp_N_51250_avg|  imp_N_220645_std|   imp_N_51274_avg|imp_N_220635_min|  imp_N_50971_min|  imp_N_51275_avg|imp_N_227443_avg|    imp_N_227466_LT|imp_N_220635_max|     imp_N_51274_LT|  imp_N_227073_max|     imp_N_220180_LT|  imp_N_227073_min|    imp_N_220602_LT|   imp_N_50931_max| imp_N_227466_max|    imp_N_51222_std|    imp_N_227457_LT| imp_N_227457_std|  imp_N_220180_std|      imp_N_50970_LT|   imp_N_220615_avg|  imp_N_51265_std|   imp_N_50882_std|    imp_N_226253_std|      imp_N_51279_LT|  imp_N_227442_min|  imp_N_220210_std|imp_N_227443_max|imp_N_220602_min| imp_N_226253_min|  imp_N_227466_min| imp_N_220546_min|  imp_N_51248_max| imp_N_223752_max|   imp_N_220546_std| imp_N_227443_std| imp_N_225677_min|  imp_N_50983_min|     imp_N_220277_LT|  imp_N_50868_avg|     imp_N_225677_TT|    imp_N_50868_std|    imp_N_223752_LT|   imp_N_223752_TT|   imp_N_223751_std|     imp_N_220047_LT|  imp_N_51222_min| imp_N_220277_avg|     imp_N_51279_TT|      imp_N_50983_LT|     imp_N_50893_LT|    imp_N_51248_std|  imp_N_223751_min|    imp_N_225625_LT|     imp_N_51250_TT| imp_N_220181_max|      imp_N_51006_LT|imp_N_223752_avg|     imp_N_225677_LT|  imp_N_220046_avg|imp_N_220047_max|  imp_N_51222_max|   imp_N_225625_std|      imp_N_51265_LT|    imp_N_223752_std|     imp_N_51237_TT|    imp_N_225625_TT|imp_N_225624_max|  imp_N_224161_avg|  imp_N_50983_max|     imp_N_220546_TT| imp_N_51275_max|   imp_N_223769_TT|  imp_N_50882_avg|     imp_N_220621_TT|      imp_N_51248_LT|imp_N_220046_min|   imp_N_50868_min| imp_N_223752_min|    imp_N_224162_std|     imp_N_227443_TT|  imp_N_51301_max|      imp_N_51277_TT| imp_N_224162_min|    imp_N_223769_LT|      imp_N_51275_TT|     imp_N_223761_LT|    imp_N_225664_LT|imp_N_220210_min|     imp_N_220615_LT|     imp_N_220210_LT|   imp_N_50868_max|     imp_N_220621_LT|imp_N_220228_min|   imp_N_50970_avg|   imp_N_51006_max|    imp_N_227467_std|    imp_N_223770_LT|  imp_N_227465_max|imp_N_220045_max|     imp_N_51274_TT|     imp_N_51237_LT| imp_N_227457_min|      imp_N_50912_LT|   imp_N_51301_avg|   imp_N_51249_min|     imp_N_220045_TT|  imp_N_220621_std|  imp_N_227466_std|     imp_N_220045_LT| imp_N_223751_avg| imp_N_220645_avg| imp_N_224162_avg|      imp_N_50868_LT|   imp_N_50902_max|     imp_N_50912_std|  imp_N_227465_avg|  imp_N_220645_max|    imp_N_51221_std|  imp_N_227467_avg|  imp_N_220210_avg|   imp_N_51249_avg|     imp_N_51250_LT|     imp_N_220228_TT|   imp_N_51237_min|    imp_N_225677_std|   imp_N_50983_avg|   imp_N_51250_std|   imp_N_223751_TT| imp_N_226253_max|      imp_N_51265_TT|   imp_N_51275_std|     imp_N_50970_std|   imp_N_51237_max|  imp_N_50960_max| imp_N_223770_min|    imp_N_220615_std|   imp_N_51277_avg| imp_N_220047_std|    imp_N_220545_TT|    features_imputed|        demo_feature|            features|DISCH_51881_51851_51884_51853_excl|DISCH_51881_51851_51884_51853_label|\n",
            "+--------+----------+--------------------+-------------------+----------------+------------------+------------------+--------------------+--------------------+--------------------+------------------+------------------+-------------------+-----------------+-----------------+-------------------+-----------------+-----------------+--------------------+----------------+------------------+-----------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------+----------------+--------------------+-----------------+-------------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+-------------------+------------------+--------------------+-----------------+--------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-----------------+-----------------+--------------------+-------------------+--------------------+----------------+-------------------+------------------+------------------+--------------------+-----------------+----------------+-------------------+----------------+--------------------+------------------+----------------+-------------------+----------------+-------------------+--------------------+----------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+----------------+--------------------+------------------+------------------+-------------------+-------------------+-------------------+------------------+----------------+-----------------+------------------+-----------------+------------------+--------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+--------------------+--------------------+-------------------+--------------------+----------------+-----------------+-------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+----------------+------------------+------------------+----------------+--------------------+-----------------+--------------------+-----------------+--------------------+-------------------+--------------------+-------------------+--------------------+------------------+------------------+----------------+-------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+------------------+-------------------+----------------+-------------------+-------------------+------------------+-----------------+-----------------+----------------+-----------------+--------------------+--------------------+--------------------+-------------------+----------------+------------------+-----------------+-------------------+-------------------+--------------------+------------------+--------------------+--------------------+--------------------+-------------------+------------------+----------------+----------------+--------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+------------------+------------------+----------------+-----------------+-----------------+----------------+-------------------+----------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+-----------------+-------------------+-------------------+-----------------+------------------+--------------------+-------------------+-----------------+------------------+--------------------+--------------------+------------------+------------------+----------------+----------------+-----------------+------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+-----------------+--------------------+-----------------+--------------------+-------------------+-------------------+------------------+-------------------+--------------------+-----------------+-----------------+-------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+-----------------+--------------------+----------------+--------------------+------------------+----------------+-----------------+-------------------+--------------------+--------------------+-------------------+-------------------+----------------+------------------+-----------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+-----------------+--------------------+-----------------+-------------------+--------------------+--------------------+-------------------+----------------+--------------------+--------------------+------------------+--------------------+----------------+------------------+------------------+--------------------+-------------------+------------------+----------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+-----------------+-----------------+--------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+-----------------+--------------------+------------------+--------------------+------------------+-----------------+-----------------+--------------------+------------------+-----------------+-------------------+--------------------+--------------------+--------------------+----------------------------------+-----------------------------------+\n",
            "|153202.0|2195-05-21|{2195-05-20 00:00...|0.13065475397959778|             8.9|             125.0|               9.0|  0.0148147169883393| 0.04162341526443389| 0.25736837479277413|              93.0|            75.375| 0.2888504831712819|             12.0|             53.0|0.38626031753797635|              4.1|              0.0|   0.679229372996118|            76.0|               1.9|              8.7| 0.3371881483049508|               0.0|                0.0| 0.8015914916790224|             471.0| 0.9643650760992986| 0.4007957458395112|               0.0|                0.4|16.326121062384175|              29.9|1.477589339794065|0.18596858204010075| 0.4600024796048131|1.4608241195741203|             0.0| 0.47869959975393217|             97.1|                0.0|0.44141736262646103|0.48651583403086374|             26.3|  0.9390680996136072|             102.0|               0.4|              98.0|  0.5873282704184287| 0.38921917141318274| 0.5231770117520154|               0.0|  0.5737610724433981|             2.89|  0.4825208223441543|              8.7| 7.120856494988662| 6.382348705609871|              4.1|              26.3|               1.9|0.21816460208664112|              11.9|             91.0|            100.0| 0.47280115065897854|                0.0|  0.8533746712047077|           120.0|                0.0|               2.6|               1.9| 0.28688053622169907|             35.0|           100.0| 0.5813086081360233|           100.0|  0.3547869743016958|               0.4|             0.0|                0.0|            83.0|0.48908889201931066|                 0.0|            12.0|             471.0| 0.15742229447779182|               0.4|               4.1|  0.3137591402751386|            471.0|            12.0| 0.31484458895558365|0.9738948671571004|16.087061323618695| 2.6127359010984805|0.19593383077174803| 0.4142515026977065|              33.0|           102.0|36.91319672131147|146.66666666666666|             26.3|              26.0|  0.2828588017908533|0.21814832929200006|               2.6|113.95833333333333|              2.89|                0.0|              26.3|16.04014206300184|               2.6| 0.23934979987696609|              40.0|               8.7|             8.9|             102.0|              26.3| 0.4584105459263105|             160.0| 0.08942376662488417|0.009408788879074658| 0.9552881166875579| 0.28199288367483494|            36.0|             11.9| 0.5245125484381217| 0.18687580390398248|                 0.0|              64.0|             156.0|             26.0|  0.6603853135019411|               0.4|             471.0|  0.8617935932847937|63.416666666666664|              8.9| 92.04166666666667|  5.05370463675466|            60.0| 0.981301814901793|              93.0| 0.9509749031237567|             138.0|              8.0|0.5130525664214498|              93.0|              93.0|             91.0| 7.363574011458174|           100.0|0.4906509074508965|              15.5|            11.9|  0.5147367495855483|             85.0|                 0.0|              8.9| 0.47022037610188283|0.12965952398334926|6.924933982718967E-4| 0.5777009663425638|                 0.0|              26.3|              15.5|             8.9|                0.0|              60.0|              4.1|             471.0|               2.6| 0.8032551337067798|               0.0| 0.7063358647907856|1.4457904300423992|0.10907416464600003|            91.0|  0.698483829596674| 0.5691032033576031|              29.9|             2.89|              0.0|             8.9|             90.0| 0.09298429102005037|  0.8475698591732508|  0.2906543040680116| 0.5726742796766917|           102.0|              93.0|37.70331834880121|                0.0| 0.9536459764959693|3.548206420894111...|               2.5|  0.2561239873313129|  0.6825128363987369| 0.28622989668578247| 0.6743762966099016|               0.0|           100.0|            26.0| 0.39186766154349606|             90.0|             12.0|            133.0| 0.4237849295866254|             99.7|             91.0|               0.0| 16.17945696932262|             1.9|              4.1|37.83908909055424|            26.0|0.41496732739917513|             1.9| 0.4594330506661511|               9.0|  0.8053904142934086|               9.0| 0.4016275668533899|              93.0|38.69393271461717|                0.0| 0.9952956055604627|              0.0|  6.76336126164761| 0.23511018805094142|                0.4|              0.0|               0.0|                 0.0| 0.26752923254082395|               4.1| 3.769163995135025|            26.0|           102.0|             85.0|36.781171693735494|             11.9|             29.9|             90.0|                0.0|              0.0|              2.6|            133.0|3.462466991359483...|              9.0| 0.46877014127330285|                0.0| 0.4784520629105555| 0.956904125821111|                0.0|   0.979188292367783|              8.7|95.41666666666667| 0.5350584650816479| 0.10908230104332056| 0.7792913186867695|                0.0|             160.0| 0.7797750402793021| 0.9328320323108141|             89.0|  0.1568795701375693|            90.0| 0.23438507063665143|             120.0|            60.0|              8.7|                0.0|  0.9959158278644086|                 0.0| 0.4884661578947222| 0.4404499194413958|            12.0|              37.5|            133.0|  0.6030323408066521|38.8348594847775|0.9866770743020669|             26.0|  0.3896953305463243| 0.42668733560235383|           120.0|               9.0|             90.0|                 0.0|  0.8546514406466165|             11.9|  0.7095739486033916|              8.0|0.49333853715103343|  0.4708701645239077| 0.34125641819936847| 0.4695340498068036|            22.0| 0.14142940089542666|                 1.0|               9.0| 0.19484766527316216|             8.7|               2.6|              12.0|0.014632153041738868|0.24126041117207714|16.373460837887045|           103.0|0.48486335344055065|0.45745215253325033|            471.0| 0.14099644183741747|              11.9|              33.0|0.033037508972991146|               0.0|0.8705195762144462|  0.9834812455135045|            160.0|            133.0|              8.0| 0.09343790195199124|             102.0|                 0.0|16.227216656547245|             133.0|                0.0|1.4611558651322438|30.291666666666668|              33.0| 0.5335839838445929|  0.5122479746626258|1.4453931203931218|                 0.0|             133.0|               0.0|0.7725206350759527|             85.0|0.008168344271182789| 0.876945766580447|                 0.0|1.4776412776412784|              1.9|             90.0|                 0.0|              15.5|              0.0| 0.5724597933715649|[0.98348124551350...|(166,[0,3,11,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|159536.0|2126-08-02|{2126-08-01 00:00...|                0.0|             9.4|             182.0|              16.0|                 0.0|  0.5372745772832075|  0.4049927972222716|              99.0|             108.8| 0.6797969315397088|30.34493907672786|             77.0|  0.419016389184504|              4.6|              0.0|2.567495753113565E-7|            95.0|               2.2|              9.3|0.38319833098312733|               0.0|                0.0| 0.9242200327996876|             198.0|                0.0| 0.4621100163998438|               0.0| 1.4766575863383713|              12.5|              27.7|              1.1| 0.5441683213580897| 0.1717482576052679|               1.1|             0.0|3.164683433765737...|             96.1|                0.0|0.14297690547548036| 0.3434965152105358|             26.7| 0.31373313619525717|             103.0|1.5093973872734954|              96.1|   0.269321112260169|9.222293721726914E-5| 0.8320230481388723|0.7100483349760915|  0.6415560614258541|             3.34|  0.6194900007990161|              9.3| 6.689544080129826| 5.564171097297422|              4.6|              26.7|               2.2| 0.9464621090323675|               4.8|             80.0|            164.0|  0.2467179393218596|                0.0| 0.17228219609830928|           120.0|                0.0|               4.5|               2.2| 0.32077803071292704|             30.0|           100.0| 0.6392789015831795|           100.0|  0.2648361152354285|1.5046424090338784|             0.0|                0.0|            67.0| 0.3988801527810958|                 0.0|            88.0|             198.0|  0.9984329781712885|1.4406106231702211|               4.6| 0.43250070550679126|            198.0|            88.0|0.003134043657423079|0.9815392365222636|              12.5| 0.6998542122237652|0.23945102402941437|0.12249567860958703|              34.7|           103.0|             24.0|             110.0|             26.7|              25.0|  0.4538385136849273|  0.946286246363002|               4.5|             171.5|              3.34|                0.0|              26.7|             12.5|               4.5|  0.9999984176582831|              30.0|               9.3|             9.4|             103.0|              26.7| 0.1994400763905479|             160.0|  0.4720685067091678|  0.9941658725039509| 0.2360342533545839| 0.45197895889384554|            19.0|              4.8| 0.8332957593383423|  0.5343214914866725|                 0.0|             100.0|             113.0|             25.0|  0.9999998716252123|1.4444584913611462|             198.0|   0.984857258566092|              86.6|              9.4| 68.66666666666667| 2.494438257849294|            50.0| 0.986777781674111|              99.0|0.33340848132331546|             107.0|              8.0|0.5092303817388681|              99.0|              99.0|             80.0|               3.0|           100.0|0.4933888908370555|              15.0|             4.8|  0.8099855944445432|             85.0|                 0.0|              9.4|  0.3961802903516639|                0.0|0.006471966778966359| 0.6404061369205825|                 0.0|              26.7|              15.0|             9.4|                0.0|              50.0|              4.6|             198.0|               4.5| 0.9239600917072498|               0.0| 0.1346605561300845|               1.1|  0.526856876818499|            98.0| 0.1353516001917399|  0.492428629283046|              27.7|             3.34|              0.0|             9.4|             90.0|  0.7279158393209552| 0.38123253524434286|  0.6803605492084103|0.49610616460362017|           103.0|              99.0|             24.0|                0.0| 0.3359539037222554| 0.02463635785660822|               0.0|  0.4024593678809968| 0.10906706397168528| 0.32001147888941067| 0.7663966619662547|               0.0|           100.0|            25.0| 0.47890204805882874|             90.0|29.59090909090909|            139.0| 0.8093837323778286|             96.1|             80.0|               0.0|              12.5|             2.2|              4.6|             24.0|            25.0| 0.1233589696609298|             2.2|0.17062472051108385|              16.0|  0.9999538885313913|              16.0| 0.4619800458536249|              99.0|             24.0|                0.0| 0.5029170637480245|              0.0|6.6211781428987395|  0.8019098548241681| 1.4724647487602325|              0.0|               0.0|                 0.0|  0.5937318817162773|               4.6|2.9760952365713798|            25.0|           103.0|             85.0|              24.0|              4.8|             27.7|             90.0|                0.0|              0.0|              4.5|            139.0|  0.9967640166105168|             16.0|  0.3996434830089294|                0.0|0.48475960000217266|0.9695192000043453|                0.0| 0.26863728864160374|              9.3|99.71428571428571| 0.8125362365674454|  0.5267689454838163| 0.9285115472622598|                0.0|             160.0| 0.9282902966610607|0.06719303231371578|            116.0|  0.4533263359134597|            90.0|  0.8001782584955353|             120.0|            50.0|              9.3|                0.0|   0.508383110843204|                 0.0|0.39887236892500944|0.14341940667787859|            88.0|              30.0|            139.0|  0.2707032003834798|            24.0|0.9905790501718436|             25.0|  0.4739722956341428| 0.08614109804915464|           120.0|              16.0|             90.0|                 0.0|  0.9922123292072403|              4.8|   0.529672230470857|              8.0| 0.4952895250859218| 0.24499135721917406| 0.05453353198584264|0.15686656809762858|            11.0|  0.4335548314340772| 0.01231817892830411|              16.0|  0.2369861478170714|             9.3|               4.5|31.112068965517242|                 0.0|0.30974500039950803|              12.5|            74.0| 0.3412494410221677|0.19943618446250472|            198.0|  0.4343233352150944|               4.8|              34.7|0.013406047436526089|               0.0|               0.0|0.006703023718263044|            160.0|            139.0|              8.0|  0.7328392542566637|             103.0|  0.0302482200664027|              12.5|             139.0|                0.0|               1.1|              15.0|              34.7|0.03359651615685789|  0.8049187357619936|               1.1|                 0.0|             139.0|               0.0| 0.838032778369008|             85.0|   0.983233778313592|               0.0|                 0.0|               1.1|              2.2|             90.0|0.029776204513543382|              15.0|              0.0| 0.6400229577788213|[0.00670302371826...|(166,[0,1,10,14,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|102486.0|2141-07-20|{2141-07-19 00:00...|                0.0|             7.4|             118.0|              12.0|                 0.0| 0.28527572776766313| 0.11517747820980694|              99.0| 62.96153846153846| 0.5500704038677933|             13.0|             37.0|0.36165156269653376|              3.4|              0.0|1.609532975782535...|            73.0|               2.1|              7.9| 0.3034253128759712|               0.0|                0.0| 0.8280376885293362|             269.0|  0.604611904907237| 0.5859811557353318|               0.0|                0.8|              16.5|              27.8|              1.5| 0.6199638177152004| 0.5278229597390028|               1.5|             0.0|9.407003443308672E-6|             96.5|                0.0|0.18832487936730066| 0.9443540805219943|             24.7| 0.41545845588492925|             105.0|               0.8| 97.13333333333333|  0.8094959748838978|0.011258207952841326|0.11361441164105651|               0.0|  0.3418651824064497|             2.85|  0.3897484515890689|              7.9| 9.576923076923077| 8.178211057112343|              3.4|              24.7|               2.1|0.21816460208664112|              10.6|             87.0|             82.0|0.005928443580563616|                0.0|  0.1897631695704932|           120.0|                0.0|               2.9|               2.1| 0.17093259120322485|             30.0|           100.0| 0.8976366291296707|           100.0|  0.8180545575122569|               0.8|             0.0|                0.0|            70.0|  0.924140058910544|                 0.0|            13.0|             269.0| 0.17029535686832742|               0.8|               3.4|  0.3397684387664792|            269.0|            13.0| 0.34059071373665484|0.9680307246992478|              16.5| 1.8401344175239518|0.23945102402941437|  0.996660567933498|              32.1|           105.0|             60.7|151.38370222803474|             24.7|              19.0| 0.49040166949984454|0.21814832929200006|               2.9| 97.11538461538461|              2.85|                0.0|              24.7|             16.5|               2.9|4.703501721654336E-6|              30.0|               7.9|             7.4|             105.0|              24.7|  0.537929970544728|             160.0| 0.21294704427559902|  0.4958161604191571|0.10647352213779951|  0.4894491185800768|            28.0|             10.6|0.11379437944827117|   0.625578218093795|                 0.0|              35.0|178.49948822927328|             19.0|8.047664878912676E-5|               0.8|             269.0| 0.23907235505648927|              53.5|              7.4| 79.61538461538461|7.2274951671054435|            50.0|0.9771005412364924|              99.0|0.22758875889654234|127.71084953940634|              8.0| 0.515984637650376|              99.0|              99.0|             87.0| 19.70452579251507|           100.0|0.4885502706182462|              18.0|            10.6| 0.23035495641961387|             85.0|                 0.0|              7.4|  0.6353988240798489|                0.0|  0.1761690015719151| 0.8998591922644134|                 0.0|              24.7|              18.0|             7.4|                0.0|              50.0|              3.4|             269.0|               2.9| 0.8321581944717855|               0.0| 0.5952520125580512|               1.5|0.10907416464600003|            93.0| 0.5882873748526358|0.11953617752824464|              27.8|             2.85|              0.0|             7.4|             90.0|  0.3099819088576002|  0.4487228200802237|  0.5511816854351647|0.12153457193935024|           105.0|              99.0|            66.85|                0.0|0.22722882328211302|6.966582880204182E-4|               0.0| 0.11512114991246207|0.044142363530349005| 0.17068183734445713| 0.6068506257519424|               0.0|           100.0|            19.0| 0.47890204805882874|             90.0|             13.0|            133.0|0.22436141004011184|             98.4|             87.0|               0.0|              16.5|             2.1|              3.4|            66.85|            19.0| 0.9970357782097182|             2.1| 0.5307242995796353|              12.0|0.005629103976420663|              12.0| 0.5839209027641072|              99.0|             73.0|                0.0| 0.7520919197904214|              0.0| 6.834584000620554| 0.31769941203992447|                0.8|              0.0|               0.0|                 0.0|  0.2430530355475481|               3.4|2.4654416170057454|            19.0|           105.0|             85.0|              60.7|             10.6|             27.8|             90.0|                0.0|              0.0|              2.9|            133.0|  0.9119154992140425|             12.0|  0.6332838797950224|                0.0|0.47361569343253623|0.9472313868650725|                0.0| 0.14263786388383157|              7.9| 97.8076923076923| 0.4861060710950962| 0.10908230104332056|0.09416243968365033|                0.0|             160.0| 0.0960885863228818| 0.5404647089190597|             77.0|  0.1698842193832396|            90.0|  0.3166419398975112|             120.0|            50.0|              7.9|                0.0|  0.7592155070105975|                 0.0| 0.9275073699266075| 0.1921771726457636|            13.0|              30.0|            133.0|  0.8234252502947285|            73.0|0.9836831939012491|             19.0|  0.4739722956341428|  0.0948815847852466|           120.0|              12.0|             90.0|                 0.0|  0.2430691438787005|             10.6|  0.3638908849754864|              8.0|0.49184159695062457|0.006678864133004063|0.022071181765174502|0.48473795362972405|            17.0| 0.24520083474992227|  0.9996516708559898|              12.0|  0.2369861478170714|             7.9|               2.9|              13.0|                 0.0|0.19487422579453445|              16.5|            94.0| 0.9385514008407294| 0.5362463150366963|            269.0|  0.2447245592900384|              10.6|              32.1|  0.0896588765165506|               0.0| 6.149999999999999|  0.0448294382582753|            160.0|            133.0|              8.0|  0.3127891090468975|             105.0|                 0.0|              16.5|             133.0|                0.0|               1.5|23.192307692307693|              32.1|0.27023235445952987| 0.23024229982492414|               1.5|                 0.0|             133.0|               0.0|0.7233031253930675|             85.0| 0.48156898597880493| 6.149999999999999|                 0.0|               1.5|              2.1|             90.0|                 0.0|              18.0|              0.0|0.34136367468891426|[0.04482943825827...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|149546.0|2155-02-08|{2155-02-07 00:00...|                0.0|             7.8|138.94057916509965|              12.0|                 0.0|  0.1496787525087407|  0.5677343256979304|             183.0| 74.77826247362239|0.10763011189452963|             31.0|47.70463975858167|  0.426930727592382|              3.5|              0.0| 0.20718381381747253|78.0369671821954|               1.7|              9.9|0.38319833098312733|               0.0|                0.0| 0.8015914916790224|             202.0|0.31874754901018426| 0.4007957458395112|               0.0|                1.0|              15.9|              30.2|              1.4| 0.6199638177152004|0.46701465347425664|               1.4|             0.0| 0.19619776364057873|             95.5|                0.0|0.44753280614666313| 0.9340293069485133|             29.1| 0.41545845588492925|             102.0|               1.0| 96.02000000000001|  0.8638571815134771| 0.22323189276593913|0.15227043484729885|               0.0|  0.9072741796744047|             3.28|  0.6194900007990161|              9.9|11.487286830973543| 8.168515431713185|              3.5|              29.1|               1.7|  0.714557794942773|              10.3|             89.0|97.67732230161715|  0.2872524231483276|                0.0|  0.9809592404305372|           120.0|                0.0|               2.6|               1.7|  0.5463629101627976|             30.0|           100.0|0.21813709089826688|           100.0|  0.3174428980309364|               1.0|             0.0|                0.0|            77.0| 0.8890503192515382|                 0.0|            31.0|             202.0| 0.49405282941353673|               1.0|               3.5|  0.9959011481158101|            202.0|            31.0|  0.9881056588270735|0.9815392365222636|              15.9|0.45175395145262565| 0.9140790661626669|0.14250626275444325|              34.2|           102.0|             25.3|151.38370222803474|             29.1|              27.0|  0.6188162389705184|  0.714656964940277|               2.6|117.87633609613528|              3.28|                0.0|              29.1|             15.9|               2.6|   0.472376144412589|              30.0|               9.9|             7.8|             102.0|              29.1| 0.4445251596257691|160.55733211512106|  0.4720685067091678|  0.9638900806513879| 0.2360342533545839|  0.6178960502701973|            12.0|             10.3|0.15257210330660537|   0.625578218093795|                 0.0|60.782215523737754|178.49948822927328|             27.0|  0.4711329744042347|               1.0|             202.0|  0.7134994830130421| 61.39591571522619|              7.8| 86.33333333333333| 8.711422896914653|            60.0|0.9745232284758952|             183.0|0.30514420661321073|127.71084953940634|              8.0|0.5092303817388681|             183.0|             183.0|             89.0| 19.70452579251507|           100.0| 0.491807068783402|              15.3|            10.3|  0.8645313486041392|85.00246212121212|                 0.0|              7.8| 0.47022037610188283|                0.0|0.006471859609530...|0.21526022378905926|                 0.0|              29.1|              15.3|             7.8|                0.0|              60.0|              3.5|             202.0|               2.6| 0.8032551337067798|               0.0| 0.5680714092432615|               1.4| 0.3573284824701385|            99.0| 0.5614410652003854| 0.6432502584934789|              30.2|             3.28|              0.0|             7.8|             90.0|  0.3099819088576002|  0.5744044309274503| 0.10906854544913344| 0.6465904979035804|           102.0|             183.0|             25.3|                0.0| 0.3045408696945977|5.845218422829997E-4|               0.0|  0.5641055546303895|2.011716691154084...|  0.5449646922845189| 0.7663966619662547|               0.0|           100.0|            27.0| 0.17184186767466622|             90.0|             31.0|            137.0| 0.7127977845362748|             96.3|             89.0|               0.0|              15.9|             1.7|              3.5|             25.3|            27.0| 0.1436262115741638|             1.7| 0.4692157220967054|              12.0| 0.48581197505212126|              12.0| 0.4016275668533899|             183.0|             25.3|                0.0|  0.518054959674306|              0.0| 8.132272964076716| 0.23511018805094142|                1.0|              0.0|               0.0|0.002728073736398...|   0.548877544645678|               3.5|               0.0|            27.0|           102.0|84.99962121212121|              25.3|             10.3|             30.2|90.01611459265891|                0.0|              0.0|              2.6|            137.0|  0.9967640701952347|             12.0| 0.46877014127330285|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.9251606237456297|              9.9|99.71428571428571|  0.902244910708644|  0.3572788974713865|0.22376640307333157|                0.0|160.30150753768845|0.22640214539090547| 0.7918405167998113|90.91899020346646| 0.49795057405790505|90.0066025067144| 0.23438507063665143|             120.0|            60.0|              9.9|                0.0|  0.5237159142692422|0.007491553859143...| 0.8865360792227868|0.45280429078181095|            31.0|              30.0|            137.0|  0.8771178695992291|            25.3|0.9905790501718436|             27.0| 0.19291933244858292|  0.4904796202152686|           120.0|              12.0|90.00044762757386|                 0.0|  0.7068190041928392|             10.3|  0.6348857960618728|              8.0| 0.4952895250859218|  0.2850125255088865|1.005858345577042...|0.48473795362972405|            12.0|  0.3094081194852592|2.922609211414998...|              12.0|  0.9035403337757085|             9.9|               2.6|              31.0|                 0.0|0.30974500039950803|              15.9|            99.0| 0.9384314441934108| 0.4432680396113934|            202.0| 0.30894802513509867|              10.3|              34.2|  0.8401739988337379|               0.0|               0.0|   0.579913000583131|160.4163621135982|            137.0|              8.0|  0.3127891090468975|             102.0|                 0.0|              15.9|             137.0|                0.0|               1.4|              12.0|              34.2|0.39592025839990563|  0.8717888907392212|               1.4|                 0.0|             137.0|               0.0|0.7269868524702858|85.00530303030303|  0.9525681714615156|               0.0|                 0.0|               1.4|              1.7|             90.0|                 0.0|              15.3|              0.0| 0.9100706154309621|[0.57991300058313...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|111375.0|2135-04-04|{2135-04-03 00:00...|                0.0|             8.1|             149.0|              14.0|  0.0148147169883393|  0.5602141238488558|  0.5007014305921953|120.72483482316362|              78.5|0.48713427104996304|30.34493907672786|             41.0|  0.426930727592382|              3.4|              0.0|  0.5592490181072254|            43.0|2.0192751891676624|9.720783890168976| 0.3371881483049508|               0.0|                0.0|0.46900135508873325|204.55184887459808|                0.0| 0.4976453997824787|0.4203854376206732| 1.4766575863383713|16.326121062384175|30.123507616302994|              1.1| 0.9558889475438066| 0.1783015799355559|1.4608241195741203|             0.0| 0.04969568184349138|             96.8|0.15238186232786088| 0.4720913015670395| 0.3566031598711118|             28.6| 0.35182833735787733|103.13290175171363|1.5093973872734954|              96.8| 0.48196839886325465|0.026929756396005068|0.11361441164105651|0.7100483349760915| 0.45219772949982334|3.250759740695953|  0.4825208223441543|              9.9| 4.109609335312651|18.980252896102307|              3.4|28.889421157684648|               2.5|0.47292877765230995|  9.43330216554195|90.84011276681434|            139.0|  0.4782614367924135|0.08596788964012393| 0.47373916357820256|           120.0|                0.0|               3.2| 2.056371584077676|  0.5286978729187907|             30.0|           100.0|0.13656657361269778|            95.0|  0.4709935406778632|               0.5|             0.0|0.06995517975068115|            70.0| 0.3988801527810958|                 0.0|            16.0|             287.0| 0.21282318310624115|               0.5|4.1610394537177555| 0.43250070550679126|206.9605004019292|            16.0|  0.4256463662124823|0.9738948671571004|              12.6|  1.632993161855452|0.46314413213559713| 0.4142515026977065|33.248717948717946|            99.0|36.91319672131147|              98.0|             28.6|25.074626865671643|  0.3281425073977985|  0.714656964940277|               3.2|143.66666666666666|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|3.4006276150627603|  0.9751521590782544|              30.0|               9.9|             8.1|103.59088827838833|              28.6| 0.1994400763905479|160.55733211512106|  0.3091690311323449| 0.39427655072486156|0.15458451556617245| 0.45197895889384554|            22.0|9.599003202562052|0.48414255054546573| 0.46370842439089255|0.051237573780987374|              63.0|              98.0|25.83084577114428|  0.7203754909463873|1.4444584913611462|209.46905144694534|  0.4752646286819739|              42.0|8.429773195876288|              71.0|               1.0|            55.0|0.9745232284758952|132.22386319471434| 0.4773693026559077|              98.0|              8.0|0.5130525664214498|120.49256068911511|126.38537745451853|90.55054369714055|               0.0|           100.0| 0.491807068783402|16.114291481631014|9.21408502024291| 0.47109294943321767|85.00246212121212|0.022153573700935885|8.320536082474234|   0.475782102493217|0.12965952398334926|0.004019416683953692|0.46459083063785256| 0.03490935761855885| 29.31268022684791|16.177069035123125|             8.1|0.02918013555493569|              55.0|4.068660082014597|             287.0|3.5946443514644364| 0.4775870080559247| 4.798857346195361| 0.4686834829104542|               1.1| 0.3573284824701385|            91.0|0.46784589154325545|   0.51281308899984|30.178889460683365|3.274385328496573|              0.0|8.37549739813451|             90.0|  0.5220555262280967|  0.4894464120957203|  0.9317167131936511| 0.6465904979035804|            99.0|125.57075735540884|             30.2|                0.0|0.22722882328211302|  0.2929552677201489|               0.0|  0.5641055546303895| 0.28300602368577227| 0.49680314683739135| 0.6743762966099016|0.3717226033966161|           100.0|            27.0|  0.4831275084671001|             90.0|29.59090909090909|            137.0| 0.4729044061266951|             96.8|90.69301248489731|               0.0| 16.17945696932262|             2.5|3.977200303490134|37.83908909055424|            27.0|0.23913071839620675|             2.5| 0.4594330506661511|              14.0|0.013464878198002534|              14.0|0.23879350402796234|130.73140172278778|             30.2|0.07060400796808293| 0.8028617246375692|              0.0| 0.816496580927726| 0.47827446509141863|                0.5|2.297622738931195|0.3525454384054092|0.002728073736398...|  0.5043438780045272|               3.4| 3.344772040064913|            27.0|            99.0|84.99962121212121|              30.2|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|              0.0|              3.2|138.3512996941896|0.002009708341976846|13.55895896170368|  0.8183048093200608|0.36128275365036766| 0.4784520629105555| 0.956904125821111|0.12368084276523614|  0.7198929380755721|9.644677419354842|             93.0|0.46473433340591286|  0.5004252396055716| 0.5084698186832426|0.05272455247871184|160.30150753768845|0.36857957876464764|0.47024088066356073|            111.0|  0.4533263359134597|            90.0|  0.4091524046600304|             120.0|            55.0|9.796491935483868|                0.0|   0.506758958686583|                 0.0| 0.4884661578947222| 0.7371591575292953|            16.0|              30.0|139.1452599388379|  0.4838445299068336|38.8348594847775|0.9866770743020669|25.46104914985511| 0.47954800041801254| 0.49055292792469574|           120.0|13.177351247600768|             90.0|                 0.0|  0.7068190041928392|9.539477732793522|  0.4579845075940477|              8.0|0.49333853715103343|  0.4708701645239077| 0.14150301184288613|0.17591416867893866|            13.0| 0.16407125369889924| 0.14647763386007445|13.949328214971208|  0.4602773778694809|             9.9|3.4959720063757715|31.112068965517242|                 0.0|0.24126041117207714|              12.6|            72.0|0.48486335344055065|0.45745215253325033|            287.0|  0.4343233352150944| 9.375520512820508|33.100986193293885| 0.08351638591410156| 5.296645179203497|               0.0| 0.04175819295705078|160.4163621135982|            137.0|              8.0| 0.46799099320339343|104.03693830921554|  0.0302482200664027|              12.6|             137.0| 0.3720366581314043|               1.1|             16.75| 33.17546745562131| 0.4987639065100168|  0.8717888907392212|1.4453931203931218|                 0.0|138.75297937600118|0.1363245068214134|0.7269868524702858|85.00530303030303|  0.4866650863530708| 0.876945766580447|  0.0911977288017119|1.4776412776412784|2.093508562325766|             90.0|                 0.0| 16.14547301843629|              0.0| 0.9936062936747827|[0.04175819295705...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|190933.0|2179-05-06|{2179-05-05 00:00...|                0.0|             8.0|             153.0|               7.0|                 0.0|0.057278801648846335|  0.5677343256979304|             116.0| 79.20833333333333| 0.5500704038677933|             19.0|             56.0|0.38626031753797635|              4.3|              0.0| 0.09675591595982397|            88.0|               2.1|              9.9| 0.3034253128759712|               0.0|                0.0| 0.8015914916790224|             190.0|0.42687494916218766| 0.4007957458395112|               0.0|                1.3|              15.5|              32.3|              1.5|0.06099136445681324| 0.4268135584383741|               1.5|             0.0|   0.269874854997331|             98.4|                0.0| 0.6301718789138533| 0.8536271168767482|             29.9|  0.5398417522311024|             102.0|               1.3| 99.03333333333332| 0.30065261692383516|0.004492087021199578| 0.6626731324989932|               0.0|  0.7561972406006011|             3.05|0.005037189085355657|              9.9|15.184741976368544| 9.526188318991437|              4.3|              29.9|               2.1| 0.9464621090323675|               5.1|             98.0|             83.0|  0.6280738235650517|                0.0|  0.2701707007750812|           120.0|                0.0|               2.7|               2.1|  0.6219013796996995|             30.0|           100.0| 0.8976366291296707|           100.0| 0.04421492552303007|               1.3|             0.0|                0.0|            65.0|  0.924140058910544|                 0.0|            19.0|             190.0|  0.2609818352397814|               1.3|               4.3|  0.5233774772761552|            190.0|            19.0|  0.5219636704795628|0.9738948671571004|              15.5| 1.5231546211727816| 0.3865822674435661| 0.3107236091383373|              33.0|           102.0|             33.3|129.66666666666666|             29.9|              34.0|  0.8342110872286047|  0.946286246363002|               2.7|112.08333333333333|              3.05|                0.0|              29.9|             15.5|               2.7|  0.1349374274986655|              30.0|               9.9|             8.0|             102.0|              29.9|  0.537929970544728|             160.0|  0.3091690311323449|  0.9453009530699499|0.15458451556617245|  0.8334373893315923|            28.0|              5.1|  0.664149413571955|0.060887183075146165|                 0.0|              66.0|             154.0|             34.0|   0.951622042020088|               1.3|             190.0|  0.0857324151258644|            69.375|              8.0| 78.20833333333333| 9.251032224688347|            55.0|0.9745232284758952|             116.0|   0.67170117285609|             109.0|              8.0|0.5130525664214498|             116.0|             116.0|             98.0| 18.55322673343433|           100.0| 0.491807068783402|              12.9|             5.1|  0.8645313486041392|85.00246212121212|                 0.0|              8.0|  0.5225219629359406|                0.0|  0.4888857989399821| 0.8998591922644134|                 0.0|              29.9|              12.9|             8.0|                0.0|58.333333333333336|              4.3|             190.0|               2.7| 0.8032551337067798|               0.0|0.15032630846191758|               1.5|  0.526856876818499|            94.0|0.15081504517481623| 0.9571337924370678|              32.3|             3.05|              0.0|             8.0|             92.0| 0.03049568222840662|  0.8475698591732508|  0.5511816854351647| 0.9578671679188786|           102.0|             116.0|             33.3|                0.0| 0.6746537350020136|   0.422268861898241|               0.0|  0.5641055546303895| 0.13280217786032092|  0.6203836768157764| 0.6068506257519424|               0.0|           100.0|            34.0|  0.7731645348871322|             92.0|             19.0|            139.0| 0.4237849295866254|             99.8|             98.0|               0.0|              15.5|             2.1|              4.3|             33.3|            34.0|0.31403691178252585|             2.1|0.42852561497701547|               7.0|  0.9977539564894002|               7.0| 0.4016275668533899|             116.0|             33.3|                0.0|0.47265047653497494|              0.0| 8.489270188498734|  0.2612609814679703|                1.3|              0.0|               0.0|0.002728073736398...|  0.3762146866068509|               4.3| 4.667968568398416|            34.0|           102.0|84.99962121212121|              33.3|              5.1|             32.3|             90.0|                0.0|              0.0|              2.7|            139.0| 0.24444289946999104|              7.0|  0.5208562344507215|                0.0| 0.4784520629105555| 0.956904125821111|                0.0|  0.9713605991755768|              9.9|             96.8| 0.7524293732137018|  0.5267689454838163|0.31508593945692664|                0.0|             160.0| 0.3177504216415489|0.19263200419169912|            105.0|  0.2616887386380776|            90.0| 0.26042811722536074|             120.0|            60.0|              9.9|                0.0| 0.47770299815503436|                 0.0| 0.9275073699266075| 0.6355008432830977|            19.0|              30.0|            139.0| 0.30163009034963245|            33.3|0.9866770743020669|             34.0|  0.7583789029340601|  0.8649146496124593|           120.0|               7.0|             90.0|                 0.0|  0.0842656641622429|              5.1| 0.08842985104606015|              8.0|0.49333853715103343|  0.6214472182766746|  0.9335989110698395| 0.2699208761155512|             8.0| 0.41710554361430235|  0.2111344309491205|               7.0| 0.37918945146703004|             9.9|               2.7|              19.0|                 0.0| 0.9974814054573222|              15.5|           102.0| 0.8570512299540309| 0.5362463150366963|            190.0| 0.41671869466579614|               5.1|              33.0|0.039727230996929895|               0.0|               0.0|0.019863615498464948|            160.0|            139.0|              8.0|0.030443591537573082|             102.0|                 0.0|              15.5|             139.0|                0.0|               1.5|18.708333333333332|              33.0| 0.9036839979041504|  0.8717888907392212|               1.5|                 0.0|             139.0|               0.0|0.7725206350759527|85.00530303030303|  0.9554059963100687|               0.0|                 0.0|               1.5|              2.1|             92.0|                 0.0|              12.9|2.357022603955158| 0.7592326463684471|[0.01986361549846...|(166,[0,2,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|153202.0|2195-04-29|{2195-04-28 00:00...|  0.408248290463863|           8.625|             140.0|              10.5|0.047140452079103105| 0.04162341526443389|  0.8431024015484478|             164.0| 68.08333333333333|0.27374663159948043|              8.5|             56.0|  0.419016389184504|            3.925|              0.0|  0.1659286917366149|            74.0|               1.8|             10.5| 0.3371881483049508|0.8640987597877147| 0.6057020719792857| 0.6712194574650666|              66.0|  0.696818165345563| 0.3356097287325333| 1.920286436967152|0.42500000000000004|              15.7|              31.2|              1.4|0.06902322717598802|0.32575197775339026|1.3333333333333333|             0.0|0.001768947919892...|             98.3| 1.9362047641943474|0.43838383105788703| 0.6515039555067805|             29.1|0.008098527062300609|              99.0|               0.5| 99.76666666666667|  0.8494628281506669|  0.9525129301560137|0.30278713523977224|               1.5| 0.40557024194924596|3.276666666666667|  0.6194900007990161|             11.7|14.522013940527977| 6.861223570828231|              4.6|              29.1|1.9749999999999999| 0.8490206736979797|10.033333333333333|             94.0|             84.0|  0.6052527037538802| 0.6057020719792857|    0.12404305925363|           120.0|                0.5|              3.45|             1.975|   0.797214879025377|             30.0|           100.0| 0.5532977763525597|           100.0|  0.9349046060342232|               0.5|             1.5| 0.8178562764256864|            83.0|  0.608193204587065| 0.10897247358851685|             7.0| 72.66666666666667|0.008790211551509018|               0.4|               4.6|0.017159653494764907|72.66666666666667|             8.5|0.017580423103018036|0.9738948671571004|              14.7|  2.196904387744011| 0.9998288078963181|0.29614535867609537|              35.3|           104.0|             32.6|             233.0|             33.2|              28.0|0.035786285288719695| 0.8493151428602235|               4.0| 96.33333333333333|               3.1|                0.0|              33.2|             14.7|               3.1|8.844739599462277E-4|              35.0|10.499999999999998|             8.8|            102.25|30.600000000000005| 0.3040966022935325|             160.0|  0.9110001498850737| 0.04067212149795718|0.45550007494253686|0.035451976506521564|            28.0|             12.2| 0.3047091003597849| 0.07066746085710292| 0.12990381056766592|              57.0|             292.0|             31.0| 0.08296434586830745|               0.4|              77.0| 0.08925251206302239| 61.09090909090909|              8.8|              96.5| 6.123724356957945|            60.0| 0.981301814901793|             244.0| 0.6094182007195698|             190.0|              8.0|0.5130525664214498|             164.0|            200.25|             93.0| 43.15089802078283|           100.0|0.4906509074508965|              17.7|             7.5|  0.3137951969031044|             85.0| 0.20237478982214055|              8.5|  0.9689128468503373|  0.408248290463863| 0.15261931459751882| 0.5474932631989609| 0.10897247358851685|30.600000000000005|              18.1|             8.5| 0.1699673171197603|              60.0|            3.925|              77.0|               4.0| 0.6734540407572737|35.765730804780155| 0.5752685859246666|               1.3|0.42465757143011174|            92.0| 0.5644714692735042| 0.9553737439684888|31.900000000000002|             3.56|1.920286436967152|           8.625|             90.0| 0.03451161358799401| 0.29599038671453903| 0.27664888817627986| 0.9569803168927646|          102.25|            200.25|35.86666666666667|  1.845715759987618| 0.6055742704795445|6.188307332960431E-4|               2.5|  0.8381016513907719|0.004238520562854932|  0.7950601880596517| 0.6743762966099016|  0.82915619758885|           100.0|            28.0|3.423842073637671...|             90.0|              7.0|            137.0| 0.8520048066427305|            100.5|93.33333333333333|  0.82915619758885|15.199999999999998|             1.8|              3.0|35.86666666666667|            29.5| 0.3026263518769401|             2.1| 0.3279293138286811|              11.0|  0.5237435349219932|              10.0|0.33672702037863683|             244.0|             38.4| 0.8640987597877147|0.02033606074897859|4.784233364802441|  4.99917348540637| 0.48445642342516865|0.42500000000000004|4.784233364802441| 1.118033988749895|                 0.0|  0.5799360825996185|               3.0|3.2121189787013393|            31.0|            99.0|             85.0|              32.6|              7.5|             32.8|             90.0| 1.9362047641943472|1.118033988749895|              3.1|            137.0| 0.07630965729875941|             10.5|  0.9624065679270641|                0.5|0.48475960000217266|0.9695192000043453|                0.0|   0.979188292367783|              9.7|96.41666666666667| 0.8401278348007629| 0.42451033684898987| 0.7808080844710565| 0.6683312551921131|             160.0| 0.7828239690976695| 0.3955696577933736|             86.0|0.008579826747382453|            90.0| 0.48120328396353207|             120.0|            60.0|             11.7|0.12990381056766592|0.020152374101803705|                 0.0| 0.6051932225998237| 0.4343520618046611|            10.0|              32.5|            139.0|  0.8710570614529914|            38.4|0.9866770743020669|             29.5|6.042135353805138E-4|   0.937978470373185|           120.0|              10.0|             90.0|                 0.0|  0.0860393662144708|             12.2| 0.13019078793155348|              8.0|0.49333853715103343|  0.5922907173521907|  0.9978807397185725| 0.9959507364688497|            14.0|0.017893142644359847|   0.999690584633352|              11.0|  0.9996978932323097|             9.7|              3.45|              10.0|0.047140452079103105|0.30974500039950803|              15.7|           107.0| 0.6558586276573622|0.30259661129991183|             66.0|0.017725988253260782|10.033333333333333|              33.3|4.989014219217635E-4|35.765730804780155|2.4239545283597113|  0.9997505492890392|            160.0|           138.25|              8.0| 0.03533373042855146|             104.0|0.043301270189221926|15.199999999999998|             139.0|  1.845715759987618|1.3333333333333333|            23.375|34.266666666666666| 0.8022151711033132|  0.3237966972184563|               1.3| 0.33541019662496846|            138.25|0.4714045207910317| 0.838032778369008|             85.0| 0.04030474820360741|2.4239545283597113| 0.33541019662496846|               1.4|              2.1|             90.0|0.043301270189221926|17.933333333333334|              0.0|0.40987962388069654|[0.99975054928903...|(166,[0,3,11,13,5...|[0.99975054928903...|                               0.0|                                0.0|\n",
            "|192399.0|2152-11-20|{2152-11-19 00:00...|                0.0|             8.4|138.94057916509965|               7.0|                 0.0|   0.382950425126365|  0.3529159189500134|             130.0| 74.77826247362239| 0.2888504831712819|             22.0|47.70463975858167|  0.426930727592382|              4.9|              0.0| 0.20718381381747253|78.0369671821954|               1.9|              9.1| 0.3371881483049508|               0.0|                0.0|0.13349940828805268|             189.0|  1.078579312490896|0.06674970414402634|               0.0|                0.4|              13.4|              25.4|              1.1|0.06099136445681324| 0.2362347480348828|               1.1|             0.0| 0.19619776364057873|             96.1|                0.0| 0.9404912526956775| 0.4724694960697656|             26.6|  0.9570763498264294|              94.0|               0.4|              98.0|  0.2899493992878918| 0.22323189276593913|  0.933775530824686|               0.0|   0.499365353901846|              3.6|  0.4825208223441543|              9.1|11.487286830973543| 8.168515431713185|              4.9|              26.6|               1.9| 0.3100940370970886|               5.0|90.84011276681434|97.67732230161715|  0.4344678286732502|                0.0|0.009385393945498236|           120.0|                0.0|               3.0|               1.9|   0.249682676950923|             30.0|           100.0| 0.5813086081360233|           100.0|  0.4334657180999039|               0.4|             0.0|                0.0|            62.0| 0.3988801527810958|                 0.0|            22.0|             189.0|  0.3142024319562725|               0.4|               4.9|    0.63129818205617|            189.0|            22.0|   0.628404863912545|0.9738948671571004|              13.4| 1.3481839637082174| 0.5229352225169951|0.21515138439841197|              34.3|            94.0|             29.2|             147.0|             26.7|              38.0|  0.2828588017908533| 0.3100943452944951|               3.0|117.87633609613528|               3.6|                0.0|              26.7|             13.4|               3.0|   0.472376144412589|              40.0|               9.1|             8.4|              94.0|             26.65| 0.1994400763905479|160.55733211512106|  0.4275832354176189|  0.9377493143624959| 0.7862083822911905| 0.28199288367483494|            18.0|              5.0| 0.9345585982645828|0.060887183075146165|                 0.0|60.782215523737754|             154.0|             38.0|  0.4711329744042347|               0.4|             189.0|0.012774276706124677| 61.39591571522619|              8.4|              68.5| 8.426149773176359|            50.0| 0.981301814901793|             139.0|0.13088280347083456|             140.0|              8.0|0.5130525664214498|             130.0|             134.5|90.55054369714055|               7.0|           100.0|0.4906509074508965|              15.9|             5.0|  0.7058318379000268|             85.0|                 0.0|              8.4|  0.6954431369445988|                0.0| 0.28432187610548393| 0.5777009663425638|                 0.0|             26.65|              15.9|             8.4|                0.0|              50.0|              4.9|             189.0|               3.0|0.13928096576623245|               0.0| 0.1449746996439459|               1.1|0.15504717264724754|            94.0|0.14553486893706977| 0.9936128616469376|              25.4|              3.6|              0.0|             8.4|             90.0| 0.03049568222840662|  0.5323719280239783|  0.2906543040680116| 0.9937482742314291|            94.0|             130.0|             29.2|0.04999999999999894|0.13244893835062796|1.348819913327819...|               5.0| 0.35081975965318957|  0.6825190749297709| 0.24873446274435135| 0.6743762966099016|               0.0|           100.0|            38.0|  0.9541295549660098|             90.0|             22.0|            134.0| 0.7338140359880109|             99.6|90.69301248489731|               0.0|              13.4|             1.9|              4.9|             29.2|            38.0| 0.2172339143366251|             1.9|0.23568464098766218|               7.0| 0.48581197505212126|               7.0|0.06964048288311622|             130.0|             29.2|                0.0|0.46887465718124793|              0.0| 8.132272964076716|  0.3477215684722994|                0.4|              0.0|               0.0|                 0.0|  0.7680859606806065|               4.9| 1.562916611125921|            38.0|            94.0|             85.0|              29.2|              5.0|             25.4|90.01611459265891|                0.0|              0.0|              3.0|            134.0|   0.857839061947258|              7.0|  0.6931015094555795|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.1914752125631825|              9.1|            97.68|0.46382807863878706|  0.1550470185485443| 0.5297543736521613|                0.0|160.30150753768845| 0.5316972155492664|0.47024088066356073|90.91899020346646|   0.315649091028085|90.0066025067144| 0.34655075472778973|             120.0|            50.0|              9.1|                0.0|   0.473873539291878|0.007491553859143...|0.39887236892500944| 0.9366055689014672|            22.0|              35.0|            134.0| 0.29106973787413953|            29.2|0.9866770743020669|             38.0|  0.8465201023477212|0.004692696972749118|           120.0|               7.0|90.00044762757386|                 0.0|0.012503451537141734|              5.0|  0.8669314361998078|              8.0|0.49333853715103343| 0.43030276879682394| 0.34125953746488547| 0.4785381749132147|             9.0| 0.14142940089542666|6.744099566639096...|               7.0|  0.5767399488261393|             9.1|               3.0|              22.0|                 0.0|0.24126041117207714|              13.4|           106.0|0.47136928197532435|0.19943618446250472|            189.0| 0.14099644183741747|               5.0|              34.3|5.867880230609641E-7|               4.5|               0.0|2.933940115304820...|160.4163621135982|            134.0|              8.0|0.030443591537573082|              94.0|                 0.0|              13.4|             134.0|0.04999999999999894|               1.1|            12.125|              34.3| 0.4987639065100168|  0.7016395193063791|               1.1|                 0.0|             134.0|0.1363245068214134|0.7269868524702858|             85.0|   0.947747078583756|               0.0|                 0.0|               1.1|              1.9|             90.0|                 0.0|              15.9|              0.0| 0.4974689254887027|[2.93394011530482...|(166,[0,2,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|\n",
            "|192031.0|2156-01-13|{2156-01-12 00:00...|                0.0|             8.8|             107.0|              16.0|                 0.0|   0.382950425126365| 0.27995452739864224|             245.0|              69.0| 0.6797969315397088|             83.0|             57.0|  0.426930727592382|              4.5|              0.0|  0.7345681439735754|            57.0|               2.2|              8.8| 0.3371881483049508|               0.0|                0.0| 0.8015914916790224|             208.0| 0.9603240193925283| 0.4007957458395112|               0.0|                3.4|              14.8|              29.2|              1.4| 0.5441683213580897| 0.3584920829189963|               1.4|             0.0|  0.6571337059718874|             96.5|                0.0| 0.5281843266082891| 0.7169841658379926|             26.5|  0.5548448754664719|             102.0|               3.4| 97.46666666666668| 0.04265072686571611|  0.7951496277877806| 0.7827139078451968|               0.0|  0.6072360034596276|             3.01|  0.4825208223441543|              8.8|               0.0|               0.0|              4.5|              26.5|               2.2| 0.9464621090323675|              18.3|             88.0|            107.0|  0.5149651415231561|                0.0|   0.575242294926473|           120.0|                0.0|               5.3|               2.2|  0.3036180017298138|             30.0|           100.0| 0.6392789015831795|           100.0| 0.49445409396101137|               3.4|             0.0|                0.0|            65.0| 0.8890503192515382|                 0.0|            83.0|             208.0|  0.9964707149631455|               3.4|               4.5|0.006206086595056...|            208.0|            83.0|0.007058570073708911|0.9738948671571004|              14.8|  2.724792588294953| 0.9981109669028437|  0.254876925303715|              33.1|           102.0|             31.0|             172.0|             26.5|              26.0| 0.07061754250774531|  0.946286246363002|               5.3|             107.0|              3.01|                0.0|              26.5|             14.8|               5.3|  0.3285668529859437|              30.0|               8.8|             8.8|             102.0|              26.5| 0.4445251596257691|160.55733211512106|  0.3091690311323449|  0.9185874654221396|0.15458451556617245| 0.07042982902042424|            23.0|             18.3|  0.784103490487847|  0.5343214914866725|                 0.0|              69.0|             175.0|             26.0|  0.3672840719867877|               3.4|             208.0|  0.8617935932847937|              57.0|              8.8| 75.70967741935483| 7.458243105351445|            50.0| 0.981301814901793|             245.0| 0.4317930190243059|             169.0|              8.0|0.5130525664214498|             245.0|             245.0|             88.0|               3.0|           100.0|0.4906509074508965|              16.2|            18.3|  0.5599090547972845|             85.0|                 0.0|              8.8| 0.13114797918555343|                0.0| 0.05115272165615324| 0.6404061369205825|                 0.0|              26.5|              16.2|             8.8|                0.0|              50.0|              4.5|             208.0|               5.3| 0.8032551337067798|               0.0| 0.9786746365671419|               1.4|  0.526856876818499|            90.0| 0.9762149801646576| 0.5691032033576031|              29.2|             3.01|              0.0|             8.8|             90.0|  0.7279158393209552|  0.8970388908978291|  0.6803605492084103| 0.5726742796766917|           102.0|             245.0|             31.0|                0.0| 0.4345721843096064| 0.31395121931067227|               0.0| 0.27850623881793624| 0.16274348333623853| 0.30290980149227265| 0.6743762966099016|               0.0|           100.0|            26.0|0.003778066194312...|             90.0|             83.0|            139.0|0.44851944544891453|             99.2|             88.0|               0.0|              14.8|             2.2|              4.5|             31.0|            26.0|0.25748257076157804|             2.2|0.35935662036455807|              16.0|  0.3975748138938903|              16.0| 0.4016275668533899|             245.0|             31.0|                0.0| 0.5407062672889302|              0.0|               0.0|  0.9344260104072233|                3.4|              0.0|               0.0|                 0.0|  0.3476563156502173|               4.5| 2.388863048955856|            26.0|           102.0|             85.0|              31.0|             18.3|             29.2|90.01611459265891|                0.0|              0.0|              5.3|            139.0| 0.02557636082807662|             16.0| 0.13315642569210542|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.1914752125631825|              8.8|96.24137931034483| 0.6953126313004346|  0.5267689454838163| 0.7359078366958555|                0.0|160.30150753768845| 0.7366535148353723| 0.6613725803138346|             69.0|  0.9968969567024717|90.0066025067144|  0.9334217871539473|             120.0|            50.0|              8.8|                0.0|  0.5466423544654097|0.007491553859143...| 0.8865360792227868| 0.5266929703292552|            83.0|              30.0|            139.0|0.047570039670684905|            31.0|0.9866770743020669|             26.0|0.005264404985588896|  0.2876211474632365|           120.0|              16.0|90.00044762757386|                 0.0|  0.8546514406466165|             18.3|  0.9889081879220227|              8.0|0.49333853715103343|    0.50975385060743| 0.08137174166811927| 0.7225775622667641|            15.0|  0.9646912287461273| 0.15697560965533613|              16.0|  0.9973677975072055|             8.8|               5.3|              83.0|                 0.0|0.24126041117207714|              14.8|            85.0| 0.7187132407291161| 0.4432680396113934|            208.0|  0.9647850854897879|              18.3|              33.1|0.001388452382281...|               0.0|               0.0|6.942261911408973E-4|160.4163621135982|            139.0|              8.0|  0.7328392542566637|             102.0|                 0.0|              14.8|             139.0|                0.0|               1.4|              18.6|              33.1| 0.3306862901569173|  0.5570124776358725|               1.4|                 0.0|             139.0|               0.0|0.7269868524702858|             85.0|  0.9067152910691807|               0.0|                 0.0|               1.4|              2.2|             90.0|                 0.0|              16.2|              0.0| 0.6058196029845453|[6.94226191140897...|(166,[0,4,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|\n",
            "|153202.0|2195-04-30|{2195-04-29 00:00...|                0.0|             8.4|             120.0|              12.0|                 0.0| 0.01259737760848169|  0.4049927972222716|             187.0| 72.16666666666667| 0.6797969315397088|              9.0|             56.0|  0.426930727592382|             3.75|4.714045207910316|  0.7525644409036717|            69.0|               2.2|              9.3| 0.9509843869310113|               0.0| 0.1499999999999999| 0.8280376885293362|              77.0| 0.8919137873593111| 0.5859811557353318|               0.0|                0.4|              15.1|              30.4|              1.3| 0.6199638177152004| 0.3873596567133406|               1.3|             0.0|  0.2543187358349703|             98.7|                0.0| 0.9404912526956775| 0.7747193134266812|             28.2|0.009907873611381032|             105.0|               0.4|100.21428571428571|  0.8780959765512513|  0.8670727514831013| 0.2081716340654819|               0.0|  0.9189350272326766|             3.05| 0.29305270223556673|              9.3| 9.604686356149273| 5.983774357005415|              3.9|              28.2|               2.2| 0.7767197448113609|               8.9|             93.0|             95.0|  0.6229405283478351| 0.1499999999999999|  0.9335075430380584|           130.0|                0.0|               3.3|               2.2|  0.4594675136163383|             30.0|           100.0| 0.6392789015831795|            99.0|   0.742773258338693|               0.4|             0.0|                0.0|            95.0| 0.7082352766381776|                 0.0|             9.0|              77.0| 0.12273320750410596|               0.4|               3.9|  0.2437814798147677|             77.0|             9.0| 0.24546641500821192|0.9738948671571004|              15.1| 1.9183326093250879| 0.9285476807510574| 0.3081881343209921|              32.9|           105.0|             33.2|             212.4|             28.2|              27.0|  0.2828588017908533| 0.7765167104772168|               3.3|             106.5|              3.05|                1.0|              28.2|             15.1|               3.3| 0.12715936791748514|              30.0|               9.3|             8.4|             105.0|              28.2| 0.3541176383190888|160.55733211512106|  0.3091690311323449|  0.2539183130095153|0.15458451556617245| 0.28199288367483494|            35.0|              8.9|0.20904204835722584|   0.625578218093795|                 0.0|              64.0|             260.0|             27.0| 0.37628222045183585|               0.4|              77.0|  0.7134994830130421|61.833333333333336|              8.4|            109.48| 8.095035515672555|            60.0| 0.981301814901793|             187.0| 0.4180840967144517|             144.0|              8.0|0.5130525664214498|             187.0|             187.0|             93.0|44.840160570631326|           100.0|0.4906509074508965|              17.5|             8.9|  0.8099855944445432|             85.0|                 0.0|              8.4|  0.8859069447322555|                0.0| 0.05824493960187936| 0.6404061369205825|                 0.0|              28.2|              17.5|             8.4|                0.0|              60.0|             3.75|              77.0|               3.3| 0.8321581944717855|               0.0|0.43904798827562563|               1.3| 0.6117416447613916|            93.0| 0.4344216204281218| 0.6432502584934789|              30.4|             3.05|              0.0|             8.4|             91.0|  0.3099819088576002|   0.798694628619848|  0.6803605492084103| 0.6465904979035804|           105.0|             187.0|             33.2|                0.0| 0.4163432681309638| 6.19464980416478E-4|               0.0|  0.4024593678809968|6.807275681867517E-5|  0.4582737176022218| 0.0980312261379774|               0.0|           100.0|            27.0| 0.14290463849788512|             92.0|              9.0|            140.0|  0.399347314309924|            101.1|             93.0|               0.0|              15.1|             2.2|              3.6|             33.2|            27.0|0.31147026417391754|             2.2|0.38858248780445526|              12.0|  0.5664636242584493|              12.0| 0.5839209027641072|             187.0|             33.2|                0.0|0.12695915650475764|              0.0|  5.30461015427985| 0.44295347236612775|                0.4|              0.0|               0.0|                 0.0|  0.3762146866068509|               3.6| 5.006766255112509|            27.0|           105.0|             85.0|              33.2|              8.9|             30.4|90.01611459265891|                0.0|              0.0|              3.3|            140.0| 0.02912246980093968|             12.0|  0.8829245426316886|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.9937013111957591|              9.3|             96.2| 0.7524293732137018|  0.6116401275943195| 0.5297543736521613|                0.0|160.30150753768845| 0.5316972155492664| 0.6653917172247079|             81.0| 0.12189073990738385|90.0066025067144|  0.4414622713158443|123.33333333333333|            60.0|              9.3|                0.0| 0.12662174821627248|0.007491553859143...| 0.7066539121412764| 0.9366055689014672|             9.0|              30.0|            140.0|  0.8688432408562436|            33.2|0.9866770743020669|             27.0|  0.1620942269935893|  0.5332462284809708|           120.0|              12.0|90.00044762757386|                 0.0|  0.7068190041928392|              8.9|  0.5144534833226139|              8.0|0.49333853715103343|  0.6163762686419842|  0.9999659636215906| 0.9950460631943094|            15.0| 0.14142940089542666|  0.9996902675097917|              12.0|  0.9189528865032054|             9.3|               3.3|               9.0|                 0.0| 0.8534736488822167|              15.1|           128.0| 0.7771649756089105| 0.3533269560706382|             77.0| 0.14099644183741747|               8.9|              32.9|3.950196653134012...|               0.0|               0.0|  0.9999999999999802|160.4163621135982|            140.0|              8.0|  0.3127891090468975|             105.0|                 0.0|              15.1|             140.0|                0.0|               1.3|            23.375|              32.9|  0.667304141387646|  0.8049187357619936|               1.3|                 0.0|             140.0|               0.0|0.7269868524702858|             85.0| 0.25324349643254496|               0.0|                 0.0|               1.3|              2.2|             90.0|                 0.0|              17.5|              0.0| 0.9165474352044436|[0.99999999999998...|(166,[0,3,11,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|192031.0|2156-01-15|{2156-01-14 00:00...|0.13065475397959778|            8.35|138.94057916509965|              17.5|  0.0148147169883393| 0.04162341526443389|0.040297070646207224|             214.0| 74.77826247362239| 0.6624985272602849|             75.0|47.70463975858167|  0.426930727592382|              3.7|              0.0| 0.20718381381747253|78.0369671821954|               2.1|              7.1| 0.3371881483049508|               0.0|0.09999999999999987|0.33219014566891736|             186.0| 0.4323350324076383| 0.8339049271655413|               0.0|               3.05|16.326121062384175|              28.9|1.477589339794065|0.14923423582698966| 0.4600024796048131|1.4608241195741203|             0.0| 0.19619776364057873|             96.5|                0.0| 0.9942067011828839|0.48651583403086374|             21.9| 0.05588986633636901|             108.0|               3.1| 97.34444444444445| 0.20699158713329455| 0.22323189276593913| 0.1734475277599536|               1.0| 0.04749156811343164|             2.44|0.005037189085355657|              7.1|11.487286830973543| 8.168515431713185|              3.8|              21.9|2.1500000000000004| 0.3896881429944603|              15.0|             90.0|97.67732230161715| 0.47280115065897854|0.09999999999999987|  0.4707367688966103|           120.0|                0.5|3.9499999999999997|2.1500000000000004| 0.02374578405671582|             35.0|           100.0|  0.672738960713646|           100.0|  0.5352743488716517|               3.1|             1.0|                0.0|            62.0|0.48908889201931066|0.050000000000000044|            74.0|             186.0|  0.9993589769724416|               3.0|               3.8|0.001063912774962...|            186.0|            75.0|0.001282046055116901|0.9738948671571004|16.087061323618695| 1.9418633662885072| 0.9834743263700748| 0.4142515026977065|              32.2|           108.0|36.91319672131147|209.66666666666666|             25.1|              20.0| 0.03741613870152961|  0.389430211420007|               4.1|117.87633609613528|              2.44|                0.0|              25.1|16.04014206300184|               3.8|   0.472376144412589|              35.0|               7.1|             8.6|             108.0|23.900000000000002| 0.4584105459263105|160.55733211512106| 0.42752968906694533|  0.9151306816627606| 0.7862351554665273| 0.03730755191194887|            22.0|             15.0|0.17416298723263302| 0.14237693807153542|                0.25|60.782215523737754|             249.0|             20.0|  0.4711329744042347|               3.0|             186.0| 0.16395339086435168| 61.39591571522619|              8.6| 66.79166666666667|3.2529367073803055|            60.0| 0.981301814901793|             251.0|0.34832597446526603|             163.0|              8.0|0.5130525664214498|             214.0|             232.5|             90.0|35.490217744549774|           100.0|0.4906509074508965|              16.4|            15.0| 0.08059414129241445|             85.0|                 0.0|              8.1|  0.5775513041973412|0.12965952398334926|3.628436036180445E-5| 0.6750029454794302|0.050000000000000044|23.900000000000002|              16.4|             8.1|                0.0|              60.0|              3.7|             186.0|               4.1| 0.3412361445026926|               0.0| 0.8965042064333527|1.4457904300423992| 0.8052848942899965|            92.0| 0.8902648724442614|0.08197669543217584|              28.9|             2.44|              0.0|            8.35|             92.0|  0.9253828820865052|  0.4872208418737004|   0.663630519643177|0.08410314387031852|           108.0|             214.0|37.70331834880121| 1.4236104336041757| 0.3468950555199072|  0.1360464926152493|               0.0|0.040581944679715466|0.046959848095491724| 0.02369477797914215| 0.6743762966099016|               0.5|           100.0|            20.0|0.033051347259850275|             92.0|             74.0|            141.0| 0.2436104209368502|             98.1|             90.0|               0.5| 16.17945696932262|             2.1|              3.6|37.83908909055424|            20.0|0.41496732739917513|             2.2| 0.4594330506661511|              18.0| 0.48581197505212126|              17.0| 0.8293819277486537|             214.0|38.69393271461717|                0.0| 0.4575653408313803|              0.0| 8.132272964076716|  0.7112243479013294|               3.05|              0.0|               0.0|                 0.0| 0.06976359570043217|               3.6| 2.668871174473532|            20.0|           108.0|             85.0|36.781171693735494|             15.0|             28.9|90.01611459265891|                0.0|              0.0|              3.8|            141.0|  0.9999818578198191|             17.5|  0.5824817849974406|                0.5|0.48009629871768866|0.9530305562536405|0.12368084276523614|   0.979188292367783|              7.1|            99.25|0.13952719140086434|  0.8051559285027698|  0.502896649408558|                0.0|160.30150753768845| 0.5058357084693346| 0.9284301130900702|90.91899020346646|  0.9994680436125188|90.0066025067144|  0.7087591075012797|             120.0|            60.0|              7.1|               0.25| 0.46240105402401876|0.007491553859143...| 0.4884661578947222| 0.9883285830613309|            76.0|              35.0|            142.0|  0.2194702551114771|38.8348594847775|0.9866770743020669|             20.0|4.305652646541797...| 0.23536838444830516|           120.0|              17.0|90.00044762757386|                 0.0| 0.16820628774063703|             15.0|  0.9294513022566966|              8.0|0.49333853715103343|  0.4708701645239077|0.023479924047745862| 0.9720550668318155|            14.0|  0.9812919306492351| 0.06802324630762464|              18.0|  0.9997847173676729|             7.1|3.9499999999999997|              76.0|0.014632153041738868| 0.9974814054573222|16.373460837887045|            74.0|0.48486335344055065|0.45745215253325033|            186.0|  0.9813462240440256|              15.0|              32.2|3.531888631677236E-8|              18.5|0.8705195762144462|1.765944315838618E-8|160.4163621135982|            141.5|              8.0|  0.9288115309642323|             108.0|0.050000000000000044|16.227216656547245|             142.0| 1.4236104336041757|1.4611558651322438| 17.91304347826087|              32.2| 0.4642150565450351| 0.08116388935943093|1.4453931203931218|  0.1499999999999999|             141.5|               0.0|0.7269868524702858|             85.0|  0.9248021080480375| 0.876945766580447|  0.1499999999999999|1.4776412776412784|              2.2|             92.0|0.050000000000000044|              16.4|              0.0| 0.0473895559582843|[1.76594431583861...|(166,[0,4,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|\n",
            "|193970.0|2106-08-11|{2106-08-10 00:00...|0.13065475397959778|             9.1|138.94057916509965|              13.0|  0.0148147169883393|0.021539254199842435|  0.5007014305921953|             130.0| 74.77826247362239| 0.2888504831712819|             14.0|47.70463975858167|  0.426930727592382|              3.9|              0.0| 0.20718381381747253|78.0369671821954|               1.9|9.720783890168976| 0.2761968333658741|0.0720476814472478|                0.0|0.24844064562599855|             215.0| 0.6262764742685327| 0.8757796771870008|               0.0|                1.0|16.326121062384175|              30.2|1.477589339794065| 0.8256396060702549| 0.4600024796048131|1.4608241195741203|             0.0| 0.19619776364057873|             97.8|                0.0|0.29471885349913585|0.48651583403086374|28.88809523809525|  0.4102348126700548|             111.0|               1.0| 99.16666666666667|  0.2715464826535922| 0.22323189276593913| 0.3807488946785406|               0.0| 0.45219772949982334|3.250759740695953|   0.026695742333049|9.798362619808303|11.487286830973543| 8.168515431713185|              3.9|28.889421157684648|               1.9| 0.8813192766007132|              14.3|             92.0|97.67732230161715| 0.47280115065897854|                0.0|  0.9809592404305372|           120.0|                0.0|               1.2|               1.9|  0.5286978729187907|             30.0|           100.0| 0.5813086081360233|           100.0|  0.4536919046531941|               1.0|             0.0|                0.0|            74.0|0.48908889201931066|                 0.0|            14.0|             215.0| 0.18382394812673275|               1.0|               3.9| 0.36712102996921425|            215.0|            14.0|  0.3676478962534655|0.9738948671571004|16.087061323618695|  0.877900939270256| 0.5229352225169951| 0.4142515026977065|              32.9|           111.0|36.91319672131147|             123.0|29.72134920634922|              18.0|  0.6188162389705184| 0.8814588626735432|               1.2|117.87633609613528|3.2267190648931874| 0.9797958971132712|29.732255489021973|16.04014206300184|               1.2|   0.472376144412589|              35.0|  9.71992725924236|             9.1|             111.0|29.305063649533878| 0.4584105459263105|160.55733211512106|  0.9110001498850737|  0.8660768673410002|0.45550007494253686|  0.6178960502701973|            34.0|             14.3|0.38176365461985073|  0.8331874204840826|                 0.0|60.782215523737754|             149.0|             18.0|  0.4711329744042347|               1.0|             215.0| 0.17058632694447423| 61.39591571522619|              9.1|             86.12| 7.895922998611372|            45.0|0.9676197184512532|             130.0| 0.7635273092397015|             108.0|              8.0|0.5130525664214498|             130.0|             130.0|             92.0|18.457157599876172|           100.0|0.4838098592256266|              16.0|            14.3| 0.47109294943321767|             85.0|0.022153573700935885|              9.1|0.060244296801609754|0.12965952398334926|6.850889715508595E-4| 0.5777009663425638|                 0.0| 29.31268022684791|              16.0|             9.1|                0.0|              48.0|              3.9|             215.0|               1.2|  0.256797006526039|               0.0| 0.8642267586732039|1.4457904300423992| 0.4407294313367716|            97.0| 0.8572645277239717|0.08529316347223712|              30.2|3.274385328496573|              0.0|             9.1|             91.2| 0.41281980303512744|   0.798694628619848|  0.2906543040680116| 0.0868768492027246|           111.0|             130.0|37.70331834880121| 0.3685342915673636| 0.7614977893570812|7.18620931537853E-13|               2.5|  0.4983362270214471|  0.0801488656603275|  0.5276163794601939| 0.5523936667317482|               0.0|           100.0|            18.0|  0.9541295549660098|             92.0|             14.0|            138.0|  0.399347314309924|             99.7|             92.0|               0.0| 16.17945696932262|             1.9|              3.9|37.83908909055424|            18.0|0.41496732739917513|             1.9| 0.4594330506661511|              13.0| 0.48581197505212126|              13.0| 0.8716014967369805|             130.0|38.69393271461717|0.07060400796808293| 0.5669615663294999|              0.0| 8.132272964076716|0.030122148400804877|                1.0|              0.0|               0.0|                 0.0|  0.5043438780045272|               3.9| 2.512050954897213|            18.0|           111.0|             85.0|36.781171693735494|             14.3|             30.2|90.01611459265891|                0.0|              0.0|              1.2|            138.0|  0.9996574555142246|             13.0|0.060308485894252806|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|0.010769627099921218|9.644677419354842| 98.8076923076923|0.46473433340591286|  0.4406596383003566| 0.8526405732504321|                0.0|160.30150753768845| 0.8527168007896625| 0.7961109513546751|90.91899020346646| 0.18356051498460713|90.0066025067144|0.030154242947126403|             120.0|            60.0|9.796491935483868|                0.0|  0.5731893363862514|0.007491553859143...| 0.4884661578947222|  0.294566398420675|            14.0|              32.5|            138.0|  0.2854709445520568|38.8348594847775|0.9789360719579988|             18.0|  0.9770627723234001|  0.4904796202152686|           120.0|              13.0|90.00044762757386|                 0.0|  0.1737536984054492|             14.3|  0.9073838093063882|              8.0| 0.4894680359789994|  0.4708701645239077|  0.9599255671698362| 0.2051174063350274|            23.0|  0.3094081194852592|  0.9999999999996407|              13.0|     0.5114686138383|9.64237220447285|               1.2|              14.0|0.014632153041738868| 0.9866521288334755|16.373460837887045|           103.0|0.48486335344055065|0.45745215253325033|            215.0| 0.30894802513509867|              14.3|              32.9|   0.729549274173344|               0.0|0.8705195762144462|   0.635225362913328|160.4163621135982|            138.0|              8.0|  0.4165937102420413|             111.0|                 0.0|16.227216656547245|             138.0| 0.3720366581314043|1.4611558651322438|             27.36|              32.9| 0.6019445243226624|  0.4707463743072148|1.4453931203931218|                 0.0|             138.0|               0.0|0.7269868524702858|             85.0|  0.8536213272274973| 0.876945766580447|                 0.0|1.4776412776412784|              1.9|             90.0|                 0.0|              16.0|              6.0|0.45356404462486793|[0.63522536291332...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|\n",
            "|190933.0|2179-05-04|{2179-05-03 00:00...|0.13065475397959778|             7.7|             137.0|               8.0|  0.0148147169883393| 0.04162341526443389|  0.2357680912969468|             123.0| 76.23076923076923| 0.2888504831712819|             24.0|             50.0|  0.419016389184504|              4.0|              0.0|  0.4713917759958851|            80.0|               1.9|              8.6| 0.9431797313702612|               0.0|                0.0| 0.8280376885293362|             128.0|0.29101779674908385| 0.5859811557353318|               0.0|                1.1|16.326121062384175|              32.6|1.477589339794065|0.11002043007475264| 0.4600024796048131|1.4608241195741203|             0.0|  0.3834754873861216|             98.0|                0.0| 0.3688919952001902|0.48651583403086374|             26.2|  0.7742023475313612|             105.0|               1.1| 98.34444444444445| 0.27950583694201114| 0.12104109764211429|  0.451174902920182|               0.0| 0.47011793018534964|             2.64| 0.29305270223556673|              8.6|13.476310576176335| 8.172692298642108|              4.0|              26.2|               1.9|   0.56044520340909|               4.9|             99.0|             86.0| 0.47280115065897854|                0.0| 0.20638593804862984|           125.0|                0.0|               3.1|               1.9| 0.23505896509267482|             30.0|           100.0| 0.5813086081360233|           100.0| 0.04421492552303007|               1.1|             0.0|                0.0|            66.0|0.48908889201931066|                 0.0|            24.0|             128.0|  0.3520697403198724|               1.1|               4.0|  0.7081070364697271|            128.0|            24.0|  0.7041394806397449|0.9738948671571004|16.087061323618695|  2.114762923408253|  0.454080366485757| 0.4142515026977065|              32.9|           105.0|36.91319672131147|             140.0|             28.1|              27.0|  0.6880850697254509| 0.5605050419662186|               3.1|113.34615384615384|              2.64|                1.0|              28.1|16.04014206300184|               3.1|  0.1917377436930608|              30.0|               8.6|             7.7|             105.0|26.899999999999995| 0.4584105459263105|             160.0|  0.3091690311323449|  0.5111966203433471|0.15458451556617245|  0.6872013059321129|            22.0|              4.9|  0.452366173438544| 0.11023924458650793|                 0.0|              56.0|             148.0|             27.0|  0.7643041120020575|               1.1|             128.0|  0.7134994830130421|  65.3076923076923|              7.7| 82.53333333333333| 8.023853327561653|            60.0| 0.986777781674111|             123.0|  0.904732346877088|             131.0|              8.0|0.5130525664214498|             123.0|             123.0|             99.0|  6.97614984548545|           100.0|0.4933888908370555|              12.9|             4.9|  0.4715361825938936|             85.0|                 0.0|              7.7|   0.757462028133137|0.12965952398334926|0.031742700748989904| 0.5777009663425638|                 0.0|26.899999999999995|              12.9|             7.7|                0.0|              60.0|              4.0|             128.0|               3.1| 0.8321581944717855|               0.0|0.13975291847100557|1.4457904300423992| 0.2802525209831093|            91.0| 0.1403805125425674| 0.6432502584934789|              32.6|             2.64|              0.0|             7.7|             91.0| 0.05501021503737632|   0.798694628619848|  0.2906543040680116| 0.6465904979035804|           105.0|             123.0|37.70331834880121|  0.852447456836296|  0.902349805840364|1.603939058765450...|               0.0| 0.23471809842150815|  0.7797246007836699| 0.23385876595952015|0.11364053725947755|               0.0|           100.0|            27.0|   0.908160732971514|             92.0|             24.0|            136.0|  0.399347314309924|             99.0|             99.0|               0.0| 16.17945696932262|             1.9|              4.0|37.83908909055424|            27.0|0.41496732739917513|             1.9| 0.4594330506661511|               8.0|  0.9394794511789428|               8.0| 0.5839209027641072|             123.0|38.69393271461717|                0.0|0.25559831017167356|              0.0| 6.407743097037609|  0.3787310140665685|                1.1|              0.0|               0.0|                 0.0| 0.13640873108917484|               4.0| 3.186778240724565|            27.0|           105.0|             85.0|36.781171693735494|              4.9|             32.6|             90.0|                0.0|              0.0|              3.1|            136.0|0.015871350374494952|              8.0|  0.7548975237528397|                0.0|0.48475960000217266|0.9695192000043453|                0.0|   0.979188292367783|              8.6|96.16666666666667| 0.2728174621783497|   0.280222601704545| 0.1844459976000951|                0.0|             160.0|0.18697084018903326| 0.1397136135656805|             92.0| 0.35405351823486353|            90.0| 0.37744876187641985|             125.0|            60.0|              8.6|                0.0|  0.2571554357993772|                 0.0| 0.4884661578947222| 0.3739416803780665|            24.0|              30.0|            136.0|  0.2807610250851348|38.8348594847775|0.9866770743020669|             27.0|  0.8891102789193863|   0.896807030975685|           125.0|               8.0|             90.0|                 0.0|  0.7068190041928392|              4.9| 0.08842985104606015|              8.0|0.49333853715103343|  0.4708701645239077|  0.6101376996081651| 0.3871011737656806|             9.0| 0.34404253486272546|8.019695293827252E-6|               8.0| 0.44455513945969316|             8.6|               3.1|              24.0|0.014632153041738868| 0.8534736488822167|16.373460837887045|           100.0|0.48486335344055065|0.45745215253325033|            128.0| 0.34360065296605646|               4.9|              32.9|  0.4035172653727185|               0.0|0.8705195762144462| 0.20175863268635924|            160.0|            136.0|              8.0| 0.05511962229325396|             105.0|                 0.0|16.227216656547245|             136.0|  0.852447456836296|1.4611558651322438|15.333333333333334|              32.9| 0.9301431932171598|  0.4694361968430163|1.4453931203931218|                 0.0|             136.0|               0.0| 0.838032778369008|             85.0|  0.5143108715987544| 0.876945766580447|                 0.0|1.4776412776412784|              1.9|             90.0|                 0.0|              12.9|              0.0| 0.4677175319190403|[0.20175863268635...|(166,[0,2,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|107462.0|2149-03-31|{2149-03-30 00:00...|                0.0|             8.6|             158.0|              14.0|                 0.0| 0.28527572776766313|  0.6465908663186931|             226.0| 79.08695652173913| 0.9319952880517142|             20.0|             40.0|0.38626031753797635|              4.2|              0.0| 0.11249775635899914|            81.0|               2.5|             10.2| 0.3034253128759712|               0.0|                0.0| 0.9242200327996876|             174.0| 0.5878397362849472| 0.4621100163998438|               0.0|                1.1|              16.6|              29.9|              1.5| 0.9558889475438066| 0.5379329597891574|               1.5|             0.0| 0.15940566981918122|             97.0|                0.0| 0.7242968595418335| 0.9241340804216851|             31.9| 0.00536638992872238|             103.0|               1.1| 97.96666666666665|  0.5369463042591698| 0.10467086171649842| 0.5944280559604681|               0.0|  0.4263476888853164|             3.41|  0.3738713374251535|             10.2| 20.43689474129244|12.279049118680941|              4.2|              31.9|               2.5| 0.7767197448113609|               6.9|             94.0|             87.0|  0.4430364437634935|                0.0|  0.8533746712047077|           120.0|                0.0|               2.7|               2.5|  0.7868261555573418|             40.0|           100.0|0.13656657361269778|            99.0| 0.41341241113830723|               1.1|             0.0|                0.0|            73.0|  0.924140058910544|                 0.0|            20.0|             174.0|  0.2781970402192187|               1.1|               4.2|  0.5582792758189525|            174.0|            20.0|  0.5563940804384374|0.9680307246992478|              16.6|  2.421855614066333| 0.9923988721345066|0.21937954559340883|              31.9|           103.0|             29.4|             225.5|             31.9|              27.0|  0.6880850697254509| 0.7765167104772168|               2.7|             124.0|              3.41|0.06445004758462232|              31.9|             16.6|               2.7|  0.9202971650904094|              45.0|              10.2|             8.6|             103.0|              31.9|  0.537929970544728|             160.0|8.641555893638878E-5|  0.8255206810795768| 0.9999567922205318|  0.6872013059321129|            36.0|              6.9| 0.5958616702270787|   0.946792473534848|                 0.0|              55.0|             290.0|             27.0|  0.9437511218205005|               1.1|             174.0|  0.7134994830130421| 65.70833333333333|              8.6| 85.83333333333333|7.7549267494212275|            50.0|0.9771005412364924|             226.0| 0.8082766595458425|             191.0|              8.0| 0.515984637650376|             226.0|             226.0|             94.0| 38.16084380618437|           100.0|0.4885502706182462|              15.8|             6.9|  0.7068182673626138|             85.0|                 0.0|              8.6|  0.5225219629359406|                0.0|9.720227269803277...|0.13600942389657175|                 0.0|              31.9|              15.8|             8.6|                0.0|              50.0|              4.2|             174.0|               2.7| 0.9239600917072498|               0.0| 0.2684731521295849|               1.5| 0.6117416447613916|            90.0| 0.2670040526736528| 0.6432502584934789|              29.9|             3.41|              0.0|             8.6|90.44908692476263|  0.5220555262280967| 0.37714868718356476|  0.9317167131936511| 0.6465904979035804|           103.0|             226.0|             29.4|                0.0| 0.8111438880790638|9.941391251594837...| 2.357022603955158|  0.6426572428052503|  0.6378248271353548|  0.7853276039752664| 0.6068506257519424|               0.0|           100.0|            27.0|0.015202255730986752|90.51460920379839|             20.0|            140.0|0.18857434359178238|             98.5|             94.0|               0.0|              16.6|             2.5|              4.2|             29.4|            27.0|0.22151822188174675|             2.5| 0.5409441735152294|              14.0|  0.9476645691417508|              14.0| 0.4619800458536249|             226.0|             29.4|                0.0| 0.4127603405397884|              0.0|10.982862281249314|  0.2612609814679703|                1.1|              0.0|               0.0|                 0.0|  0.6445091313191611|               4.2|  4.24575847503781|            27.0|           103.0|             85.0|              29.4|              6.9|             29.9|90.01611459265891|                0.0|              0.0|              2.7|            140.0|4.860113634901638...|             14.0|  0.5208562344507215|                0.0|0.48009629871768866|0.9530305562536405|                0.0| 0.14263786388383157|             10.2|             93.5| 0.7109817373616778|  0.6116401275943195| 0.6378515702290832|                0.0|             160.0| 0.6391940422251249| 0.5441343679229096|             96.0| 0.27913963790947627|90.0066025067144| 0.26042811722536074|             120.0|            50.0|             10.2|                0.0|  0.4169167995122752|0.007491553859143...| 0.9275073699266075| 0.7216119155497502|            20.0|41.666666666666664|            140.0|  0.5340081053473056|            29.4|0.9836831939012491|             27.0|0.019571788506886224| 0.42668733560235383|           120.0|              14.0|90.00044762757386|                 0.0|  0.7068190041928392|              6.9|  0.8268248222766145|              8.0|0.49184159695062457| 0.43875909118681766|  0.3189124135676774| 0.9973168050356388|            20.0| 0.34404253486272546|                 1.0|              14.0|  0.9902141057465569|            10.2|               2.7|              20.0|                 0.0| 0.4225132067981789|              16.6|            99.0| 0.9181116529695413| 0.5362463150366963|            174.0| 0.34360065296605646|               6.9|              31.9|  0.8010808660789625|               0.0|               0.0|  0.5994595669605187|            160.0|            140.0|              8.0|   0.526603763232576|             103.0|                 0.0|              16.6|             140.0|                0.0|               1.5|30.130434782608695|              31.9| 0.7279328160385452|  0.7146855143894995|               1.5|                 0.0|             140.0|               0.0|0.7725206350759527|             85.0|  0.8338335990245505|               0.0|                 0.0|               1.5|              2.5|90.38166544923301|                 0.0|              15.8|              0.0| 0.4293447920494673|[0.59945956696051...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|\n",
            "|176986.0|2124-03-30|{2124-03-29 00:00...| 0.6531972647421806|             8.4|             127.0|13.597910537212597| 0.08164965809277258|  0.5602426599302645|   0.867178898040382|             153.0| 76.77777777777777| 0.7905702978199138|             28.0|             58.0|  0.419016389184504|4.068208670260556|              0.0|  0.5941955873550857|            87.0|               2.3|             10.8| 0.3371881483049508|               0.0|0.08476868946084137|0.07530862398670389|             198.0|  0.570643557622579| 0.9623456880066481|               0.0|                1.0|              14.9|              30.6|              1.3| 0.4634458150587124|0.17461602194619852|1.2000000000000002|             0.0| 0.07340145945951213|97.29775093569233|                0.0| 0.9404912526956775|0.34923204389239704|             31.4|  0.9286722931816589|             115.0|               1.0| 98.08017781384638|0.008547259694383564| 0.12097119743533971| 0.4833624831267787|               0.0| 0.21953721146551025|             3.54|0.005037189085355657|             10.8| 9.673688382079519| 8.270130695968176|4.159509433962263|              31.4|               2.3|0.47292877765230995|              20.9|             93.0|             94.0| 0.22417756989297666|0.08596788964012393|  0.8487362437179414|           120.0|0.35617271464321204| 3.500057344901359|               2.3|  0.8902313942672448|             30.0|           100.0|0.41866125589013137|           100.0|  0.0977978224852912|               1.0|             0.0|                0.0|            80.0|0.29160361267884305|                 0.0|            28.0|             211.5| 0.43200767862601536|               1.0|4.1610394537177555|  0.8702085090882137|            211.5|            28.0|  0.8640153572520307|0.9738948671571004|              13.3|  0.759202798262025| 0.7341924406223514|0.10956527476958616|              32.8|           115.0|             24.5|             154.0|             33.0|              22.0|  0.6188162389705184| 0.4721770330141089|3.5965474209650576|103.44444444444444|              3.54|                0.0|              33.0|             13.3|3.4006276150627603| 0.03670072972975606|              35.0|              10.8|             8.4|             115.0|              32.2|0.14580180633942152|             160.0|  0.9110001498850737|  0.8481149845477995|0.45550007494253686|  0.6178960502701973|            18.0|             20.9|0.48414255054546573| 0.46370842439089255|                 0.0|              67.0|             154.0|             22.0|  0.7029022063224571|               1.0|             225.0|  0.5497190532886032| 68.44444444444444|              8.4|              84.0|3.6514837167011076|            50.0| 0.981301814901793|             153.0| 0.4773693026559077|             154.0|              8.0|0.5130525664214498|             153.0|             153.0|             93.0|               0.0|           100.0|0.4906509074508965|              13.7|            20.9| 0.26564220391923604|             85.0|                 0.0|              8.4|   0.475782102493217| 0.6531972647421806|0.007158299831221294| 0.4188594043601722|                 0.0|              32.2|              13.7|             8.4|                0.0|              55.0|4.068660082014597|             225.0|3.5946443514644364|0.08037252201688713|               0.0| 0.9957263701528082|               1.1| 0.5004475598958745|            98.0| 0.9949779708054476| 0.2748595266443016|              30.6|             3.54|              0.0|             8.4|             92.0|  0.4678802538173802|  0.7505962587175995|  0.7906693720549343|  0.278067730126483|           115.0|             153.0|             30.3| 0.8000000000000007|0.47723030968144614|0.016019025906931352|               2.5|  0.8631174214841814| 0.32834702258044673|  0.8888133940424412| 0.6743762966099016|0.3717226033966161|           100.0|            22.0|  0.5316151187552971|             92.0|             28.0|138.3575503993914|0.37529812935879975|98.87376658727456|             93.0|0.3680998820137272|              14.1|             2.3|3.977200303490134|             30.3|            22.0|0.11208878494648833|             2.3|  0.174733806517274|13.981693363844393|  0.9395144012823301|13.220061022120518| 0.9598137389915564|             153.0|             33.8|                0.0| 0.5759425077261002|             13.5| 8.001543061061703| 0.47827446509141863|                1.0|             13.5|               0.0|                 0.0|   0.731791270962617|3.9778867924528267|1.5723301886761007|            22.0|           115.0|             85.0|              24.5|             20.9|             30.6|             90.0|                0.0|              0.0|3.405948419301164|138.3512996941896|  0.9964208500843893|13.55895896170368| 0.47673291112742694|0.36128275365036766| 0.4784520629105555| 0.956904125821111|                0.0|  0.7198786700348678|             10.8|99.08333333333333|  0.536417458074766|  0.5004252396055716| 0.5297543736521613|                0.0|             160.0| 0.5316972155492664| 0.6653917172247079|             96.0| 0.43510425454410684|            90.0| 0.47783318356312104|             120.0|            60.0|             10.8|                0.0|  0.5844616893429506|                 0.0|0.29075700255816966| 0.9366055689014672|            28.0|              32.5|139.1452599388379|0.010044058389104727|            33.8|0.9866770743020669|             22.0|  0.5610135642774978|  0.5756318781410292|           120.0|13.177351247600768|             90.0|                 0.0|   0.556135460252966|             20.9|  0.1955956449705824|              8.0|0.49333853715103343| 0.21913054953917233| 0.43721795594277313| 0.5356638534091706|            11.0|  0.3094081194852592|0.008009512953465676|13.949328214971208|  0.7194932178612511|            10.8|3.4959720063757715|              28.0| 0.08164965809277258| 0.9974814054573222|              14.9|            88.0|  0.349467613034548|0.14537850127908483|            198.0| 0.30894802513509867|              20.9|              32.8|  0.8302773434616422|               0.0|4.1303752856126765|  0.4151386717308211|            160.0|138.7550739009944|              8.0| 0.46799099320339343|             115.0|                 0.0|14.100000000000001|139.14416127805248| 0.8000000000000007|1.2000000000000002|15.833333333333334|              32.8|  0.667304141387646| 0.27376515703163723|               1.1| 0.08957582974112871|138.75297937600118|               0.0| 0.838032778369008|             85.0|  0.8310766213140989|4.1303752856126765|  0.0911977288017119|               1.3|              2.3|             92.0|                 0.0|              13.7|              5.0|0.22237321191511766|[0.41513867173082...|(166,[0,3,11,20,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|196271.0|2141-12-23|{2141-12-22 00:00...|0.13065475397959778|             7.7|             123.0|               9.5|  0.0148147169883393| 0.04162341526443389|0.011396308873774743|              83.0|              74.0| 0.5706230715907137|              8.5|             53.0|0.38626031753797635|              3.8|              0.0|   0.977905834042727|            80.0|               2.0|              7.3| 0.3371881483049508|               0.0|                0.0| 0.6413598398090137|             455.0| 0.5134138194478215|0.32067991990450684|               0.5|                0.7|16.326121062384175|              29.4|1.477589339794065|0.09384414268745607| 0.4600024796048131|1.4608241195741203|             0.0|0.021322770247424946|             98.0|                0.5| 0.2038457891785212|0.48651583403086374|             21.2|  0.4762383440546457|             101.0|               0.7|           98.7875|0.029423277459913376|  0.3105711659425305| 0.2466909119612835|               0.5|0.015713230646250614|             2.45| 0.29305270223556673|              7.3|10.040348288281637| 7.176350047203662|              3.8|              21.2|               2.1|0.41033388138496085|              16.2|             90.0|             90.0| 0.47280115065897854|                0.0|  0.6519614795193027|           120.0|                0.5|              3.75|               2.1|0.007856615323125307|             30.0|           100.0| 0.8556360563526966|           100.0| 0.20713751356900506|               0.7|             0.5| 0.7999999999999972|            82.0|0.48908889201931066| 0.10000000000000009|             8.0|             472.0|0.046555652428750656|               0.7|               3.8| 0.09188636640086657|            455.0|             8.5| 0.09311130485750131|0.9738948671571004|16.087061323618695| 1.8320484120467573|0.05938207800495983| 0.4142515026977065|              34.3|           102.0|36.91319672131147|             110.0|             25.2|              29.0|  0.2665018632198425| 0.4104052681191437|               3.8|          103.9375|              2.43|                1.0|              25.2|16.04014206300184|               3.7|0.010661385123712473|              30.0|               7.3|             7.7|             101.5|22.866666666666664| 0.4584105459263105|             160.0|  0.3091690311323449|2.295717223618402...|0.15458451556617245|  0.2655174401587249|            19.0|             16.7|0.24772586211147224| 0.09484403985556165|                 0.0|              63.0|             110.0|             29.0|  0.4889529170213635|               0.7|             455.0|  0.2867574507362795|           64.5625|              7.7| 87.66666666666667|4.2163702135578385|            60.0| 0.986777781674111|             108.0| 0.4954517242229445|             110.0|              8.0|0.5130525664214498|              83.0| 91.33333333333333|             87.0|               0.0|           100.0|0.4933888908370555|              15.1|            15.7|0.022792617747549485|             85.0|0.020000000000000018|              7.7|  0.7465730375201259|0.12965952398334926|  0.3064038946652724| 0.8587538568185726| 0.10000000000000009|22.866666666666664|              15.1|             7.7|                0.0|              60.0|              3.8|             489.0|               3.8| 0.6447961715696787|               0.0| 0.9852883612700433|1.4457904300423992|0.20520263405957184|            95.0| 0.9831495269191155| 0.8566212746318602|             29.65|             2.47|              0.5|             7.7|             91.0|0.046922071343728035|  0.8631707688029249|  0.5721819718236517| 0.8593932611385096|           101.5|              83.0|37.70331834880121|  1.699673171197595|  0.493381823922567|0.010539285415788123|               0.0|0.011497149501100342| 0.22613234770607032|0.007859187012409915| 0.6743762966099016|               1.0|           100.0|            29.0| 0.11876415600991966|             92.0|              8.0|            135.0| 0.5684146155985376|             99.7|             88.5|               1.0| 16.17945696932262|             2.0|              3.8|37.83908909055424|            29.0|0.41496732739917513|             2.2| 0.4594330506661511|              10.0|  0.8447144170287347|               9.0|0.32239808578483936|              83.0|38.69393271461717|                0.0|  0.999885214138819|             17.0| 7.210831696136029|  0.6267134812399371|                0.7|              0.0|               0.0|                 0.0|0.019589096011496766|               3.8|2.0548046676563256|            29.0|           101.0|             85.0|36.781171693735494|             15.7|             29.9|             90.0|                0.5|              0.0|              3.7|            135.0|  0.8467980526673637|              9.5|  0.7515991411877838|                0.5| 0.4784520629105555| 0.956904125821111|                0.0|   0.979188292367783|              7.3|97.76470588235294|0.03917819202299353| 0.20516694069248043| 0.1019228945892606|               0.25|             160.0|0.10431744232962346|  0.619656051275024|             88.0| 0.04594318320043329|            90.0|  0.6242004294061081|             120.0|            60.0|              7.3|                0.0|  0.9936377309023947|                 0.0| 0.4884661578947222|0.20863488465924693|             9.0|              30.0|            137.0| 0.03370094616176906|38.8348594847775|0.9866770743020669|             29.0| 0.11899204696629205| 0.32598073975965136|           120.0|               9.0|             90.0|                 0.0|  0.2812134777229809|             16.7|  0.4142750271380101|              8.0|0.49333853715103343|  0.4708701645239077|  0.8869338261469648|0.23811917202732286|            13.0| 0.13325093160992124|0.005269642707894062|              10.0|0.059496023483146025|             7.3|              3.75|               9.0|0.014632153041738868| 0.8534736488822167|16.373460837887045|            97.0|0.48486335344055065|0.45745215253325033|            455.0| 0.13275872007936246|              16.2|              32.7| 0.48460389543673454|11.785113019775793|0.8705195762144462|  0.7576980522816328|            160.0|            136.0|              8.0| 0.04742201992778083|             102.0|                 0.0|16.227216656547245|             137.0|  1.699673171197595|1.4611558651322438|16.333333333333332|              33.5|  0.309828025637512|0.022994299002200683|1.4453931203931218| 0.04999999999999982|             136.0|               1.5|0.7725206350759527|             85.0|0.012724538195210536| 0.876945766580447| 0.04999999999999982|1.4776412776412784|              2.2|             90.0|                 0.0|              15.1|              0.0|0.01571837402481983|[0.75769805228163...|(166,[0,2,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|107462.0|2149-04-04|{2149-04-03 00:00...|                0.0|             8.3|138.94057916509965|              13.0|                 0.0|1.563940361854594...|  0.6717097527396186|             142.0| 74.77826247362239|  0.966519207113261|             34.0|47.70463975858167|  0.426930727592382|              3.4|              0.0| 0.20718381381747253|78.0369671821954|               2.6|             10.3| 0.3371881483049508|               0.0|                0.0| 0.7088611790207303|             460.0| 1.1368817000902063| 0.6455694104896348|               0.0|                1.2|              15.6|              29.1|              1.4| 0.8256396060702549| 0.4368093972444698|               1.4|             0.0| 0.19619776364057873|             96.5|                0.0| 0.9486646067167785| 0.8736187944889396|             32.6| 0.41545845588492925|             106.0|               1.2| 98.05000000000001|  0.7384634103524592| 0.22323189276593913|0.11361441164105651|               0.0| 0.33445158855806834|             3.53|  0.3738713374251535|             10.3|11.487286830973543| 8.168515431713185|              3.4|              32.6|               2.6|0.17203839893891715|              11.0|             92.0|97.67732230161715|  0.3851058352521204|                0.0|  0.5392200114022563|           120.0|                0.0|               3.5|               2.6|  0.8327742057209658|             40.0|           100.0|0.06746205695622363|           100.0| 0.41341241113830723|               1.2|             0.0|                0.0|            51.0| 0.8890503192515382|                 0.0|            34.0|             460.0|  0.5562425322172879|               1.2|               3.4|  0.8783041593254626|            460.0|            34.0|   0.887514935565424|0.9738948671571004|              15.6|  2.357468123778428| 0.6382877706103647|0.19079476169985227|              31.6|           106.0|             28.0|151.38370222803474|             32.6|              29.0|  0.7600767323102067|0.17188604316907938|               3.5|117.87633609613528|              3.53|0.06445004758462232|              32.6|             15.6|               3.5|   0.472376144412589|              40.0|              10.3|             8.3|             106.0|              32.6| 0.4445251596257691|160.55733211512106|  0.0656202747032537|0.012681546647063037| 0.9671898626483731|  0.7592421727640487|            36.0|             11.0|0.11379437944827117|  0.8331874204840826|                 0.0|60.782215523737754|178.49948822927328|             29.0|  0.4711329744042347|               1.2|             460.0| 0.45128162827208385| 61.39591571522619|              8.3|62.458333333333336| 6.337580812546343|            40.0| 0.981301814901793|             142.0|0.22758875889654234|127.71084953940634|              8.0|0.5130525664214498|             142.0|             142.0|             92.0| 19.70452579251507|           100.0|0.4906509074508965|              15.8|            11.0|  0.6565804945207627|             85.0|                 0.0|              8.3|  0.9825704584833852|                0.0| 0.04199066384315559|0.06696158577347804|                 0.0|              32.6|              15.8|             8.3|                0.0|              40.0|              3.4|             460.0|               3.5| 0.7146464602556497|               0.0| 0.6307682948237704|               1.4| 0.9140569784154603|            91.0| 0.6234285794009405|  0.774359185863958|              29.1|             3.53|              0.0|             8.3|90.44908692476263| 0.41281980303512744| 0.28391127426390905|  0.9662689715218882| 0.7769710045951528|           106.0|             142.0|             28.0|                0.0|0.22722882328211302|6.655943652961386...|               0.0|  0.6677216531680673|  0.7516197469345433|  0.8313814676603787| 0.6743762966099016|               0.0|           100.0|            29.0|  0.7234244587792705|90.51460920379839|             34.0|            145.0|0.14195563713195453|             99.8|             92.0|               0.0|              15.6|             2.6|              3.4|             28.0|            29.0| 0.1925529176260602|             2.6| 0.4386443108440325|              13.0| 0.48581197505212126|              13.0| 0.6426767698721751|             142.0|             28.0|                0.0| 0.9936592266764684|              0.0| 8.132272964076716|  0.5087147707583074|                1.2|              0.0|               0.0|                 0.0|  0.7254755977431124|               3.4| 4.681523968396046|            29.0|           106.0|             85.0|              28.0|             11.0|             29.1|90.01611459265891|                0.0|              0.0|              3.5|            145.0|0.020995331921577796|             13.0|   0.985906794023877|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|7.819701809272973E-5|             10.3|96.08695652173913| 0.5490488045137751|  0.9139808005305414| 0.4743323033583893|                0.0|160.30150753768845|0.47653626657293524| 0.7961109513546751|90.91899020346646|  0.5608479203372687|90.0066025067144|  0.5070466029880615|             120.0|            40.0|             10.3|                0.0|  0.9944479197697371|0.007491553859143...| 0.8865360792227868| 0.9530725331458705|            34.0|              40.0|            145.0|  0.7531428411981189|            28.0|0.9905790501718436|             29.0|  0.7511971742166561| 0.26961000570112814|           120.0|              13.0|90.00044762757386|                 0.0|  0.4460579908096943|             11.0|  0.8268248222766145|              8.0| 0.4952895250859218| 0.38158952339970453|  0.3758098734672716|0.48473795362972405|            15.0| 0.38003836615510334|  0.9999999966720282|              13.0|   0.624401412891672|            10.3|               3.5|              34.0|                 0.0| 0.4225132067981789|              15.6|            71.0|  0.877288621688065| 0.4432680396113934|            460.0| 0.37962108638202435|              11.0|              31.6|8.843657344815311...|               0.0|               0.0|4.421828672407655...|160.4163621135982|            145.0|              8.0|  0.4165937102420413|             106.0|                 0.0|              15.6|             145.0|                0.0|               1.4|              26.0|              31.6| 0.6019445243226624|  0.6645566936638654|               1.4|                 0.0|             145.0|               0.0|0.7269868524702858|             85.0|0.011104160460525848|               0.0|                 0.0|               1.4|              2.6|90.38166544923301|                 0.0|              15.8|              0.0|0.33723706467924264|[4.42182867240765...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "|122619.0|2164-05-23|{2164-05-22 00:00...|0.13065475397959778|            8.45|             149.0|              14.5|  0.0148147169883393| 0.19113899790625108|  0.5007014305921953|             103.0|              81.0|0.06537548397442225|             10.5|             51.0|0.36165156269653376|              3.5|              0.0|0.045879108361798496|            81.0|               1.7|9.720783890168976| 0.3034253128759712|0.0720476814472478| 0.2999999999999998| 0.3641563464936197|204.55184887459808| 0.6454972243679028|0.18207817324680986|               0.5|                0.5|16.326121062384175|30.123507616302994|1.477589339794065| 0.7847731072252886| 0.4600024796048131|1.4608241195741203|             0.0|0.006294550143638595|             97.7|0.15238186232786088| 0.8384467361807976|0.48651583403086374|28.88809523809525|  0.9854346785591696|              99.0|               0.6|              98.7| 0.48196839886325465| 0.19475238740146078|0.07326473219685131|               0.5| 0.45219772949982334|3.250759740695953|  0.6194900007990161|9.798362619808303|10.259243518034205| 7.225685179676006|              3.8|28.889421157684648|              1.75|0.01861913933091351|  9.43330216554195|90.84011276681434|            103.0| 0.47280115065897854| 0.2999999999999998| 0.47373916357820256|           120.0|                1.5|              1.75|              1.75|  0.5286978729187907|             35.0|           100.0|   0.13333412130835|           100.0|  0.4709935406778632|               0.6|             0.5|0.06995517975068115|            83.0|0.48908889201931066|0.050000000000000044|            10.0|207.85274463007156|  0.0627778825394596|               0.4|               3.8| 0.12444099126590709|206.9605004019292|            10.5|  0.1255557650789192|0.9680307246992478|16.087061323618695| 1.1575161985907585|0.48368971676867756| 0.4142515026977065|33.248717948717946|           100.0|36.91319672131147|149.66666666666666|29.72134920634922|              19.0| 0.16672124155971146|0.01860971492201124|               1.8|131.89473684210526|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|               1.7|  0.9968527249281807|              35.0|  9.71992725924236|             8.8|              99.5|29.305063649533878| 0.4584105459263105|             160.0|  0.3311830982240087|  0.4886900771438565| 0.8344084508879956| 0.16592954814705455|            29.0|9.599003202562052|0.07351684342824598|  0.7714436273711858| 0.35000000000000053|              64.0|             213.0|             22.0|  0.9770604458191008|               0.4|209.46905144694534|  0.2093311783634658| 65.21052631578948|              8.8|              97.5| 7.978095010715277|            50.0|0.9745232284758952|             150.0|0.14703368685649196|             103.0|              8.0| 0.515984637650376|             103.0|             126.5|90.55054369714055| 46.42796092394706|           100.0| 0.491807068783402|16.114291481631014|9.21408502024291| 0.47109294943321767|85.00246212121212|0.022153573700935885|              8.1|0.043967096451587896|0.12965952398334926| 0.38508085865314434| 0.1307509679488445|0.050000000000000044| 29.31268022684791|16.177069035123125|             8.1|0.02918013555493569|56.666666666666664|              3.5|210.35680190930788|               1.8| 0.3704290814255442|              23.5| 0.4686834829104542|1.4457904300423992|0.00930485746100562|            96.0|0.46784589154325545| 0.1046655891817329|30.178889460683365|3.274385328496573|              0.5|            8.45|             90.0|  0.6076134463873557|  0.4894464120957203|   0.066667060654175| 0.1071947043737671|            99.5|             126.5|37.70331834880121| 0.3685342915673636|0.14652946439370262|  0.5443390498748227|               0.0|  0.4983362270214471|   0.375451439017075|  0.5276163794601939| 0.6068506257519424|               1.0|           100.0|            19.0|  0.9673794335373551|             90.0|             10.0|            130.0| 0.4729044061266951|             99.7|90.69301248489731|               1.0| 16.17945696932262|             1.7|              3.2|37.83908909055424|            20.5|0.41496732739917513|             1.8| 0.4594330506661511|              16.0|  0.9026238062992696|              13.0| 0.1852145407127721|             150.0|38.69393271461717|0.07060400796808293| 0.5049095001727325|2.305587200599279| 7.345452924793685|0.021983548225793948|                0.5|2.297622738931195|               1.5|0.002728073736398...|  0.5043438780045272|               3.2| 4.579854719538335|            22.0|            99.0|84.99962121212121|36.781171693735494|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|              1.5|              1.7|            130.0|  0.8074595706734278|             14.5| 0.04387195048768025|                1.5|0.47361569343253623|0.9472313868650725|                0.0|  0.9044305010468745|9.644677419354842|          97.6875|0.46473433340591286|0.009309569665456756| 0.5807766319096013|0.05272455247871184|             160.0|  0.583294241900559|0.47024088066356073|             95.0|0.062220495632953544|            90.0|0.021935975243840125|             120.0|            60.0|9.796491935483868|0.35000000000000053|   0.506758958686583|                 0.0| 0.4884661578947222|  0.833411516198882|            11.0|              35.0|            132.0|  0.4838445299068336|38.8348594847775|0.9836831939012491|             20.5|  0.9376223534774848| 0.49055292792469574|           120.0|              13.0|             90.0|                 0.0|  0.2143894087475342|9.539477732793522|  0.4579845075940477|              8.0|0.49184159695062457|  0.4708701645239077|  0.8122742804914624| 0.5072826607204153|            13.0| 0.08336062077985573| 0.27216952493741137|              16.0|  0.4688111767387424|9.64237220447285|              1.75|              11.0|0.014632153041738868|0.30974500039950803|16.373460837887045|           117.0|0.48486335344055065|0.45745215253325033|205.4315831344471| 0.08296477407352727| 9.375520512820508|33.100986193293885|5.515855430906425E-4|              23.5|0.8705195762144462|  0.9997242072284547|            160.0|            131.0|              8.0|  0.6142781863144071|             100.0| 0.09999999999999998|16.227216656547245|             132.0| 0.3720366581314043|1.4611558651322438|18.842105263157894| 33.17546745562131| 0.4987639065100168|  0.4707463743072148|1.4453931203931218|0.050000000000000044|             131.0|0.1363245068214134|0.7233031253930675|85.00530303030303|  0.4866650863530708| 0.876945766580447|0.050000000000000044|1.4776412776412784|              1.8|             90.0| 0.09999999999999998| 16.14547301843629|4.714045207910317|0.45356404462486793|[0.99972420722845...|(166,[0,2,10,13,5...|[0.99972420722845...|                               0.0|                                0.0|\n",
            "|116807.0|2117-02-07|{2117-02-06 00:00...|                0.0|             6.7|             103.0|              15.0|                 0.0|  0.1496787525087407|   0.594492698538468|             110.0|62.333333333333336|0.05700811392212522|             14.0|             40.0|  0.426930727592382|              4.1|              0.0|0.055471419158142334|            66.0|               1.6|             10.0|0.38319833098312733|               0.0|                0.0| 0.3998651360945944|204.55184887459808|0.23570226039551584| 0.8000674319527028|               0.0|                0.8|              18.5|              30.9|              1.7| 0.7407032844532456| 0.7184899722686522|               1.7|             0.0|0.003195742693544208|             97.4|0.15238186232786088|0.02213034619658222| 0.5630200554626956|             30.7| 0.33329657944584723|             109.0|               0.8| 97.73333333333335| 0.48196839886325465| 0.22335891754995538| 0.5231770117520154|               0.0|  0.6139275363102388|             3.24| 0.04731287585814677|             10.0|13.199326582148887|  9.94428926011753|              4.1|              30.7|               1.6|   0.56044520340909|  9.43330216554195|             95.0|             67.0|  0.9875101370703736|                0.0|   0.725080657807811|           120.0|                0.0|               4.1|               1.6|  0.6930362318448806|32.15018688413184|           100.0|0.11608214361493663|            99.0|  0.6153947686560318|               0.8|             0.0|                0.0|            70.0| 0.5723090162781292|                 0.0|            14.0|207.85274463007156| 0.18382394812673275|               0.8|               4.1| 0.36712102996921425|206.9605004019292|            14.0|  0.3676478962534655| 0.964593531955711|              18.5| 1.6072751268321592| 0.3312668735370495| 0.5009964792894596|              32.5|           109.0|             40.2|              96.0|             30.7|              16.0| 0.49040166949984454| 0.5605050419662186|               4.1| 89.33333333333333|              3.24|                0.0|              30.7|             18.5|               4.1|0.001597871346772104|33.498131158681616|              10.0|             6.7|             109.0|              30.7| 0.7138454918609354|160.55733211512106| 0.37029854772356713|  0.4886900771438565|  0.454664934364283|  0.4894491185800768|            18.0|9.599003202562052| 0.5245125484381217|  0.7307831554495909|                 0.0|              48.0|              96.0|             16.0|0.027735709579071167|               0.8|209.46905144694534| 0.07903882459641288|              53.5|              6.7| 75.66666666666667|   3.8873012632302|            60.0| 0.986777781674111|             110.0| 0.9509749031237567|              96.0|8.001711156741958|0.5122275324512284|             110.0|             110.0|             95.0|               0.0|           100.0|0.4933888908370555|              16.8|9.21408502024291|  0.8110146029230639|             85.0|                 0.0|              6.7|  0.6045752569230266|                0.0|  0.7279231634644692|0.11401622784425045|                 0.0|              30.7|              16.8|             6.7|                0.0|              60.0|              4.1|210.35680190930788|               4.1|0.40842693744767955|               0.0| 0.4686834829104542|               1.7| 0.2802525209831093|            95.0|0.46784589154325545|0.03951941229820644|              30.9|             3.24|              0.0|             6.7|             92.0|  0.6296483577733771|  0.6126470557419207|0.058041071807468314|0.04040852575860842|           109.0|             110.0|             40.2|                0.0| 0.9536459764959693|0.002359306067165...|0.6456096427150202|  0.5907398170442795|  0.5233400198111846|  0.6914708202684547| 0.7663966619662547|               0.0|           100.0|            16.0|   0.662533747074099|             92.0|             14.0|            136.0|0.30632352787096034|             97.9|             95.0|               0.0|              18.5|             1.6|              4.1|             40.2|            16.0| 0.5062449314648132|             1.6| 0.7229104968886264|              15.0| 0.11167945877497769|              15.0| 0.7957865312761603|             110.0|             40.2|                0.0| 0.5049095001727325|2.305587200599279|10.372238588334406|  0.6977123715384868|                0.8|2.297622738931195|               0.0|                 0.0|  0.5185863354890904|               4.1| 2.078698548207745|            16.0|           109.0|             85.0|              40.2|9.271773418734984|             30.9|90.01611459265891|0.15403168443235046|              0.0|              4.1|            136.0|  0.6360384182677654|             15.0|  0.6083456795889751|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.9251606237456297|             10.0|             97.5| 0.9628273290218192|   0.280222601704545|0.01106517309829111|                0.0|160.30150753768845|0.01153722911082979|0.43500466140042404|             74.0| 0.18356051498460713|90.0066025067144|  0.6958271602055124|             120.0|            60.0|             10.0|                0.0|   0.506758958686583|0.007491553859143...| 0.5766368313274335|0.02307445822165958|            14.0| 32.81576379787387|            136.0|  0.4838445299068336|            40.2|0.9905790501718436|             16.0|  0.6514403098293393|  0.6374596710960945|           120.0|              15.0|90.00044762757386|0.003037197636785...| 0.08081705151721684|9.539477732793522|  0.7692104626879364|7.995208761122519| 0.4952895250859218|  0.9980070414210809|  0.2616700099055923|0.16664828972292361|            12.0| 0.24520083474992227|0.001179653033582...|              15.0| 0.32572015491466966|            10.0|               4.1|              14.0|                 0.0| 0.9763435620709267|              18.5|            83.0| 0.5541790062227472| 0.7116815843362833|205.4315831344471|  0.2447245592900384| 9.375520512820508|              32.5| 0.08350439152559527|               0.0|               0.0|0.041752195762797636|160.4163621135982|            136.0|7.997900981063198|  0.6346084222752045|             109.0|                 0.0|              18.5|             136.0|                0.0|               1.7| 14.11111111111111|              32.5|  0.782497669299788|  0.8185203659114411|               1.7|                 0.0|             136.0|               0.0|0.7269868524702858|             85.0|  0.4866650863530708|               0.0|                 0.0|               1.7|              1.6|             92.0|                 0.0|              16.8|              0.0| 0.6170583594630905|[0.04175219576279...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|\n",
            "|167106.0|2184-06-11|{2184-06-10 00:00...|                0.0|             8.4|             151.0|              13.0|                 0.0| 0.28527572776766313|  0.9948733461022559|              67.0| 83.66666666666667| 0.5500704038677933|             11.0|             57.0|  0.426930727592382|              3.6|              0.0|   0.119741270001636|            79.0|               2.1|             13.4| 0.3034253128759712|               0.0|                0.0| 0.7088611790207303|             142.0|0.29439202887759586| 0.6455694104896348|               0.0|                1.0|              15.1|              30.1|              1.3| 0.8256396060702549| 0.3873596567133406|               1.3|             0.0| 0.05327298400206616|            100.2|                0.0| 0.9404912526956775| 0.7747193134266812|             36.2| 0.41545845588492925|             106.0|               1.0|100.60000000000001|  0.9517022615938819|  0.2555793785383002|0.19879058326481908|               0.0| 0.06607903118648298|             4.44|  0.3897484515890689|             13.4|10.159833769418782| 8.556998435328957|              3.6|              36.2|               2.1| 0.9464621090323675|               9.3|             82.0|            118.0|  0.4344678286732502|                0.0|  0.9382132371331686|           120.0|                0.0|               1.6|               2.1|  0.9669604844067585|             30.0|           100.0| 0.8976366291296707|            96.0|0.028165863154629392|               1.0|             0.0|                0.0|            76.0| 0.7082352766381776|                 0.0|            11.0|             142.0| 0.14520620727291608|               1.0|               3.6|  0.2890958536245729|            142.0|            11.0| 0.29041241454583216|0.9680307246992478|              15.1|  1.049781318335648|0.06704255485263781|0.21515138439841197|              36.9|           106.0|             29.2|151.38370222803474|             36.2|              24.0|  0.6188162389705184|  0.946286246363002|               1.6|135.66666666666666|              4.44|                0.0|              36.2|             15.1|               1.6|  0.9733635079989669|              40.0|              13.4|             8.4|             106.0|              36.2| 0.3541176383190888|160.55733211512106|  0.8160678784568325|  0.6001922151232196| 0.5919660607715838|  0.6178960502701973|            22.0|              9.3|0.19924435279217279|  0.8331874204840826|                 0.0|              71.0|178.49948822927328|             24.0|   0.940129364999182|               1.0|             142.0|    0.83206748784093| 67.66666666666667|              8.4| 83.14285714285714| 5.329930887479322|            50.0|0.9745232284758952|              67.0|0.39848870558434557|127.71084953940634|              8.0| 0.515984637650376|              67.0|              67.0|             82.0| 19.70452579251507|           100.0| 0.491807068783402|              12.5|             9.3|0.010253307795488314|85.00246212121212|                 0.0|              8.4| 0.12149134092137374|                0.0|0.003978308517472698| 0.8998591922644134|                 0.0|              36.2|              12.5|             8.4|                0.0|              50.0|              3.6|             142.0|               1.6| 0.7146464602556497|               0.0|0.47585113079694097|               1.3|  0.526856876818499|            93.0| 0.4705965170838848|  0.416033743920465|              30.1|             4.44|              0.0|             8.4|             90.0| 0.41281980303512744|0.024020233373387774|  0.5511816854351647|  0.419681718607656|           106.0|              67.0|             29.2|                0.0|0.39758116652963815| 0.47770121709823954| 4.714045207910317|  0.9944948028832138|0.001854732736824...|  0.9663949066742558| 0.6068506257519424|               0.0|           100.0|            24.0| 0.13408510970527562|             90.0|             11.0|            139.0| 0.9879898833133061|            100.9|             82.0|               0.0|              15.1|             2.1|              3.6|             29.2|            24.0| 0.2172339143366251|             2.1|0.38858248780445526|              13.0|  0.8722103107308499|              13.0| 0.6426767698721751|              67.0|             29.2|                0.0| 0.3000961075616098|              0.0|7.5203427817856525| 0.06074567046068687|                1.0|              0.0|               0.0|0.002728073736398...|  0.9901562765522123|               3.6| 2.415933503612538|            24.0|           106.0|84.99962121212121|              29.2|              9.3|             30.1|90.01611459265891|                0.0|              0.0|              1.6|            139.0|0.001989154258736349|             13.0| 0.12140996424143871|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614| 0.14263786388383157|             13.4|94.42857142857143|0.01968744689557546|  0.5267689454838163| 0.5297543736521613|                0.0|160.30150753768845| 0.5316972155492664|0.13823561327589817|             95.0| 0.14454792681228645|90.0066025067144|0.060704982120719356|             120.0|            50.0|             13.4|                0.0|  0.3023982933889825|0.007491553859143...| 0.7066539121412764| 0.9366055689014672|            11.0|33.333333333333336|            139.0|  0.9411930341677696|            29.2|0.9836831939012491|             24.0| 0.13762805081724974|  0.4691066185665843|           120.0|              13.0|90.00044762757386|                 0.0|   0.839363437215312|              9.3|0.056331726309258784|              8.0|0.49184159695062457| 0.43030276879682394|  0.9990726336315876|0.48473795362972405|            14.0|  0.3094081194852592| 0.23885060854911977|              13.0| 0.06881402540862487|            13.4|               1.6|              11.0|                 0.0|0.19487422579453445|              15.1|            91.0| 0.7771649756089105| 0.3533269560706382|            142.0| 0.30894802513509867|               9.3|              36.9|  0.7612294089236227|               0.0|               0.0| 0.38061470446181134|160.4163621135982|            139.0|              8.0|  0.4165937102420413|             106.0|                 0.0|              15.1|             139.0|                0.0|               1.3|18.142857142857142|              36.9|0.06911780663794909|0.011010394233572316|               1.3|                 0.0|             139.0|               0.0|0.7269868524702858|85.00530303030303|   0.604796586777965|               0.0|                 0.0|               1.3|              2.1|             90.0|                 0.0|              12.5|              0.0|0.06721018665148852|[0.38061470446181...|(166,[0,3,11,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|\n",
            "+--------+----------+--------------------+-------------------+----------------+------------------+------------------+--------------------+--------------------+--------------------+------------------+------------------+-------------------+-----------------+-----------------+-------------------+-----------------+-----------------+--------------------+----------------+------------------+-----------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------+----------------+--------------------+-----------------+-------------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+-------------------+------------------+--------------------+-----------------+--------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-----------------+-----------------+--------------------+-------------------+--------------------+----------------+-------------------+------------------+------------------+--------------------+-----------------+----------------+-------------------+----------------+--------------------+------------------+----------------+-------------------+----------------+-------------------+--------------------+----------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+----------------+--------------------+------------------+------------------+-------------------+-------------------+-------------------+------------------+----------------+-----------------+------------------+-----------------+------------------+--------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+--------------------+--------------------+-------------------+--------------------+----------------+-----------------+-------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+----------------+------------------+------------------+----------------+--------------------+-----------------+--------------------+-----------------+--------------------+-------------------+--------------------+-------------------+--------------------+------------------+------------------+----------------+-------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+------------------+-------------------+----------------+-------------------+-------------------+------------------+-----------------+-----------------+----------------+-----------------+--------------------+--------------------+--------------------+-------------------+----------------+------------------+-----------------+-------------------+-------------------+--------------------+------------------+--------------------+--------------------+--------------------+-------------------+------------------+----------------+----------------+--------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+------------------+------------------+----------------+-----------------+-----------------+----------------+-------------------+----------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+-----------------+-------------------+-------------------+-----------------+------------------+--------------------+-------------------+-----------------+------------------+--------------------+--------------------+------------------+------------------+----------------+----------------+-----------------+------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+-----------------+--------------------+-----------------+--------------------+-------------------+-------------------+------------------+-------------------+--------------------+-----------------+-----------------+-------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+-----------------+--------------------+----------------+--------------------+------------------+----------------+-----------------+-------------------+--------------------+--------------------+-------------------+-------------------+----------------+------------------+-----------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+-----------------+--------------------+-----------------+-------------------+--------------------+--------------------+-------------------+----------------+--------------------+--------------------+------------------+--------------------+----------------+------------------+------------------+--------------------+-------------------+------------------+----------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+-----------------+-----------------+--------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+-----------------+--------------------+------------------+--------------------+------------------+-----------------+-----------------+--------------------+------------------+-----------------+-------------------+--------------------+--------------------+--------------------+----------------------------------+-----------------------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-----+--------+\n",
            "|label|count(1)|\n",
            "+-----+--------+\n",
            "|  0.0|     250|\n",
            "|  1.0|      71|\n",
            "+-----+--------+\n",
            "\n",
            "root\n",
            " |-- ID: double (nullable = true)\n",
            " |-- TIME_OBS: date (nullable = true)\n",
            " |-- TIME_SPAN: struct (nullable = false)\n",
            " |    |-- TIME_FROM: timestamp (nullable = true)\n",
            " |    |-- TIME_TO: timestamp (nullable = true)\n",
            " |-- imp_N_227465_std: double (nullable = true)\n",
            " |-- imp_N_225625_avg: double (nullable = true)\n",
            " |-- imp_N_220179_max: double (nullable = true)\n",
            " |-- imp_N_227073_avg: double (nullable = true)\n",
            " |-- imp_N_51237_std: double (nullable = true)\n",
            " |-- imp_N_220047_TT: double (nullable = true)\n",
            " |-- imp_N_51222_LT: double (nullable = true)\n",
            " |-- imp_N_220621_min: double (nullable = true)\n",
            " |-- imp_N_220181_avg: double (nullable = true)\n",
            " |-- imp_N_50960_LT: double (nullable = true)\n",
            " |-- imp_N_51006_avg: double (nullable = true)\n",
            " |-- imp_N_220180_min: double (nullable = true)\n",
            " |-- imp_N_223751_LT: double (nullable = true)\n",
            " |-- imp_N_227442_avg: double (nullable = true)\n",
            " |-- imp_N_220046_std: double (nullable = true)\n",
            " |-- imp_N_220181_TT: double (nullable = true)\n",
            " |-- imp_N_220180_max: double (nullable = true)\n",
            " |-- imp_N_50960_min: double (nullable = true)\n",
            " |-- imp_N_51222_avg: double (nullable = true)\n",
            " |-- imp_N_220046_LT: double (nullable = true)\n",
            " |-- imp_N_220228_std: double (nullable = true)\n",
            " |-- imp_N_227442_std: double (nullable = true)\n",
            " |-- imp_N_50902_TT: double (nullable = true)\n",
            " |-- imp_N_51265_min: double (nullable = true)\n",
            " |-- imp_N_223761_std: double (nullable = true)\n",
            " |-- imp_N_50902_LT: double (nullable = true)\n",
            " |-- imp_N_50902_std: double (nullable = true)\n",
            " |-- imp_N_50912_avg: double (nullable = true)\n",
            " |-- imp_N_51274_max: double (nullable = true)\n",
            " |-- imp_N_51248_min: double (nullable = true)\n",
            " |-- imp_N_227467_max: double (nullable = true)\n",
            " |-- imp_N_227073_TT: double (nullable = true)\n",
            " |-- imp_N_227465_LT: double (nullable = true)\n",
            " |-- imp_N_51237_avg: double (nullable = true)\n",
            " |-- imp_N_223769_std: double (nullable = true)\n",
            " |-- imp_N_220179_TT: double (nullable = true)\n",
            " |-- imp_N_223761_min: double (nullable = true)\n",
            " |-- imp_N_51301_std: double (nullable = true)\n",
            " |-- imp_N_50893_TT: double (nullable = true)\n",
            " |-- imp_N_227465_TT: double (nullable = true)\n",
            " |-- imp_N_220545_min: double (nullable = true)\n",
            " |-- imp_N_225664_TT: double (nullable = true)\n",
            " |-- imp_N_50902_min: double (nullable = true)\n",
            " |-- imp_N_50912_max: double (nullable = true)\n",
            " |-- imp_N_223761_avg: double (nullable = true)\n",
            " |-- imp_N_51301_TT: double (nullable = true)\n",
            " |-- imp_N_220180_TT: double (nullable = true)\n",
            " |-- imp_N_227442_LT: double (nullable = true)\n",
            " |-- imp_N_51006_std: double (nullable = true)\n",
            " |-- imp_N_51221_TT: double (nullable = true)\n",
            " |-- imp_N_51279_avg: double (nullable = true)\n",
            " |-- imp_N_223770_TT: double (nullable = true)\n",
            " |-- imp_N_220228_max: double (nullable = true)\n",
            " |-- imp_N_220179_std: double (nullable = true)\n",
            " |-- imp_N_220181_std: double (nullable = true)\n",
            " |-- imp_N_227442_max: double (nullable = true)\n",
            " |-- imp_N_51221_min: double (nullable = true)\n",
            " |-- imp_N_220635_avg: double (nullable = true)\n",
            " |-- imp_N_50983_TT: double (nullable = true)\n",
            " |-- imp_N_220546_avg: double (nullable = true)\n",
            " |-- imp_N_51250_max: double (nullable = true)\n",
            " |-- imp_N_220179_min: double (nullable = true)\n",
            " |-- imp_N_227466_TT: double (nullable = true)\n",
            " |-- imp_N_50971_std: double (nullable = true)\n",
            " |-- imp_N_51248_TT: double (nullable = true)\n",
            " |-- imp_N_220046_max: double (nullable = true)\n",
            " |-- imp_N_227073_std: double (nullable = true)\n",
            " |-- imp_N_225677_avg: double (nullable = true)\n",
            " |-- imp_N_50960_avg: double (nullable = true)\n",
            " |-- imp_N_51221_LT: double (nullable = true)\n",
            " |-- imp_N_224161_min: double (nullable = true)\n",
            " |-- imp_N_223769_min: double (nullable = true)\n",
            " |-- imp_N_220635_TT: double (nullable = true)\n",
            " |-- imp_N_220277_max: double (nullable = true)\n",
            " |-- imp_N_51277_LT: double (nullable = true)\n",
            " |-- imp_N_220615_max: double (nullable = true)\n",
            " |-- imp_N_225624_std: double (nullable = true)\n",
            " |-- imp_N_51249_std: double (nullable = true)\n",
            " |-- imp_N_220045_min: double (nullable = true)\n",
            " |-- imp_N_227467_TT: double (nullable = true)\n",
            " |-- imp_N_220635_std: double (nullable = true)\n",
            " |-- imp_N_225624_min: double (nullable = true)\n",
            " |-- imp_N_227457_avg: double (nullable = true)\n",
            " |-- imp_N_225624_LT: double (nullable = true)\n",
            " |-- imp_N_220615_min: double (nullable = true)\n",
            " |-- imp_N_50971_max: double (nullable = true)\n",
            " |-- imp_N_51006_TT: double (nullable = true)\n",
            " |-- imp_N_51265_avg: double (nullable = true)\n",
            " |-- imp_N_225624_avg: double (nullable = true)\n",
            " |-- imp_N_225624_TT: double (nullable = true)\n",
            " |-- imp_N_224162_TT: double (nullable = true)\n",
            " |-- imp_N_227465_min: double (nullable = true)\n",
            " |-- imp_N_220277_std: double (nullable = true)\n",
            " |-- imp_N_50931_LT: double (nullable = true)\n",
            " |-- imp_N_51275_LT: double (nullable = true)\n",
            " |-- imp_N_51249_max: double (nullable = true)\n",
            " |-- imp_N_220602_max: double (nullable = true)\n",
            " |-- imp_N_51275_min: double (nullable = true)\n",
            " |-- imp_N_225664_avg: double (nullable = true)\n",
            " |-- imp_N_220545_max: double (nullable = true)\n",
            " |-- imp_N_50882_min: double (nullable = true)\n",
            " |-- imp_N_220615_TT: double (nullable = true)\n",
            " |-- imp_N_220645_TT: double (nullable = true)\n",
            " |-- imp_N_225677_max: double (nullable = true)\n",
            " |-- imp_N_220179_avg: double (nullable = true)\n",
            " |-- imp_N_51279_min: double (nullable = true)\n",
            " |-- imp_N_223770_std: double (nullable = true)\n",
            " |-- imp_N_51221_max: double (nullable = true)\n",
            " |-- imp_N_51274_min: double (nullable = true)\n",
            " |-- imp_N_50970_min: double (nullable = true)\n",
            " |-- imp_N_220179_LT: double (nullable = true)\n",
            " |-- imp_N_224161_max: double (nullable = true)\n",
            " |-- imp_N_220228_avg: double (nullable = true)\n",
            " |-- imp_N_225625_max: double (nullable = true)\n",
            " |-- imp_N_50902_avg: double (nullable = true)\n",
            " |-- imp_N_220545_avg: double (nullable = true)\n",
            " |-- imp_N_227467_LT: double (nullable = true)\n",
            " |-- imp_N_223751_max: double (nullable = true)\n",
            " |-- imp_N_224161_TT: double (nullable = true)\n",
            " |-- imp_N_227457_TT: double (nullable = true)\n",
            " |-- imp_N_224161_LT: double (nullable = true)\n",
            " |-- imp_N_50912_TT: double (nullable = true)\n",
            " |-- imp_N_220210_max: double (nullable = true)\n",
            " |-- imp_N_220546_max: double (nullable = true)\n",
            " |-- imp_N_50971_LT: double (nullable = true)\n",
            " |-- imp_N_50868_TT: double (nullable = true)\n",
            " |-- imp_N_50893_std: double (nullable = true)\n",
            " |-- imp_N_220181_min: double (nullable = true)\n",
            " |-- imp_N_225664_max: double (nullable = true)\n",
            " |-- imp_N_50882_max: double (nullable = true)\n",
            " |-- imp_N_220181_LT: double (nullable = true)\n",
            " |-- imp_N_50912_min: double (nullable = true)\n",
            " |-- imp_N_51265_max: double (nullable = true)\n",
            " |-- imp_N_50882_TT: double (nullable = true)\n",
            " |-- imp_N_220180_avg: double (nullable = true)\n",
            " |-- imp_N_50893_max: double (nullable = true)\n",
            " |-- imp_N_220045_avg: double (nullable = true)\n",
            " |-- imp_N_220045_std: double (nullable = true)\n",
            " |-- imp_N_220047_min: double (nullable = true)\n",
            " |-- imp_N_226253_TT: double (nullable = true)\n",
            " |-- imp_N_220621_max: double (nullable = true)\n",
            " |-- imp_N_50971_TT: double (nullable = true)\n",
            " |-- imp_N_225664_min: double (nullable = true)\n",
            " |-- imp_N_224162_max: double (nullable = true)\n",
            " |-- imp_N_224162_LT: double (nullable = true)\n",
            " |-- imp_N_50931_min: double (nullable = true)\n",
            " |-- imp_N_220621_avg: double (nullable = true)\n",
            " |-- imp_N_51250_min: double (nullable = true)\n",
            " |-- imp_N_225664_std: double (nullable = true)\n",
            " |-- imp_N_223769_max: double (nullable = true)\n",
            " |-- imp_N_226253_LT: double (nullable = true)\n",
            " |-- imp_N_51277_min: double (nullable = true)\n",
            " |-- imp_N_51301_min: double (nullable = true)\n",
            " |-- imp_N_51222_TT: double (nullable = true)\n",
            " |-- imp_N_226253_avg: double (nullable = true)\n",
            " |-- imp_N_51279_std: double (nullable = true)\n",
            " |-- imp_N_50893_min: double (nullable = true)\n",
            " |-- imp_N_50970_TT: double (nullable = true)\n",
            " |-- imp_N_51274_std: double (nullable = true)\n",
            " |-- imp_N_220277_TT: double (nullable = true)\n",
            " |-- imp_N_50960_TT: double (nullable = true)\n",
            " |-- imp_N_50960_std: double (nullable = true)\n",
            " |-- imp_N_51221_avg: double (nullable = true)\n",
            " |-- imp_N_51277_max: double (nullable = true)\n",
            " |-- imp_N_225625_min: double (nullable = true)\n",
            " |-- imp_N_51277_std: double (nullable = true)\n",
            " |-- imp_N_220047_avg: double (nullable = true)\n",
            " |-- imp_N_50971_avg: double (nullable = true)\n",
            " |-- imp_N_227457_max: double (nullable = true)\n",
            " |-- imp_N_50970_max: double (nullable = true)\n",
            " |-- imp_N_220602_TT: double (nullable = true)\n",
            " |-- imp_N_50931_std: double (nullable = true)\n",
            " |-- imp_N_51301_LT: double (nullable = true)\n",
            " |-- imp_N_227467_min: double (nullable = true)\n",
            " |-- imp_N_220645_LT: double (nullable = true)\n",
            " |-- imp_N_220277_min: double (nullable = true)\n",
            " |-- imp_N_220546_LT: double (nullable = true)\n",
            " |-- imp_N_50882_LT: double (nullable = true)\n",
            " |-- imp_N_51248_avg: double (nullable = true)\n",
            " |-- imp_N_51279_max: double (nullable = true)\n",
            " |-- imp_N_220602_std: double (nullable = true)\n",
            " |-- imp_N_50893_avg: double (nullable = true)\n",
            " |-- imp_N_223770_avg: double (nullable = true)\n",
            " |-- imp_N_227073_LT: double (nullable = true)\n",
            " |-- imp_N_51249_TT: double (nullable = true)\n",
            " |-- imp_N_220635_LT: double (nullable = true)\n",
            " |-- imp_N_227443_LT: double (nullable = true)\n",
            " |-- imp_N_220602_avg: double (nullable = true)\n",
            " |-- imp_N_50931_avg: double (nullable = true)\n",
            " |-- imp_N_227466_avg: double (nullable = true)\n",
            " |-- imp_N_220545_std: double (nullable = true)\n",
            " |-- imp_N_227442_TT: double (nullable = true)\n",
            " |-- imp_N_220210_TT: double (nullable = true)\n",
            " |-- imp_N_224161_std: double (nullable = true)\n",
            " |-- imp_N_220228_LT: double (nullable = true)\n",
            " |-- imp_N_223761_TT: double (nullable = true)\n",
            " |-- imp_N_220545_LT: double (nullable = true)\n",
            " |-- imp_N_220046_TT: double (nullable = true)\n",
            " |-- imp_N_50983_std: double (nullable = true)\n",
            " |-- imp_N_223769_avg: double (nullable = true)\n",
            " |-- imp_N_227443_min: double (nullable = true)\n",
            " |-- imp_N_50931_TT: double (nullable = true)\n",
            " |-- imp_N_223770_max: double (nullable = true)\n",
            " |-- imp_N_51006_min: double (nullable = true)\n",
            " |-- imp_N_220645_min: double (nullable = true)\n",
            " |-- imp_N_51249_LT: double (nullable = true)\n",
            " |-- imp_N_223761_max: double (nullable = true)\n",
            " |-- imp_N_51250_avg: double (nullable = true)\n",
            " |-- imp_N_220645_std: double (nullable = true)\n",
            " |-- imp_N_51274_avg: double (nullable = true)\n",
            " |-- imp_N_220635_min: double (nullable = true)\n",
            " |-- imp_N_50971_min: double (nullable = true)\n",
            " |-- imp_N_51275_avg: double (nullable = true)\n",
            " |-- imp_N_227443_avg: double (nullable = true)\n",
            " |-- imp_N_227466_LT: double (nullable = true)\n",
            " |-- imp_N_220635_max: double (nullable = true)\n",
            " |-- imp_N_51274_LT: double (nullable = true)\n",
            " |-- imp_N_227073_max: double (nullable = true)\n",
            " |-- imp_N_220180_LT: double (nullable = true)\n",
            " |-- imp_N_227073_min: double (nullable = true)\n",
            " |-- imp_N_220602_LT: double (nullable = true)\n",
            " |-- imp_N_50931_max: double (nullable = true)\n",
            " |-- imp_N_227466_max: double (nullable = true)\n",
            " |-- imp_N_51222_std: double (nullable = true)\n",
            " |-- imp_N_227457_LT: double (nullable = true)\n",
            " |-- imp_N_227457_std: double (nullable = true)\n",
            " |-- imp_N_220180_std: double (nullable = true)\n",
            " |-- imp_N_50970_LT: double (nullable = true)\n",
            " |-- imp_N_220615_avg: double (nullable = true)\n",
            " |-- imp_N_51265_std: double (nullable = true)\n",
            " |-- imp_N_50882_std: double (nullable = true)\n",
            " |-- imp_N_226253_std: double (nullable = true)\n",
            " |-- imp_N_51279_LT: double (nullable = true)\n",
            " |-- imp_N_227442_min: double (nullable = true)\n",
            " |-- imp_N_220210_std: double (nullable = true)\n",
            " |-- imp_N_227443_max: double (nullable = true)\n",
            " |-- imp_N_220602_min: double (nullable = true)\n",
            " |-- imp_N_226253_min: double (nullable = true)\n",
            " |-- imp_N_227466_min: double (nullable = true)\n",
            " |-- imp_N_220546_min: double (nullable = true)\n",
            " |-- imp_N_51248_max: double (nullable = true)\n",
            " |-- imp_N_223752_max: double (nullable = true)\n",
            " |-- imp_N_220546_std: double (nullable = true)\n",
            " |-- imp_N_227443_std: double (nullable = true)\n",
            " |-- imp_N_225677_min: double (nullable = true)\n",
            " |-- imp_N_50983_min: double (nullable = true)\n",
            " |-- imp_N_220277_LT: double (nullable = true)\n",
            " |-- imp_N_50868_avg: double (nullable = true)\n",
            " |-- imp_N_225677_TT: double (nullable = true)\n",
            " |-- imp_N_50868_std: double (nullable = true)\n",
            " |-- imp_N_223752_LT: double (nullable = true)\n",
            " |-- imp_N_223752_TT: double (nullable = true)\n",
            " |-- imp_N_223751_std: double (nullable = true)\n",
            " |-- imp_N_220047_LT: double (nullable = true)\n",
            " |-- imp_N_51222_min: double (nullable = true)\n",
            " |-- imp_N_220277_avg: double (nullable = true)\n",
            " |-- imp_N_51279_TT: double (nullable = true)\n",
            " |-- imp_N_50983_LT: double (nullable = true)\n",
            " |-- imp_N_50893_LT: double (nullable = true)\n",
            " |-- imp_N_51248_std: double (nullable = true)\n",
            " |-- imp_N_223751_min: double (nullable = true)\n",
            " |-- imp_N_225625_LT: double (nullable = true)\n",
            " |-- imp_N_51250_TT: double (nullable = true)\n",
            " |-- imp_N_220181_max: double (nullable = true)\n",
            " |-- imp_N_51006_LT: double (nullable = true)\n",
            " |-- imp_N_223752_avg: double (nullable = true)\n",
            " |-- imp_N_225677_LT: double (nullable = true)\n",
            " |-- imp_N_220046_avg: double (nullable = true)\n",
            " |-- imp_N_220047_max: double (nullable = true)\n",
            " |-- imp_N_51222_max: double (nullable = true)\n",
            " |-- imp_N_225625_std: double (nullable = true)\n",
            " |-- imp_N_51265_LT: double (nullable = true)\n",
            " |-- imp_N_223752_std: double (nullable = true)\n",
            " |-- imp_N_51237_TT: double (nullable = true)\n",
            " |-- imp_N_225625_TT: double (nullable = true)\n",
            " |-- imp_N_225624_max: double (nullable = true)\n",
            " |-- imp_N_224161_avg: double (nullable = true)\n",
            " |-- imp_N_50983_max: double (nullable = true)\n",
            " |-- imp_N_220546_TT: double (nullable = true)\n",
            " |-- imp_N_51275_max: double (nullable = true)\n",
            " |-- imp_N_223769_TT: double (nullable = true)\n",
            " |-- imp_N_50882_avg: double (nullable = true)\n",
            " |-- imp_N_220621_TT: double (nullable = true)\n",
            " |-- imp_N_51248_LT: double (nullable = true)\n",
            " |-- imp_N_220046_min: double (nullable = true)\n",
            " |-- imp_N_50868_min: double (nullable = true)\n",
            " |-- imp_N_223752_min: double (nullable = true)\n",
            " |-- imp_N_224162_std: double (nullable = true)\n",
            " |-- imp_N_227443_TT: double (nullable = true)\n",
            " |-- imp_N_51301_max: double (nullable = true)\n",
            " |-- imp_N_51277_TT: double (nullable = true)\n",
            " |-- imp_N_224162_min: double (nullable = true)\n",
            " |-- imp_N_223769_LT: double (nullable = true)\n",
            " |-- imp_N_51275_TT: double (nullable = true)\n",
            " |-- imp_N_223761_LT: double (nullable = true)\n",
            " |-- imp_N_225664_LT: double (nullable = true)\n",
            " |-- imp_N_220210_min: double (nullable = true)\n",
            " |-- imp_N_220615_LT: double (nullable = true)\n",
            " |-- imp_N_220210_LT: double (nullable = true)\n",
            " |-- imp_N_50868_max: double (nullable = true)\n",
            " |-- imp_N_220621_LT: double (nullable = true)\n",
            " |-- imp_N_220228_min: double (nullable = true)\n",
            " |-- imp_N_50970_avg: double (nullable = true)\n",
            " |-- imp_N_51006_max: double (nullable = true)\n",
            " |-- imp_N_227467_std: double (nullable = true)\n",
            " |-- imp_N_223770_LT: double (nullable = true)\n",
            " |-- imp_N_227465_max: double (nullable = true)\n",
            " |-- imp_N_220045_max: double (nullable = true)\n",
            " |-- imp_N_51274_TT: double (nullable = true)\n",
            " |-- imp_N_51237_LT: double (nullable = true)\n",
            " |-- imp_N_227457_min: double (nullable = true)\n",
            " |-- imp_N_50912_LT: double (nullable = true)\n",
            " |-- imp_N_51301_avg: double (nullable = true)\n",
            " |-- imp_N_51249_min: double (nullable = true)\n",
            " |-- imp_N_220045_TT: double (nullable = true)\n",
            " |-- imp_N_220621_std: double (nullable = true)\n",
            " |-- imp_N_227466_std: double (nullable = true)\n",
            " |-- imp_N_220045_LT: double (nullable = true)\n",
            " |-- imp_N_223751_avg: double (nullable = true)\n",
            " |-- imp_N_220645_avg: double (nullable = true)\n",
            " |-- imp_N_224162_avg: double (nullable = true)\n",
            " |-- imp_N_50868_LT: double (nullable = true)\n",
            " |-- imp_N_50902_max: double (nullable = true)\n",
            " |-- imp_N_50912_std: double (nullable = true)\n",
            " |-- imp_N_227465_avg: double (nullable = true)\n",
            " |-- imp_N_220645_max: double (nullable = true)\n",
            " |-- imp_N_51221_std: double (nullable = true)\n",
            " |-- imp_N_227467_avg: double (nullable = true)\n",
            " |-- imp_N_220210_avg: double (nullable = true)\n",
            " |-- imp_N_51249_avg: double (nullable = true)\n",
            " |-- imp_N_51250_LT: double (nullable = true)\n",
            " |-- imp_N_220228_TT: double (nullable = true)\n",
            " |-- imp_N_51237_min: double (nullable = true)\n",
            " |-- imp_N_225677_std: double (nullable = true)\n",
            " |-- imp_N_50983_avg: double (nullable = true)\n",
            " |-- imp_N_51250_std: double (nullable = true)\n",
            " |-- imp_N_223751_TT: double (nullable = true)\n",
            " |-- imp_N_226253_max: double (nullable = true)\n",
            " |-- imp_N_51265_TT: double (nullable = true)\n",
            " |-- imp_N_51275_std: double (nullable = true)\n",
            " |-- imp_N_50970_std: double (nullable = true)\n",
            " |-- imp_N_51237_max: double (nullable = true)\n",
            " |-- imp_N_50960_max: double (nullable = true)\n",
            " |-- imp_N_223770_min: double (nullable = true)\n",
            " |-- imp_N_220615_std: double (nullable = true)\n",
            " |-- imp_N_51277_avg: double (nullable = true)\n",
            " |-- imp_N_220047_std: double (nullable = true)\n",
            " |-- imp_N_220545_TT: double (nullable = true)\n",
            " |-- features_imputed: vector (nullable = true)\n",
            " |-- demo_feature: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- DISCH_51881_51851_51884_51853_excl: double (nullable = true)\n",
            " |-- DISCH_51881_51851_51884_51853_label: double (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:170: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 330712483 entries, 0 to 330712482\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   ID        int32 \n",
            " 1   ITEMID    int32 \n",
            " 2   TIME_OBS  object\n",
            " 3   VALUE     object\n",
            " 4   SOURCE    object\n",
            "dtypes: int32(2), object(3)\n",
            "memory usage: 9.9+ GB\n",
            "None\n",
            "Index              128\n",
            "ID          1322849932\n",
            "ITEMID      1322849932\n",
            "TIME_OBS    2645699864\n",
            "VALUE       2645699864\n",
            "SOURCE      2645699864\n",
            "dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27854055 entries, 0 to 27854054\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype  \n",
            "---  ------    -----  \n",
            " 0   ID        float64\n",
            " 1   ITEMID    int64  \n",
            " 2   TIME_OBS  object \n",
            " 3   VALUE     object \n",
            " 4   SOURCE    object \n",
            "dtypes: float64(1), int64(1), object(3)\n",
            "memory usage: 1.0+ GB\n",
            "None\n",
            "Index             128\n",
            "ID          222832440\n",
            "ITEMID      222832440\n",
            "TIME_OBS    222832440\n",
            "VALUE       222832440\n",
            "SOURCE      222832440\n",
            "dtype: int64\n",
            "check!!!\n",
            "(0, 1)\n",
            "         ID  ITEMID            TIME_OBS VALUE SOURCE    DBSOURCE DNR_TIME\n",
            "0  165660.0  223834 2134-05-12 12:00:00    15  VITAL  metavision      NaT\n",
            "1  165660.0  223835 2134-05-12 12:00:00   100  VITAL  metavision      NaT\n",
            "2  165660.0  224328 2134-05-12 12:00:00  0.37  VITAL  metavision      NaT\n",
            "3  165660.0  224329 2134-05-12 12:00:00     6  VITAL  metavision      NaT\n",
            "4  165660.0  224330 2134-05-12 12:00:00   2.5  VITAL  metavision      NaT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 330712483 entries, 0 to 330712482\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype \n",
            "---  ------    ----- \n",
            " 0   ID        int32 \n",
            " 1   ITEMID    int32 \n",
            " 2   TIME_OBS  object\n",
            " 3   VALUE     object\n",
            " 4   SOURCE    object\n",
            "dtypes: int32(2), object(3)\n",
            "memory usage: 9.9+ GB\n",
            "None\n",
            "Index              128\n",
            "ID          1322849932\n",
            "ITEMID      1322849932\n",
            "TIME_OBS    2645699864\n",
            "VALUE       2645699864\n",
            "SOURCE      2645699864\n",
            "dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27854055 entries, 0 to 27854054\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Dtype  \n",
            "---  ------    -----  \n",
            " 0   ID        float64\n",
            " 1   ITEMID    int64  \n",
            " 2   TIME_OBS  object \n",
            " 3   VALUE     object \n",
            " 4   SOURCE    object \n",
            "dtypes: float64(1), int64(1), object(3)\n",
            "memory usage: 1.0+ GB\n",
            "None\n",
            "Index             128\n",
            "ID          222832440\n",
            "ITEMID      222832440\n",
            "TIME_OBS    222832440\n",
            "VALUE       222832440\n",
            "SOURCE      222832440\n",
            "dtype: int64\n",
            "check!!!\n",
            "(0, 1)\n",
            "         ID  ITEMID            TIME_OBS VALUE SOURCE    DBSOURCE DNR_TIME\n",
            "0  165660.0  223834 2134-05-12 12:00:00    15  VITAL  metavision      NaT\n",
            "1  165660.0  223835 2134-05-12 12:00:00   100  VITAL  metavision      NaT\n",
            "2  165660.0  224328 2134-05-12 12:00:00  0.37  VITAL  metavision      NaT\n",
            "3  165660.0  224329 2134-05-12 12:00:00     6  VITAL  metavision      NaT\n",
            "4  165660.0  224330 2134-05-12 12:00:00   2.5  VITAL  metavision      NaT\n",
            "620\n",
            "[ True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False  True False  True False\n",
            "  True False  True False  True False  True False]\n",
            "[118007. 163199. 115553. 138376. 139346. 164735. 147462. 175168. 119255.\n",
            " 109992. 139061. 156942. 170024. 194618. 158507. 188386. 189443. 185291.\n",
            " 183910. 176637. 189546. 113195. 162934. 198930. 141389. 180104. 192698.\n",
            " 117648. 145304. 119213. 125288. 138805. 154714. 125578. 114707. 135732.\n",
            " 145323. 195707. 144830. 186680. 166628. 118608. 112028. 167945. 186355.\n",
            " 102354. 170681. 196721. 170252. 134370. 148642. 149111. 173495. 139221.\n",
            " 107918. 163539. 142774. 154648. 125857. 197436. 178216. 121938. 132401.\n",
            " 173988. 138877. 159874. 198464. 140995. 109309. 114572. 189745. 166453.\n",
            " 181445. 102486. 196749. 163080. 152254. 102024. 193970. 178576. 188969.\n",
            " 173708. 112643. 124460. 104328. 130986. 170786. 105192. 109932. 173442.\n",
            " 173633. 175684. 151196. 101259. 135998. 129425. 149546. 122379. 161129.\n",
            " 182255. 102607. 183494. 127215. 162768. 101322. 116188. 124657. 112077.\n",
            " 194269. 107213. 182383. 119090. 185539. 129741. 170430. 192557. 180659.\n",
            " 154530. 165323. 101537. 135108. 122518. 154086. 160186. 172739. 197882.\n",
            " 168848. 161140. 164846. 155897. 153637. 161635. 128108. 129899. 160127.\n",
            " 147286. 164660. 153202. 128932. 158813. 134761. 165590. 156020. 178736.\n",
            " 157563. 114726. 152771. 151240. 199622. 156497. 145955. 124398. 136637.\n",
            " 111302. 117923. 140146. 185375. 113189. 111312. 133450. 126020. 172439.\n",
            " 128648. 126769. 197057. 181810. 168356. 155618. 135882. 129757. 174925.\n",
            " 194191. 103106. 155098. 110184. 134152. 120497. 148275. 174417. 198393.\n",
            " 168686. 157895. 158975. 197426. 135186. 108856. 105852. 133491. 190740.\n",
            " 153755. 132331. 130982. 141424. 195962. 163733. 126055. 123032. 130537.\n",
            " 162718. 170047. 199008. 152037. 150720. 139914. 130702. 172805. 173581.\n",
            " 107414. 124525. 145953. 140410. 167393. 187697. 107580. 132067. 161526.\n",
            " 113717. 155191. 114887. 165242. 146557. 137510. 142000. 195990. 153072.\n",
            " 182796. 193317. 126217. 190933. 176904. 132890. 199221. 117988. 109045.\n",
            " 191767. 166923. 121412. 169807. 169479. 145688. 109208. 178411. 178473.\n",
            " 199609. 140547. 192358. 128201. 124439. 117876. 164646. 174095. 125726.\n",
            " 148740. 135923. 138942. 115545. 101759. 147339. 191117. 162589. 113090.\n",
            " 140666. 182566. 190628. 184345. 105481. 106048. 134584. 103203. 171505.\n",
            " 116807. 131376. 109633. 168932. 190365. 131713. 140109. 114247. 156682.\n",
            " 177047. 128899. 111375. 173305. 137638. 116346. 137117. 108168. 140431.\n",
            " 148904. 162248. 133203. 194340. 134410. 178164. 175505. 137250. 192031.\n",
            " 154854. 100931. 151109. 159536. 197750. 172420. 168943. 125028. 170299.\n",
            " 174162. 112951. 181697. 111063.]\n",
            "VAL_ROUND_0_TARGET IDS:[118007.0, 163199.0, 115553.0, 138376.0, 139346.0, 164735.0, 147462.0, 175168.0, 119255.0, 109992.0, 139061.0, 156942.0, 170024.0, 194618.0, 158507.0, 188386.0, 189443.0, 185291.0, 183910.0, 176637.0, 189546.0, 113195.0, 162934.0, 198930.0, 141389.0, 180104.0, 192698.0, 117648.0, 145304.0, 119213.0, 125288.0, 138805.0, 154714.0, 125578.0, 114707.0, 135732.0, 145323.0, 195707.0, 144830.0, 186680.0, 166628.0, 118608.0, 112028.0, 167945.0, 186355.0, 102354.0, 170681.0, 196721.0, 170252.0, 134370.0, 148642.0, 149111.0, 173495.0, 139221.0, 107918.0, 163539.0, 142774.0, 154648.0, 125857.0, 197436.0, 178216.0, 121938.0, 132401.0, 173988.0, 138877.0, 159874.0, 198464.0, 140995.0, 109309.0, 114572.0, 189745.0, 166453.0, 181445.0, 102486.0, 196749.0, 163080.0, 152254.0, 102024.0, 193970.0, 178576.0, 188969.0, 173708.0, 112643.0, 124460.0, 104328.0, 130986.0, 170786.0, 105192.0, 109932.0, 173442.0, 173633.0, 175684.0, 151196.0, 101259.0, 135998.0, 129425.0, 149546.0, 122379.0, 161129.0, 182255.0, 102607.0, 183494.0, 127215.0, 162768.0, 101322.0, 116188.0, 124657.0, 112077.0, 194269.0, 107213.0, 182383.0, 119090.0, 185539.0, 129741.0, 170430.0, 192557.0, 180659.0, 154530.0, 165323.0, 101537.0, 135108.0, 122518.0, 154086.0, 160186.0, 172739.0, 197882.0, 168848.0, 161140.0, 164846.0, 155897.0, 153637.0, 161635.0, 128108.0, 129899.0, 160127.0, 147286.0, 164660.0, 153202.0, 128932.0, 158813.0, 134761.0, 165590.0, 156020.0, 178736.0, 157563.0, 114726.0, 152771.0, 151240.0, 199622.0, 156497.0, 145955.0, 124398.0, 136637.0, 111302.0, 117923.0, 140146.0, 185375.0, 113189.0, 111312.0, 133450.0, 126020.0, 172439.0, 128648.0, 126769.0, 197057.0, 181810.0, 168356.0, 155618.0, 135882.0, 129757.0, 174925.0, 194191.0, 103106.0, 155098.0, 110184.0, 134152.0, 120497.0, 148275.0, 174417.0, 198393.0, 168686.0, 157895.0, 158975.0, 197426.0, 135186.0, 108856.0, 105852.0, 133491.0, 190740.0, 153755.0, 132331.0, 130982.0, 141424.0, 195962.0, 163733.0, 126055.0, 123032.0, 130537.0, 162718.0, 170047.0, 199008.0, 152037.0, 150720.0, 139914.0, 130702.0, 172805.0, 173581.0, 107414.0, 124525.0, 145953.0, 140410.0, 167393.0, 187697.0, 107580.0, 132067.0, 161526.0, 113717.0, 155191.0, 114887.0, 165242.0, 146557.0, 137510.0, 142000.0, 195990.0, 153072.0, 182796.0, 193317.0, 126217.0, 190933.0, 176904.0, 132890.0, 199221.0, 117988.0, 109045.0, 191767.0, 166923.0, 121412.0, 169807.0, 169479.0, 145688.0, 109208.0, 178411.0, 178473.0, 199609.0, 140547.0, 192358.0, 128201.0, 124439.0, 117876.0, 164646.0, 174095.0, 125726.0, 148740.0, 135923.0, 138942.0, 115545.0, 101759.0, 147339.0, 191117.0, 162589.0, 113090.0, 140666.0, 182566.0, 190628.0, 184345.0, 105481.0, 106048.0, 134584.0, 103203.0, 171505.0, 116807.0, 131376.0, 109633.0, 168932.0, 190365.0, 131713.0, 140109.0, 114247.0, 156682.0, 177047.0, 128899.0, 111375.0, 173305.0, 137638.0, 116346.0, 137117.0, 108168.0, 140431.0, 148904.0, 162248.0, 133203.0, 194340.0, 134410.0, 178164.0, 175505.0, 137250.0, 192031.0, 154854.0, 100931.0, 151109.0, 159536.0, 197750.0, 172420.0, 168943.0, 125028.0, 170299.0, 174162.0, 112951.0, 181697.0, 111063.0]\n",
            "+-----+--------+\n",
            "|label|count(1)|\n",
            "+-----+--------+\n",
            "|  0.0|    1040|\n",
            "|  1.0|     340|\n",
            "+-----+--------+\n",
            "\n",
            "+-----+--------------------+\n",
            "|label|rawPrediction       |\n",
            "+-----+--------------------+\n",
            "|0.0  |0.8921432874988979  |\n",
            "|0.0  |0.3612920705314888  |\n",
            "|0.0  |0.08979530841536687 |\n",
            "|0.0  |0.056782803385060254|\n",
            "|0.0  |0.412662178390394   |\n",
            "|0.0  |0.09482459311024782 |\n",
            "|0.0  |0.3119557463860063  |\n",
            "|1.0  |0.4720329226216117  |\n",
            "|0.0  |0.37914267018035297 |\n",
            "|0.0  |0.592465433390437   |\n",
            "|1.0  |0.6983196203399575  |\n",
            "|0.0  |0.2191164773723311  |\n",
            "|0.0  |0.9853041343046071  |\n",
            "|1.0  |0.25541459768035746 |\n",
            "|0.0  |0.1801120932783521  |\n",
            "|0.0  |0.08647182687067223 |\n",
            "|0.0  |0.3114202745835132  |\n",
            "|0.0  |0.037682857815271364|\n",
            "|0.0  |0.11689798970770215 |\n",
            "|0.0  |0.4223445870134137  |\n",
            "|0.0  |0.475298844453219   |\n",
            "|0.0  |0.2529643195341682  |\n",
            "|0.0  |0.16279519069805004 |\n",
            "|0.0  |0.18268231148216096 |\n",
            "|0.0  |0.9999561832291491  |\n",
            "|0.0  |0.1938829975827473  |\n",
            "|0.0  |0.42020015036851843 |\n",
            "|0.0  |0.9045027198966328  |\n",
            "|0.0  |0.19306400685571012 |\n",
            "|0.0  |0.14792433176751774 |\n",
            "|0.0  |0.07902662803158533 |\n",
            "|0.0  |0.9479339167081579  |\n",
            "|0.0  |0.22996621597159594 |\n",
            "|0.0  |0.9991074739663964  |\n",
            "|0.0  |0.22039846023995924 |\n",
            "|0.0  |0.3502435887580474  |\n",
            "|0.0  |0.25913189346922305 |\n",
            "|0.0  |0.13704614836687545 |\n",
            "|0.0  |0.990839819003091   |\n",
            "|1.0  |0.7769294141298271  |\n",
            "|0.0  |0.9534100572062748  |\n",
            "|0.0  |0.24653193092783054 |\n",
            "|0.0  |0.33042224852196433 |\n",
            "|0.0  |0.2516911722590366  |\n",
            "|1.0  |0.9999975581715221  |\n",
            "|0.0  |0.37565234540292725 |\n",
            "|0.0  |0.08505618414762806 |\n",
            "|1.0  |0.9999880192375189  |\n",
            "|1.0  |0.7191977560544125  |\n",
            "|0.0  |0.1220959725388494  |\n",
            "|0.0  |0.48677843864607506 |\n",
            "|0.0  |0.15701441204788025 |\n",
            "|1.0  |0.26821400130418893 |\n",
            "|0.0  |0.5237953696417591  |\n",
            "|1.0  |0.8410414061588747  |\n",
            "|0.0  |0.7421565979099323  |\n",
            "|1.0  |0.2634541761622494  |\n",
            "|0.0  |0.4958981888785834  |\n",
            "|0.0  |0.3053274068163727  |\n",
            "|0.0  |0.16523409524234167 |\n",
            "|0.0  |0.312411060507956   |\n",
            "|1.0  |0.4225846161287874  |\n",
            "|0.0  |0.865809731170466   |\n",
            "|0.0  |0.24173698695202062 |\n",
            "|0.0  |0.16536984749238892 |\n",
            "|0.0  |0.40117517923242074 |\n",
            "|0.0  |0.8738030075177741  |\n",
            "|0.0  |0.33632053695139996 |\n",
            "|0.0  |0.14022009122961654 |\n",
            "|0.0  |0.1218944046598276  |\n",
            "|0.0  |0.5233846354351769  |\n",
            "|1.0  |0.9204742520211836  |\n",
            "|0.0  |0.648328828637721   |\n",
            "|0.0  |0.9035372928395646  |\n",
            "|0.0  |0.235368525329551   |\n",
            "|0.0  |0.589212961481061   |\n",
            "|0.0  |0.13215549674412097 |\n",
            "|0.0  |0.12729141948916467 |\n",
            "|0.0  |0.044670111648168476|\n",
            "|0.0  |0.14791794734941643 |\n",
            "|0.0  |0.16947010530714435 |\n",
            "|0.0  |0.17009957818593846 |\n",
            "|0.0  |0.9564137366851847  |\n",
            "|1.0  |0.22868645743641136 |\n",
            "|0.0  |0.17959951517497097 |\n",
            "|0.0  |0.23269689518251757 |\n",
            "|0.0  |0.1837154845234943  |\n",
            "|1.0  |0.9107728135294719  |\n",
            "|0.0  |0.3362338346449665  |\n",
            "|0.0  |0.9685423360235986  |\n",
            "|0.0  |0.1484796421617547  |\n",
            "|0.0  |0.7602737527377478  |\n",
            "|0.0  |0.430567047677174   |\n",
            "|0.0  |0.5513419504679329  |\n",
            "|0.0  |0.20051209753041033 |\n",
            "|0.0  |0.27950085873310604 |\n",
            "|0.0  |0.13239584229927304 |\n",
            "|0.0  |0.19181734488101432 |\n",
            "|0.0  |0.9999951271358212  |\n",
            "|0.0  |0.13360660275850655 |\n",
            "|0.0  |0.3212769924474843  |\n",
            "|0.0  |0.08789117880657793 |\n",
            "|1.0  |0.25145720526895743 |\n",
            "|1.0  |0.6392383888307058  |\n",
            "|0.0  |0.42080645612096035 |\n",
            "|1.0  |0.2851825969453866  |\n",
            "|0.0  |0.33152477538548986 |\n",
            "|0.0  |0.3656086352365018  |\n",
            "|0.0  |0.43029922071048565 |\n",
            "|0.0  |0.7379949578941065  |\n",
            "|0.0  |0.3566058593163409  |\n",
            "|0.0  |0.3735895097262033  |\n",
            "|1.0  |0.4115077524356827  |\n",
            "|1.0  |0.8443452302226413  |\n",
            "|1.0  |0.4254658363902867  |\n",
            "|0.0  |0.9924273493058535  |\n",
            "|1.0  |0.6071825371819037  |\n",
            "|0.0  |0.4007791367451078  |\n",
            "|0.0  |0.4499895546441126  |\n",
            "|0.0  |0.9170494291669699  |\n",
            "|0.0  |0.056767035809576205|\n",
            "|0.0  |0.7975843052851972  |\n",
            "|1.0  |0.9673370680548135  |\n",
            "|0.0  |0.11279269224197175 |\n",
            "|0.0  |0.269681569121362   |\n",
            "|0.0  |0.12144060391153333 |\n",
            "|1.0  |0.8941901828725803  |\n",
            "|0.0  |0.13402136448260382 |\n",
            "|0.0  |0.40751796055067535 |\n",
            "|0.0  |0.15093820926320767 |\n",
            "|0.0  |0.6514169632383457  |\n",
            "|0.0  |0.14329266789224804 |\n",
            "|0.0  |0.14154617938353464 |\n",
            "|0.0  |0.21026108173961622 |\n",
            "|0.0  |0.7026773610748175  |\n",
            "|0.0  |0.24415213359983823 |\n",
            "|0.0  |0.10104895895435739 |\n",
            "|0.0  |0.3478234829992528  |\n",
            "|0.0  |0.5974148223872686  |\n",
            "|1.0  |0.5307935569216768  |\n",
            "|0.0  |0.23236136844267885 |\n",
            "|1.0  |0.30286142384366577 |\n",
            "|0.0  |0.12276285700395262 |\n",
            "|0.0  |0.9785072406180219  |\n",
            "|0.0  |0.19224560087045572 |\n",
            "|0.0  |0.7850343901966657  |\n",
            "|0.0  |0.3296397025141061  |\n",
            "|0.0  |0.21628504428873163 |\n",
            "|0.0  |0.20755795735853189 |\n",
            "|0.0  |0.39686621391494714 |\n",
            "|0.0  |0.1978601267035034  |\n",
            "|0.0  |0.2888234457751787  |\n",
            "|0.0  |0.9909883796651009  |\n",
            "|0.0  |0.05706833663283595 |\n",
            "|0.0  |0.9999999999919195  |\n",
            "|0.0  |0.3480328279842767  |\n",
            "|0.0  |0.37794857161402196 |\n",
            "|0.0  |0.20255357607599667 |\n",
            "|0.0  |0.11142488277566076 |\n",
            "|1.0  |0.6243879580836402  |\n",
            "|0.0  |0.29417516993574    |\n",
            "|0.0  |0.9415107608304695  |\n",
            "|1.0  |0.5772716397370203  |\n",
            "|0.0  |0.2419385821456964  |\n",
            "|1.0  |0.9824416174319759  |\n",
            "|0.0  |0.5659569079962485  |\n",
            "|0.0  |0.16448861683785765 |\n",
            "|0.0  |0.1420332664698598  |\n",
            "|1.0  |0.6631826902112989  |\n",
            "|0.0  |0.40912554624135744 |\n",
            "|0.0  |0.5808167192765163  |\n",
            "|0.0  |0.15411953243221965 |\n",
            "|1.0  |0.6087992640430653  |\n",
            "|0.0  |0.34116649629922224 |\n",
            "|1.0  |0.9063049680756523  |\n",
            "|1.0  |0.9996865684132724  |\n",
            "|0.0  |0.21444816216640672 |\n",
            "|0.0  |0.9563276920262609  |\n",
            "|0.0  |0.4185278540729964  |\n",
            "|1.0  |0.6771924550764503  |\n",
            "|1.0  |0.9745699155381848  |\n",
            "|0.0  |0.11257938701625447 |\n",
            "|0.0  |0.08822789659427177 |\n",
            "|0.0  |0.39993061435531574 |\n",
            "|0.0  |0.550776020558314   |\n",
            "|0.0  |0.3271433954045615  |\n",
            "|0.0  |0.13940943471667355 |\n",
            "|0.0  |0.7636956810836437  |\n",
            "|0.0  |0.42467738531529897 |\n",
            "|0.0  |0.30747884685208904 |\n",
            "|0.0  |0.4339596386098179  |\n",
            "|0.0  |0.5573136783661083  |\n",
            "|1.0  |0.9285468284743713  |\n",
            "|1.0  |0.1712501200570713  |\n",
            "|0.0  |0.23798214076411983 |\n",
            "|0.0  |0.8282781030719131  |\n",
            "|1.0  |0.49193044425029175 |\n",
            "|0.0  |0.19655178167845588 |\n",
            "|0.0  |0.3511233826409872  |\n",
            "|0.0  |0.5142741915362197  |\n",
            "|0.0  |0.2456028346220912  |\n",
            "|0.0  |0.4445000535396215  |\n",
            "|0.0  |0.2700376373632054  |\n",
            "|1.0  |0.9984364375999357  |\n",
            "|0.0  |0.09264060584515366 |\n",
            "|0.0  |0.4488549150709783  |\n",
            "|0.0  |0.22297061900141368 |\n",
            "|1.0  |0.9236083413032489  |\n",
            "|0.0  |0.10154628568674295 |\n",
            "|1.0  |0.5333971188440629  |\n",
            "|0.0  |0.25415338316240477 |\n",
            "|0.0  |0.5432599982293737  |\n",
            "|0.0  |0.14928375469497213 |\n",
            "|0.0  |0.13098754189110384 |\n",
            "|0.0  |0.29911937625514007 |\n",
            "|1.0  |0.950146501763074   |\n",
            "|0.0  |0.13625684272141747 |\n",
            "|0.0  |0.3982335742969626  |\n",
            "|0.0  |0.9268110853252954  |\n",
            "|0.0  |0.5800496904929924  |\n",
            "|0.0  |0.6488313877979022  |\n",
            "|0.0  |0.11777843090397422 |\n",
            "|1.0  |0.5950596724867652  |\n",
            "|0.0  |0.22617505942945715 |\n",
            "|0.0  |0.1484875878532309  |\n",
            "|0.0  |0.6267895371348805  |\n",
            "|0.0  |0.052491312265947054|\n",
            "|1.0  |0.9754925453014778  |\n",
            "|0.0  |0.3406285902571162  |\n",
            "|1.0  |0.11436902029718587 |\n",
            "|0.0  |0.13026867906042083 |\n",
            "|0.0  |0.09953727408959867 |\n",
            "|0.0  |0.423792547571594   |\n",
            "|1.0  |0.17747946218667088 |\n",
            "|0.0  |0.3104344565566678  |\n",
            "|0.0  |0.6232141900730548  |\n",
            "|0.0  |0.24982999855875443 |\n",
            "|1.0  |0.5886064293215679  |\n",
            "|0.0  |0.09411264408674258 |\n",
            "|0.0  |0.22791423147230017 |\n",
            "|0.0  |0.22417803800414793 |\n",
            "|0.0  |0.1836048090196546  |\n",
            "|1.0  |0.9047131252350249  |\n",
            "|0.0  |0.218765251264197   |\n",
            "|0.0  |0.8818476012757188  |\n",
            "|0.0  |0.35130294098506976 |\n",
            "|0.0  |0.7913734833956165  |\n",
            "|1.0  |0.9607406263669881  |\n",
            "|0.0  |0.5209624366003391  |\n",
            "|0.0  |0.10042450209786402 |\n",
            "|0.0  |0.14372821852034967 |\n",
            "|1.0  |0.8731309923383492  |\n",
            "|0.0  |0.22556808068160394 |\n",
            "|0.0  |0.257502841872988   |\n",
            "|0.0  |0.28545653585603736 |\n",
            "|0.0  |0.4589671906802525  |\n",
            "|0.0  |0.1452542146046223  |\n",
            "|0.0  |0.9965617531045268  |\n",
            "|0.0  |0.2925969031142912  |\n",
            "|0.0  |0.1814613323073293  |\n",
            "|1.0  |0.9907114100447308  |\n",
            "|0.0  |0.31695950160272546 |\n",
            "|0.0  |0.2791236562692613  |\n",
            "|0.0  |0.8410797888737485  |\n",
            "|0.0  |0.2894021110635243  |\n",
            "|0.0  |0.36427952783974615 |\n",
            "|0.0  |0.6001920473961966  |\n",
            "|0.0  |0.19325809929250526 |\n",
            "|1.0  |0.9734507775756396  |\n",
            "|0.0  |0.25034113253943113 |\n",
            "|1.0  |0.9557595362197684  |\n",
            "|1.0  |0.22428267176847805 |\n",
            "|0.0  |0.722608801624819   |\n",
            "|0.0  |0.21401707773222145 |\n",
            "|0.0  |0.04696049278237546 |\n",
            "|0.0  |0.40593745602471043 |\n",
            "|0.0  |0.820121589809705   |\n",
            "|0.0  |0.2795922081486575  |\n",
            "+-----+--------------------+\n",
            "\n",
            "+-----+--------------------+\n",
            "|label|rawPrediction       |\n",
            "+-----+--------------------+\n",
            "|0.0  |0.8921432874988979  |\n",
            "|0.0  |0.3612920705314888  |\n",
            "|0.0  |0.08979530841536687 |\n",
            "|0.0  |0.056782803385060254|\n",
            "|0.0  |0.412662178390394   |\n",
            "|0.0  |0.09482459311024782 |\n",
            "|0.0  |0.3119557463860063  |\n",
            "|1.0  |0.4720329226216117  |\n",
            "|0.0  |0.37914267018035297 |\n",
            "|0.0  |0.592465433390437   |\n",
            "|1.0  |0.6983196203399575  |\n",
            "|0.0  |0.2191164773723311  |\n",
            "|0.0  |0.9853041343046071  |\n",
            "|1.0  |0.25541459768035746 |\n",
            "|0.0  |0.1801120932783521  |\n",
            "|0.0  |0.08647182687067223 |\n",
            "|0.0  |0.3114202745835132  |\n",
            "|0.0  |0.037682857815271364|\n",
            "|0.0  |0.11689798970770215 |\n",
            "|0.0  |0.4223445870134137  |\n",
            "|0.0  |0.475298844453219   |\n",
            "|0.0  |0.2529643195341682  |\n",
            "|0.0  |0.16279519069805004 |\n",
            "|0.0  |0.18268231148216096 |\n",
            "|0.0  |0.9999561832291491  |\n",
            "|0.0  |0.1938829975827473  |\n",
            "|0.0  |0.42020015036851843 |\n",
            "|0.0  |0.9045027198966328  |\n",
            "|0.0  |0.19306400685571012 |\n",
            "|0.0  |0.14792433176751774 |\n",
            "|0.0  |0.07902662803158533 |\n",
            "|0.0  |0.9479339167081579  |\n",
            "|0.0  |0.22996621597159594 |\n",
            "|0.0  |0.9991074739663964  |\n",
            "|0.0  |0.22039846023995924 |\n",
            "|0.0  |0.3502435887580474  |\n",
            "|0.0  |0.25913189346922305 |\n",
            "|0.0  |0.13704614836687545 |\n",
            "|0.0  |0.990839819003091   |\n",
            "|1.0  |0.7769294141298271  |\n",
            "|0.0  |0.9534100572062748  |\n",
            "|0.0  |0.24653193092783054 |\n",
            "|0.0  |0.33042224852196433 |\n",
            "|0.0  |0.2516911722590366  |\n",
            "|1.0  |0.9999975581715221  |\n",
            "|0.0  |0.37565234540292725 |\n",
            "|0.0  |0.08505618414762806 |\n",
            "|1.0  |0.9999880192375189  |\n",
            "|1.0  |0.7191977560544125  |\n",
            "|0.0  |0.1220959725388494  |\n",
            "|0.0  |0.48677843864607506 |\n",
            "|0.0  |0.15701441204788025 |\n",
            "|1.0  |0.26821400130418893 |\n",
            "|0.0  |0.5237953696417591  |\n",
            "|1.0  |0.8410414061588747  |\n",
            "|0.0  |0.7421565979099323  |\n",
            "|1.0  |0.2634541761622494  |\n",
            "|0.0  |0.4958981888785834  |\n",
            "|0.0  |0.3053274068163727  |\n",
            "|0.0  |0.16523409524234167 |\n",
            "|0.0  |0.312411060507956   |\n",
            "|1.0  |0.4225846161287874  |\n",
            "|0.0  |0.865809731170466   |\n",
            "|0.0  |0.24173698695202062 |\n",
            "|0.0  |0.16536984749238892 |\n",
            "|0.0  |0.40117517923242074 |\n",
            "|0.0  |0.8738030075177741  |\n",
            "|0.0  |0.33632053695139996 |\n",
            "|0.0  |0.14022009122961654 |\n",
            "|0.0  |0.1218944046598276  |\n",
            "|0.0  |0.5233846354351769  |\n",
            "|1.0  |0.9204742520211836  |\n",
            "|0.0  |0.648328828637721   |\n",
            "|0.0  |0.9035372928395646  |\n",
            "|0.0  |0.235368525329551   |\n",
            "|0.0  |0.589212961481061   |\n",
            "|0.0  |0.13215549674412097 |\n",
            "|0.0  |0.12729141948916467 |\n",
            "|0.0  |0.044670111648168476|\n",
            "|0.0  |0.14791794734941643 |\n",
            "|0.0  |0.16947010530714435 |\n",
            "|0.0  |0.17009957818593846 |\n",
            "|0.0  |0.9564137366851847  |\n",
            "|1.0  |0.22868645743641136 |\n",
            "|0.0  |0.17959951517497097 |\n",
            "|0.0  |0.23269689518251757 |\n",
            "|0.0  |0.1837154845234943  |\n",
            "|1.0  |0.9107728135294719  |\n",
            "|0.0  |0.3362338346449665  |\n",
            "|0.0  |0.9685423360235986  |\n",
            "|0.0  |0.1484796421617547  |\n",
            "|0.0  |0.7602737527377478  |\n",
            "|0.0  |0.430567047677174   |\n",
            "|0.0  |0.5513419504679329  |\n",
            "|0.0  |0.20051209753041033 |\n",
            "|0.0  |0.27950085873310604 |\n",
            "|0.0  |0.13239584229927304 |\n",
            "|0.0  |0.19181734488101432 |\n",
            "|0.0  |0.9999951271358212  |\n",
            "|0.0  |0.13360660275850655 |\n",
            "|0.0  |0.3212769924474843  |\n",
            "|0.0  |0.08789117880657793 |\n",
            "|1.0  |0.25145720526895743 |\n",
            "|1.0  |0.6392383888307058  |\n",
            "|0.0  |0.42080645612096035 |\n",
            "|1.0  |0.2851825969453866  |\n",
            "|0.0  |0.33152477538548986 |\n",
            "|0.0  |0.3656086352365018  |\n",
            "|0.0  |0.43029922071048565 |\n",
            "|0.0  |0.7379949578941065  |\n",
            "|0.0  |0.3566058593163409  |\n",
            "|0.0  |0.3735895097262033  |\n",
            "|1.0  |0.4115077524356827  |\n",
            "|1.0  |0.8443452302226413  |\n",
            "|1.0  |0.4254658363902867  |\n",
            "|0.0  |0.9924273493058535  |\n",
            "|1.0  |0.6071825371819037  |\n",
            "|0.0  |0.4007791367451078  |\n",
            "|0.0  |0.4499895546441126  |\n",
            "|0.0  |0.9170494291669699  |\n",
            "|0.0  |0.056767035809576205|\n",
            "|0.0  |0.7975843052851972  |\n",
            "|1.0  |0.9673370680548135  |\n",
            "|0.0  |0.11279269224197175 |\n",
            "|0.0  |0.269681569121362   |\n",
            "|0.0  |0.12144060391153333 |\n",
            "|1.0  |0.8941901828725803  |\n",
            "|0.0  |0.13402136448260382 |\n",
            "|0.0  |0.40751796055067535 |\n",
            "|0.0  |0.15093820926320767 |\n",
            "|0.0  |0.6514169632383457  |\n",
            "|0.0  |0.14329266789224804 |\n",
            "|0.0  |0.14154617938353464 |\n",
            "|0.0  |0.21026108173961622 |\n",
            "|0.0  |0.7026773610748175  |\n",
            "|0.0  |0.24415213359983823 |\n",
            "|0.0  |0.10104895895435739 |\n",
            "|0.0  |0.3478234829992528  |\n",
            "|0.0  |0.5974148223872686  |\n",
            "|1.0  |0.5307935569216768  |\n",
            "|0.0  |0.23236136844267885 |\n",
            "|1.0  |0.30286142384366577 |\n",
            "|0.0  |0.12276285700395262 |\n",
            "|0.0  |0.9785072406180219  |\n",
            "|0.0  |0.19224560087045572 |\n",
            "|0.0  |0.7850343901966657  |\n",
            "|0.0  |0.3296397025141061  |\n",
            "|0.0  |0.21628504428873163 |\n",
            "|0.0  |0.20755795735853189 |\n",
            "|0.0  |0.39686621391494714 |\n",
            "|0.0  |0.1978601267035034  |\n",
            "|0.0  |0.2888234457751787  |\n",
            "|0.0  |0.9909883796651009  |\n",
            "|0.0  |0.05706833663283595 |\n",
            "|0.0  |0.9999999999919195  |\n",
            "|0.0  |0.3480328279842767  |\n",
            "|0.0  |0.37794857161402196 |\n",
            "|0.0  |0.20255357607599667 |\n",
            "|0.0  |0.11142488277566076 |\n",
            "|1.0  |0.6243879580836402  |\n",
            "|0.0  |0.29417516993574    |\n",
            "|0.0  |0.9415107608304695  |\n",
            "|1.0  |0.5772716397370203  |\n",
            "|0.0  |0.2419385821456964  |\n",
            "|1.0  |0.9824416174319759  |\n",
            "|0.0  |0.5659569079962485  |\n",
            "|0.0  |0.16448861683785765 |\n",
            "|0.0  |0.1420332664698598  |\n",
            "|1.0  |0.6631826902112989  |\n",
            "|0.0  |0.40912554624135744 |\n",
            "|0.0  |0.5808167192765163  |\n",
            "|0.0  |0.15411953243221965 |\n",
            "|1.0  |0.6087992640430653  |\n",
            "|0.0  |0.34116649629922224 |\n",
            "|1.0  |0.9063049680756523  |\n",
            "|1.0  |0.9996865684132724  |\n",
            "|0.0  |0.21444816216640672 |\n",
            "|0.0  |0.9563276920262609  |\n",
            "|0.0  |0.4185278540729964  |\n",
            "|1.0  |0.6771924550764503  |\n",
            "|1.0  |0.9745699155381848  |\n",
            "|0.0  |0.11257938701625447 |\n",
            "|0.0  |0.08822789659427177 |\n",
            "|0.0  |0.39993061435531574 |\n",
            "|0.0  |0.550776020558314   |\n",
            "|0.0  |0.3271433954045615  |\n",
            "|0.0  |0.13940943471667355 |\n",
            "|0.0  |0.7636956810836437  |\n",
            "|0.0  |0.42467738531529897 |\n",
            "|0.0  |0.30747884685208904 |\n",
            "|0.0  |0.4339596386098179  |\n",
            "|0.0  |0.5573136783661083  |\n",
            "|1.0  |0.9285468284743713  |\n",
            "|1.0  |0.1712501200570713  |\n",
            "|0.0  |0.23798214076411983 |\n",
            "|0.0  |0.8282781030719131  |\n",
            "|1.0  |0.49193044425029175 |\n",
            "|0.0  |0.19655178167845588 |\n",
            "|0.0  |0.3511233826409872  |\n",
            "|0.0  |0.5142741915362197  |\n",
            "|0.0  |0.2456028346220912  |\n",
            "|0.0  |0.4445000535396215  |\n",
            "|0.0  |0.2700376373632054  |\n",
            "|1.0  |0.9984364375999357  |\n",
            "|0.0  |0.09264060584515366 |\n",
            "|0.0  |0.4488549150709783  |\n",
            "|0.0  |0.22297061900141368 |\n",
            "|1.0  |0.9236083413032489  |\n",
            "|0.0  |0.10154628568674295 |\n",
            "|1.0  |0.5333971188440629  |\n",
            "|0.0  |0.25415338316240477 |\n",
            "|0.0  |0.5432599982293737  |\n",
            "|0.0  |0.14928375469497213 |\n",
            "|0.0  |0.13098754189110384 |\n",
            "|0.0  |0.29911937625514007 |\n",
            "|1.0  |0.950146501763074   |\n",
            "|0.0  |0.13625684272141747 |\n",
            "|0.0  |0.3982335742969626  |\n",
            "|0.0  |0.9268110853252954  |\n",
            "|0.0  |0.5800496904929924  |\n",
            "|0.0  |0.6488313877979022  |\n",
            "|0.0  |0.11777843090397422 |\n",
            "|1.0  |0.5950596724867652  |\n",
            "|0.0  |0.22617505942945715 |\n",
            "|0.0  |0.1484875878532309  |\n",
            "|0.0  |0.6267895371348805  |\n",
            "|0.0  |0.052491312265947054|\n",
            "|1.0  |0.9754925453014778  |\n",
            "|0.0  |0.3406285902571162  |\n",
            "|1.0  |0.11436902029718587 |\n",
            "|0.0  |0.13026867906042083 |\n",
            "|0.0  |0.09953727408959867 |\n",
            "|0.0  |0.423792547571594   |\n",
            "|1.0  |0.17747946218667088 |\n",
            "|0.0  |0.3104344565566678  |\n",
            "|0.0  |0.6232141900730548  |\n",
            "|0.0  |0.24982999855875443 |\n",
            "|1.0  |0.5886064293215679  |\n",
            "|0.0  |0.09411264408674258 |\n",
            "|0.0  |0.22791423147230017 |\n",
            "|0.0  |0.22417803800414793 |\n",
            "|0.0  |0.1836048090196546  |\n",
            "|1.0  |0.9047131252350249  |\n",
            "|0.0  |0.218765251264197   |\n",
            "|0.0  |0.8818476012757188  |\n",
            "|0.0  |0.35130294098506976 |\n",
            "|0.0  |0.7913734833956165  |\n",
            "|1.0  |0.9607406263669881  |\n",
            "|0.0  |0.5209624366003391  |\n",
            "|0.0  |0.10042450209786402 |\n",
            "|0.0  |0.14372821852034967 |\n",
            "|1.0  |0.8731309923383492  |\n",
            "|0.0  |0.22556808068160394 |\n",
            "|0.0  |0.257502841872988   |\n",
            "|0.0  |0.28545653585603736 |\n",
            "|0.0  |0.4589671906802525  |\n",
            "|0.0  |0.1452542146046223  |\n",
            "|0.0  |0.9965617531045268  |\n",
            "|0.0  |0.2925969031142912  |\n",
            "|0.0  |0.1814613323073293  |\n",
            "|1.0  |0.9907114100447308  |\n",
            "|0.0  |0.31695950160272546 |\n",
            "|0.0  |0.2791236562692613  |\n",
            "|0.0  |0.8410797888737485  |\n",
            "|0.0  |0.2894021110635243  |\n",
            "|0.0  |0.36427952783974615 |\n",
            "|0.0  |0.6001920473961966  |\n",
            "|0.0  |0.19325809929250526 |\n",
            "|1.0  |0.9734507775756396  |\n",
            "|0.0  |0.25034113253943113 |\n",
            "|1.0  |0.9557595362197684  |\n",
            "|1.0  |0.22428267176847805 |\n",
            "|0.0  |0.722608801624819   |\n",
            "|0.0  |0.21401707773222145 |\n",
            "|0.0  |0.04696049278237546 |\n",
            "|0.0  |0.40593745602471043 |\n",
            "|0.0  |0.820121589809705   |\n",
            "|0.0  |0.2795922081486575  |\n",
            "+-----+--------------------+\n",
            "\n",
            "[False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True False  True False  True\n",
            " False  True False  True False  True False  True]\n",
            "[151104. 101651. 155726. 156471. 127454. 112035. 155880. 192399. 172484.\n",
            " 127888. 135926. 106510. 177536. 171863. 171739. 132967. 118991. 157997.\n",
            " 144371. 120208. 136760. 166252. 122585. 162773. 165271. 153907. 171462.\n",
            " 152632. 165674. 186251. 142691. 112064. 180858. 117413. 107462. 113216.\n",
            " 106963. 102959. 138842. 107901. 191180. 149102. 124321. 163150. 124456.\n",
            " 158767. 127294. 153370. 189563. 175858. 114761. 145893. 162930. 104589.\n",
            " 120675. 136572. 151534. 129279. 131592. 158995. 138828. 155816. 172079.\n",
            " 112083. 139869. 123423. 118210. 126501. 192993. 175797. 100765. 189332.\n",
            " 158943. 100914. 143497. 166898. 189564. 152972. 145681. 193827. 109424.\n",
            " 126219. 101257. 140738. 147469. 182758. 160598. 104564. 176986. 123437.\n",
            " 117029. 132278. 144429. 175734. 181742. 153063. 184650. 171130. 198630.\n",
            " 160561. 140287. 148278. 113595. 147143. 168862. 145012. 125124. 160336.\n",
            " 198184. 122988. 137321. 144187. 174823. 106374. 130275. 175096. 198044.\n",
            " 144794. 114690. 163541. 143525. 144659. 162649. 103169. 195197. 102376.\n",
            " 183391. 116367. 181880. 169284. 135044. 175644. 130698. 121527. 173921.\n",
            " 187545. 105566. 183762. 130389. 101216. 186505. 110341. 108877. 127184.\n",
            " 187809. 167106. 100361. 160367. 188483. 112807. 173377. 190705. 171977.\n",
            " 147433. 114129. 163913. 161237. 156641. 172335. 151967. 192230. 107085.\n",
            " 108294. 147237. 171119. 191813. 128601. 123730. 178444. 144319. 112600.\n",
            " 102365. 158966. 168828. 110348. 176760. 123362. 119825. 184338. 140167.\n",
            " 178065. 162623. 115691. 123124. 189720. 143273. 178493. 131345. 158591.\n",
            " 122619. 122900. 133906. 118470. 100009. 155256. 166934. 152696. 185150.\n",
            " 127285. 124531. 193803. 146623. 105610. 156708. 190934. 106038. 143224.\n",
            " 188973. 191151. 135773. 148585. 175774. 111515. 170157. 132744. 105464.\n",
            " 126804. 199603. 117262. 116360. 181404. 114939. 105407. 170892. 115480.\n",
            " 134342. 183959. 186086. 188320. 129080. 168039. 148207. 187008. 184857.\n",
            " 174517. 115157. 167836. 194111. 104994. 184485. 158018. 177162. 170247.\n",
            " 198888. 148689. 161696. 146035. 157554. 167697. 153844. 100795. 175206.\n",
            " 135614. 171990. 183768. 146062. 117750. 153264. 199574. 171650. 130108.\n",
            " 139343. 104140. 169579. 103002. 102220. 186721. 190711. 135302. 165660.\n",
            " 162370. 190600. 147243. 157999. 133334. 184124. 172563. 136809. 161958.\n",
            " 102500. 187638. 115247. 142053. 180216. 193147. 161950. 191719. 174677.\n",
            " 106870. 185074. 130760. 164632. 169363. 196271. 121028. 134531. 114849.\n",
            " 106780. 149601. 154196. 195261. 123860. 177843. 138484. 170188. 126793.\n",
            " 195813. 128158. 118529. 112721.]\n",
            "VAL_ROUND_1_TARGET IDS:[151104.0, 101651.0, 155726.0, 156471.0, 127454.0, 112035.0, 155880.0, 192399.0, 172484.0, 127888.0, 135926.0, 106510.0, 177536.0, 171863.0, 171739.0, 132967.0, 118991.0, 157997.0, 144371.0, 120208.0, 136760.0, 166252.0, 122585.0, 162773.0, 165271.0, 153907.0, 171462.0, 152632.0, 165674.0, 186251.0, 142691.0, 112064.0, 180858.0, 117413.0, 107462.0, 113216.0, 106963.0, 102959.0, 138842.0, 107901.0, 191180.0, 149102.0, 124321.0, 163150.0, 124456.0, 158767.0, 127294.0, 153370.0, 189563.0, 175858.0, 114761.0, 145893.0, 162930.0, 104589.0, 120675.0, 136572.0, 151534.0, 129279.0, 131592.0, 158995.0, 138828.0, 155816.0, 172079.0, 112083.0, 139869.0, 123423.0, 118210.0, 126501.0, 192993.0, 175797.0, 100765.0, 189332.0, 158943.0, 100914.0, 143497.0, 166898.0, 189564.0, 152972.0, 145681.0, 193827.0, 109424.0, 126219.0, 101257.0, 140738.0, 147469.0, 182758.0, 160598.0, 104564.0, 176986.0, 123437.0, 117029.0, 132278.0, 144429.0, 175734.0, 181742.0, 153063.0, 184650.0, 171130.0, 198630.0, 160561.0, 140287.0, 148278.0, 113595.0, 147143.0, 168862.0, 145012.0, 125124.0, 160336.0, 198184.0, 122988.0, 137321.0, 144187.0, 174823.0, 106374.0, 130275.0, 175096.0, 198044.0, 144794.0, 114690.0, 163541.0, 143525.0, 144659.0, 162649.0, 103169.0, 195197.0, 102376.0, 183391.0, 116367.0, 181880.0, 169284.0, 135044.0, 175644.0, 130698.0, 121527.0, 173921.0, 187545.0, 105566.0, 183762.0, 130389.0, 101216.0, 186505.0, 110341.0, 108877.0, 127184.0, 187809.0, 167106.0, 100361.0, 160367.0, 188483.0, 112807.0, 173377.0, 190705.0, 171977.0, 147433.0, 114129.0, 163913.0, 161237.0, 156641.0, 172335.0, 151967.0, 192230.0, 107085.0, 108294.0, 147237.0, 171119.0, 191813.0, 128601.0, 123730.0, 178444.0, 144319.0, 112600.0, 102365.0, 158966.0, 168828.0, 110348.0, 176760.0, 123362.0, 119825.0, 184338.0, 140167.0, 178065.0, 162623.0, 115691.0, 123124.0, 189720.0, 143273.0, 178493.0, 131345.0, 158591.0, 122619.0, 122900.0, 133906.0, 118470.0, 100009.0, 155256.0, 166934.0, 152696.0, 185150.0, 127285.0, 124531.0, 193803.0, 146623.0, 105610.0, 156708.0, 190934.0, 106038.0, 143224.0, 188973.0, 191151.0, 135773.0, 148585.0, 175774.0, 111515.0, 170157.0, 132744.0, 105464.0, 126804.0, 199603.0, 117262.0, 116360.0, 181404.0, 114939.0, 105407.0, 170892.0, 115480.0, 134342.0, 183959.0, 186086.0, 188320.0, 129080.0, 168039.0, 148207.0, 187008.0, 184857.0, 174517.0, 115157.0, 167836.0, 194111.0, 104994.0, 184485.0, 158018.0, 177162.0, 170247.0, 198888.0, 148689.0, 161696.0, 146035.0, 157554.0, 167697.0, 153844.0, 100795.0, 175206.0, 135614.0, 171990.0, 183768.0, 146062.0, 117750.0, 153264.0, 199574.0, 171650.0, 130108.0, 139343.0, 104140.0, 169579.0, 103002.0, 102220.0, 186721.0, 190711.0, 135302.0, 165660.0, 162370.0, 190600.0, 147243.0, 157999.0, 133334.0, 184124.0, 172563.0, 136809.0, 161958.0, 102500.0, 187638.0, 115247.0, 142053.0, 180216.0, 193147.0, 161950.0, 191719.0, 174677.0, 106870.0, 185074.0, 130760.0, 164632.0, 169363.0, 196271.0, 121028.0, 134531.0, 114849.0, 106780.0, 149601.0, 154196.0, 195261.0, 123860.0, 177843.0, 138484.0, 170188.0, 126793.0, 195813.0, 128158.0, 118529.0, 112721.0]\n",
            "+-----+--------+\n",
            "|label|count(1)|\n",
            "+-----+--------+\n",
            "|  0.0|     890|\n",
            "|  1.0|     244|\n",
            "+-----+--------+\n",
            "\n",
            "+-----+-------------------+\n",
            "|label|rawPrediction      |\n",
            "+-----+-------------------+\n",
            "|0.0  |0.2537388672042824 |\n",
            "|0.0  |0.30190710175778157|\n",
            "|0.0  |0.9994339350915736 |\n",
            "|0.0  |0.7400558425441308 |\n",
            "|0.0  |0.5885238245271296 |\n",
            "|1.0  |0.9131696805171126 |\n",
            "|1.0  |0.9999998569546372 |\n",
            "|0.0  |0.3482204528558063 |\n",
            "|1.0  |0.7191101029012559 |\n",
            "|0.0  |0.15929691842359162|\n",
            "|0.0  |0.25787658453477436|\n",
            "|1.0  |0.27137268703722905|\n",
            "|0.0  |0.3551493213446848 |\n",
            "|1.0  |0.1642560615623061 |\n",
            "|0.0  |0.8555894160238454 |\n",
            "|0.0  |0.7762407369545241 |\n",
            "|0.0  |0.3284134530104411 |\n",
            "|0.0  |0.10004376629231215|\n",
            "|0.0  |0.10235737127685085|\n",
            "|0.0  |0.9199201930889233 |\n",
            "|0.0  |0.5466184715604889 |\n",
            "|0.0  |0.4081195473707524 |\n",
            "|0.0  |0.04424215029112766|\n",
            "|1.0  |0.999843366298792  |\n",
            "|0.0  |0.5653575436563162 |\n",
            "|0.0  |0.13479635766231635|\n",
            "|0.0  |0.15769381251641934|\n",
            "|0.0  |0.9999376787337007 |\n",
            "|1.0  |0.41236911216892524|\n",
            "|0.0  |0.09722468554740082|\n",
            "|1.0  |0.26342761427332695|\n",
            "|0.0  |0.3734869874095923 |\n",
            "|0.0  |0.8793051486060987 |\n",
            "|0.0  |0.16913218759881465|\n",
            "|0.0  |0.759649078298935  |\n",
            "|1.0  |0.5856119992840916 |\n",
            "|1.0  |0.9999999991376397 |\n",
            "|0.0  |0.9907124269788492 |\n",
            "|0.0  |0.12565971339145232|\n",
            "|0.0  |0.1699189637032572 |\n",
            "|0.0  |0.14279163435349107|\n",
            "|0.0  |0.15046496510588414|\n",
            "|0.0  |0.6003385276554115 |\n",
            "|0.0  |0.14700232813138425|\n",
            "|0.0  |0.2124819028721262 |\n",
            "|0.0  |0.5697819063159766 |\n",
            "|0.0  |0.8490826148279161 |\n",
            "|0.0  |0.21876048003566462|\n",
            "|1.0  |0.9997221793647625 |\n",
            "|1.0  |0.9652259330933711 |\n",
            "|0.0  |0.10960977724927423|\n",
            "|1.0  |0.9919349324908092 |\n",
            "|0.0  |0.5550017280196708 |\n",
            "|0.0  |0.25361326012944496|\n",
            "|0.0  |0.7279639627580545 |\n",
            "|0.0  |0.9297875063449249 |\n",
            "|1.0  |0.7652900071487055 |\n",
            "|0.0  |0.9624026877646734 |\n",
            "|0.0  |0.2454423859388969 |\n",
            "|0.0  |0.21408570421472495|\n",
            "|0.0  |0.0923858333897819 |\n",
            "|0.0  |0.8441966518804414 |\n",
            "|0.0  |0.42401817018396093|\n",
            "|1.0  |0.9987229460239418 |\n",
            "|0.0  |0.45664984423158905|\n",
            "|0.0  |0.2820482882838242 |\n",
            "|0.0  |0.17131384490390167|\n",
            "|0.0  |0.2664809376349513 |\n",
            "|1.0  |0.999897855610513  |\n",
            "|0.0  |0.24418373325599851|\n",
            "|0.0  |0.3508623437349836 |\n",
            "|0.0  |0.15865890169670815|\n",
            "|0.0  |0.11872544074997382|\n",
            "|0.0  |0.11380052680167174|\n",
            "|0.0  |0.42688768784897846|\n",
            "|0.0  |0.1879949601043167 |\n",
            "|0.0  |0.7807121803033117 |\n",
            "|0.0  |0.1291839309259426 |\n",
            "|0.0  |0.9918500985371453 |\n",
            "|0.0  |0.47713349750801026|\n",
            "|0.0  |0.12044239227495879|\n",
            "|0.0  |0.14426582204577776|\n",
            "|0.0  |0.21094339731271106|\n",
            "|0.0  |0.9929959406678627 |\n",
            "|0.0  |0.19536175365804553|\n",
            "|0.0  |0.08744156847522344|\n",
            "|0.0  |0.9214887850359963 |\n",
            "|0.0  |0.19476238476441154|\n",
            "|0.0  |0.8318520702606551 |\n",
            "|0.0  |0.7811223650647989 |\n",
            "|1.0  |0.3180975004515392 |\n",
            "|1.0  |0.9983998107742441 |\n",
            "|0.0  |0.6305716485313774 |\n",
            "|0.0  |0.23558013773149256|\n",
            "|0.0  |0.766555153389261  |\n",
            "|1.0  |0.18245913043888917|\n",
            "|0.0  |0.12357204748282358|\n",
            "|1.0  |0.4576280281560686 |\n",
            "|0.0  |0.1683941775570481 |\n",
            "|0.0  |0.8756973015579085 |\n",
            "|0.0  |0.9995339875213773 |\n",
            "|0.0  |0.2676947788188099 |\n",
            "|0.0  |0.1864329443430507 |\n",
            "|1.0  |0.6873893085090953 |\n",
            "|0.0  |0.9999786528248324 |\n",
            "|0.0  |0.5939489838538636 |\n",
            "|0.0  |0.6267192247421285 |\n",
            "|1.0  |0.4610734995257194 |\n",
            "|0.0  |0.12222440381459099|\n",
            "|0.0  |0.9520650349982823 |\n",
            "|1.0  |0.6249783805043665 |\n",
            "|0.0  |0.9434576974461325 |\n",
            "|0.0  |0.7501782624303786 |\n",
            "|0.0  |0.15132379094716386|\n",
            "|0.0  |0.28923318749672877|\n",
            "|0.0  |0.20189801463378432|\n",
            "|0.0  |0.6705220230907271 |\n",
            "|0.0  |0.43178233035603986|\n",
            "|0.0  |0.11369412430430115|\n",
            "|0.0  |0.2751117323411405 |\n",
            "|0.0  |0.7418681363202493 |\n",
            "|0.0  |0.17990677745977124|\n",
            "|1.0  |0.9999835895158509 |\n",
            "|0.0  |0.1366093653390621 |\n",
            "|0.0  |0.06828980853633004|\n",
            "|0.0  |0.18969617246134862|\n",
            "|0.0  |0.9995309319248943 |\n",
            "|0.0  |0.26953535418383745|\n",
            "|0.0  |0.15288092564045508|\n",
            "|1.0  |0.5481684188447077 |\n",
            "|1.0  |0.5840709848613374 |\n",
            "|0.0  |0.9620878577511685 |\n",
            "|0.0  |0.30966436444685896|\n",
            "|0.0  |0.16435897655390452|\n",
            "|0.0  |0.5169441363545112 |\n",
            "|0.0  |0.12874957412572052|\n",
            "|0.0  |0.11651380399853639|\n",
            "|0.0  |0.5064002035880535 |\n",
            "|0.0  |0.2837028425544703 |\n",
            "|0.0  |0.2932739075175833 |\n",
            "|0.0  |0.07917268907216002|\n",
            "|0.0  |0.17012518915648234|\n",
            "|0.0  |0.996117264983622  |\n",
            "|0.0  |0.7187219868315179 |\n",
            "|0.0  |0.09275444825992218|\n",
            "|0.0  |0.8531213404731286 |\n",
            "|1.0  |0.9546033072952524 |\n",
            "|0.0  |0.21686667784154223|\n",
            "|1.0  |0.8408946002339139 |\n",
            "|0.0  |0.19255975107174517|\n",
            "|0.0  |0.9418630792562314 |\n",
            "|0.0  |0.05009553644895548|\n",
            "|0.0  |0.1632647449599588 |\n",
            "|0.0  |0.2938684403394235 |\n",
            "|1.0  |0.20068297933288348|\n",
            "|0.0  |0.1885798567891821 |\n",
            "|0.0  |0.1091862731932679 |\n",
            "|0.0  |0.8948304112735578 |\n",
            "|0.0  |0.5468194476706407 |\n",
            "|1.0  |0.8348473233117408 |\n",
            "|0.0  |0.20220632526484028|\n",
            "|0.0  |0.2946783079692331 |\n",
            "|0.0  |0.584366490450255  |\n",
            "|1.0  |0.10519678928994236|\n",
            "|1.0  |0.1538264445004014 |\n",
            "|1.0  |0.9818862129729685 |\n",
            "|0.0  |0.1886672007196616 |\n",
            "|0.0  |0.8441230750868439 |\n",
            "|0.0  |0.6151181136543262 |\n",
            "|0.0  |0.32283415981678065|\n",
            "|0.0  |0.9105607129002796 |\n",
            "|0.0  |0.18300931465133385|\n",
            "|1.0  |0.5371921757287369 |\n",
            "|1.0  |0.5991144220491517 |\n",
            "|0.0  |0.10763046240550489|\n",
            "|0.0  |0.2158209709275627 |\n",
            "|0.0  |0.9426435786245936 |\n",
            "|0.0  |0.13813261201968796|\n",
            "|0.0  |0.11751621045406568|\n",
            "|0.0  |0.27101141513427995|\n",
            "|0.0  |0.9403656644539423 |\n",
            "|0.0  |0.19717558738945762|\n",
            "|1.0  |0.9720960972366826 |\n",
            "|0.0  |0.12118222139335244|\n",
            "|1.0  |0.8246961888162071 |\n",
            "|0.0  |0.05012790756447505|\n",
            "|1.0  |0.7084908488978406 |\n",
            "|0.0  |0.16209954917941638|\n",
            "|0.0  |0.16486807176139473|\n",
            "|0.0  |0.3546478131157077 |\n",
            "|1.0  |0.9999999999986935 |\n",
            "|0.0  |0.9408150998625124 |\n",
            "|0.0  |0.24231095831277705|\n",
            "|0.0  |0.2829450428311713 |\n",
            "|0.0  |0.6744784347010461 |\n",
            "|0.0  |0.22811751013690684|\n",
            "|0.0  |0.21361375180291808|\n",
            "|0.0  |0.18862926201999675|\n",
            "|1.0  |0.19357257339754153|\n",
            "|0.0  |0.1265577123776599 |\n",
            "|0.0  |0.125222071837379  |\n",
            "|0.0  |0.9579881374418995 |\n",
            "|0.0  |0.22833243529550007|\n",
            "|0.0  |0.2185626558661311 |\n",
            "|1.0  |0.9838072575522421 |\n",
            "|0.0  |0.15948183378627412|\n",
            "|0.0  |0.7570426849608114 |\n",
            "|0.0  |0.8799612991219332 |\n",
            "|0.0  |0.05448754629263686|\n",
            "|0.0  |0.20310555484521176|\n",
            "|0.0  |0.970088180336526  |\n",
            "|1.0  |0.5282428306395228 |\n",
            "|0.0  |0.40393065432024744|\n",
            "|0.0  |0.2654569551816942 |\n",
            "|0.0  |0.8627266093708396 |\n",
            "|0.0  |0.5777391747343369 |\n",
            "|0.0  |0.1058192825418689 |\n",
            "|1.0  |0.761471089841876  |\n",
            "|0.0  |0.24235177649134632|\n",
            "|0.0  |0.8303235187131706 |\n",
            "|0.0  |0.5634500737861093 |\n",
            "|0.0  |0.25408601031272104|\n",
            "|0.0  |0.29703701656001913|\n",
            "|0.0  |0.19915029802163475|\n",
            "|1.0  |0.9650029371053876 |\n",
            "|0.0  |0.5150889876165967 |\n",
            "|1.0  |0.9950715732514513 |\n",
            "|0.0  |0.11677445238355477|\n",
            "|0.0  |0.2543833412000094 |\n",
            "|1.0  |0.9922553708610135 |\n",
            "|1.0  |0.8631937902465525 |\n",
            "|1.0  |0.8852271563843879 |\n",
            "|0.0  |0.43420426377086985|\n",
            "|0.0  |0.39771194188330894|\n",
            "|0.0  |0.9999775125146086 |\n",
            "|0.0  |0.18557458993676113|\n",
            "|0.0  |0.40620215654951186|\n",
            "|0.0  |0.20528127237316096|\n",
            "|0.0  |0.20528478806021455|\n",
            "|0.0  |0.6420287119123851 |\n",
            "|0.0  |0.13495893766780165|\n",
            "|0.0  |0.11011907794739706|\n",
            "|0.0  |0.11864927807399517|\n",
            "|0.0  |0.8794005264841294 |\n",
            "|0.0  |0.3574400082202269 |\n",
            "|0.0  |0.6361356137235273 |\n",
            "|0.0  |0.8916690741436971 |\n",
            "|0.0  |0.4169840151400396 |\n",
            "|0.0  |0.1909075825865154 |\n",
            "|1.0  |0.683534158766968  |\n",
            "|0.0  |0.15663121982844064|\n",
            "|1.0  |0.32121743320890817|\n",
            "|0.0  |0.3151409220997441 |\n",
            "|0.0  |0.3653557516467798 |\n",
            "|0.0  |0.7625479738384838 |\n",
            "|0.0  |0.2212322418187782 |\n",
            "|0.0  |0.6461111225998291 |\n",
            "|0.0  |0.18615732420608755|\n",
            "|0.0  |0.5879727279635693 |\n",
            "|0.0  |0.23706392527760733|\n",
            "|0.0  |0.9541560719093393 |\n",
            "|0.0  |0.10791805032263957|\n",
            "|0.0  |0.12883353316919965|\n",
            "|0.0  |0.12020334102325247|\n",
            "|0.0  |0.5574224767888939 |\n",
            "|0.0  |0.17134727899021818|\n",
            "|0.0  |0.3113690689297589 |\n",
            "|0.0  |0.1402315282497575 |\n",
            "|0.0  |0.5800528378469676 |\n",
            "|0.0  |0.29878107850642   |\n",
            "|0.0  |0.49232570442722234|\n",
            "|0.0  |0.6369486595074558 |\n",
            "|0.0  |0.3740853146017552 |\n",
            "|0.0  |0.8645441734682827 |\n",
            "|0.0  |0.18875103017748696|\n",
            "|1.0  |0.9398804587947952 |\n",
            "|0.0  |0.2553674016898234 |\n",
            "+-----+-------------------+\n",
            "\n",
            "+-----+-------------------+\n",
            "|label|rawPrediction      |\n",
            "+-----+-------------------+\n",
            "|0.0  |0.2537388672042824 |\n",
            "|0.0  |0.30190710175778157|\n",
            "|0.0  |0.9994339350915736 |\n",
            "|0.0  |0.7400558425441308 |\n",
            "|0.0  |0.5885238245271296 |\n",
            "|1.0  |0.9131696805171126 |\n",
            "|1.0  |0.9999998569546372 |\n",
            "|0.0  |0.3482204528558063 |\n",
            "|1.0  |0.7191101029012559 |\n",
            "|0.0  |0.15929691842359162|\n",
            "|0.0  |0.25787658453477436|\n",
            "|1.0  |0.27137268703722905|\n",
            "|0.0  |0.3551493213446848 |\n",
            "|1.0  |0.1642560615623061 |\n",
            "|0.0  |0.8555894160238454 |\n",
            "|0.0  |0.7762407369545241 |\n",
            "|0.0  |0.3284134530104411 |\n",
            "|0.0  |0.10004376629231215|\n",
            "|0.0  |0.10235737127685085|\n",
            "|0.0  |0.9199201930889233 |\n",
            "|0.0  |0.5466184715604889 |\n",
            "|0.0  |0.4081195473707524 |\n",
            "|0.0  |0.04424215029112766|\n",
            "|1.0  |0.999843366298792  |\n",
            "|0.0  |0.5653575436563162 |\n",
            "|0.0  |0.13479635766231635|\n",
            "|0.0  |0.15769381251641934|\n",
            "|0.0  |0.9999376787337007 |\n",
            "|1.0  |0.41236911216892524|\n",
            "|0.0  |0.09722468554740082|\n",
            "|1.0  |0.26342761427332695|\n",
            "|0.0  |0.3734869874095923 |\n",
            "|0.0  |0.8793051486060987 |\n",
            "|0.0  |0.16913218759881465|\n",
            "|0.0  |0.759649078298935  |\n",
            "|1.0  |0.5856119992840916 |\n",
            "|1.0  |0.9999999991376397 |\n",
            "|0.0  |0.9907124269788492 |\n",
            "|0.0  |0.12565971339145232|\n",
            "|0.0  |0.1699189637032572 |\n",
            "|0.0  |0.14279163435349107|\n",
            "|0.0  |0.15046496510588414|\n",
            "|0.0  |0.6003385276554115 |\n",
            "|0.0  |0.14700232813138425|\n",
            "|0.0  |0.2124819028721262 |\n",
            "|0.0  |0.5697819063159766 |\n",
            "|0.0  |0.8490826148279161 |\n",
            "|0.0  |0.21876048003566462|\n",
            "|1.0  |0.9997221793647625 |\n",
            "|1.0  |0.9652259330933711 |\n",
            "|0.0  |0.10960977724927423|\n",
            "|1.0  |0.9919349324908092 |\n",
            "|0.0  |0.5550017280196708 |\n",
            "|0.0  |0.25361326012944496|\n",
            "|0.0  |0.7279639627580545 |\n",
            "|0.0  |0.9297875063449249 |\n",
            "|1.0  |0.7652900071487055 |\n",
            "|0.0  |0.9624026877646734 |\n",
            "|0.0  |0.2454423859388969 |\n",
            "|0.0  |0.21408570421472495|\n",
            "|0.0  |0.0923858333897819 |\n",
            "|0.0  |0.8441966518804414 |\n",
            "|0.0  |0.42401817018396093|\n",
            "|1.0  |0.9987229460239418 |\n",
            "|0.0  |0.45664984423158905|\n",
            "|0.0  |0.2820482882838242 |\n",
            "|0.0  |0.17131384490390167|\n",
            "|0.0  |0.2664809376349513 |\n",
            "|1.0  |0.999897855610513  |\n",
            "|0.0  |0.24418373325599851|\n",
            "|0.0  |0.3508623437349836 |\n",
            "|0.0  |0.15865890169670815|\n",
            "|0.0  |0.11872544074997382|\n",
            "|0.0  |0.11380052680167174|\n",
            "|0.0  |0.42688768784897846|\n",
            "|0.0  |0.1879949601043167 |\n",
            "|0.0  |0.7807121803033117 |\n",
            "|0.0  |0.1291839309259426 |\n",
            "|0.0  |0.9918500985371453 |\n",
            "|0.0  |0.47713349750801026|\n",
            "|0.0  |0.12044239227495879|\n",
            "|0.0  |0.14426582204577776|\n",
            "|0.0  |0.21094339731271106|\n",
            "|0.0  |0.9929959406678627 |\n",
            "|0.0  |0.19536175365804553|\n",
            "|0.0  |0.08744156847522344|\n",
            "|0.0  |0.9214887850359963 |\n",
            "|0.0  |0.19476238476441154|\n",
            "|0.0  |0.8318520702606551 |\n",
            "|0.0  |0.7811223650647989 |\n",
            "|1.0  |0.3180975004515392 |\n",
            "|1.0  |0.9983998107742441 |\n",
            "|0.0  |0.6305716485313774 |\n",
            "|0.0  |0.23558013773149256|\n",
            "|0.0  |0.766555153389261  |\n",
            "|1.0  |0.18245913043888917|\n",
            "|0.0  |0.12357204748282358|\n",
            "|1.0  |0.4576280281560686 |\n",
            "|0.0  |0.1683941775570481 |\n",
            "|0.0  |0.8756973015579085 |\n",
            "|0.0  |0.9995339875213773 |\n",
            "|0.0  |0.2676947788188099 |\n",
            "|0.0  |0.1864329443430507 |\n",
            "|1.0  |0.6873893085090953 |\n",
            "|0.0  |0.9999786528248324 |\n",
            "|0.0  |0.5939489838538636 |\n",
            "|0.0  |0.6267192247421285 |\n",
            "|1.0  |0.4610734995257194 |\n",
            "|0.0  |0.12222440381459099|\n",
            "|0.0  |0.9520650349982823 |\n",
            "|1.0  |0.6249783805043665 |\n",
            "|0.0  |0.9434576974461325 |\n",
            "|0.0  |0.7501782624303786 |\n",
            "|0.0  |0.15132379094716386|\n",
            "|0.0  |0.28923318749672877|\n",
            "|0.0  |0.20189801463378432|\n",
            "|0.0  |0.6705220230907271 |\n",
            "|0.0  |0.43178233035603986|\n",
            "|0.0  |0.11369412430430115|\n",
            "|0.0  |0.2751117323411405 |\n",
            "|0.0  |0.7418681363202493 |\n",
            "|0.0  |0.17990677745977124|\n",
            "|1.0  |0.9999835895158509 |\n",
            "|0.0  |0.1366093653390621 |\n",
            "|0.0  |0.06828980853633004|\n",
            "|0.0  |0.18969617246134862|\n",
            "|0.0  |0.9995309319248943 |\n",
            "|0.0  |0.26953535418383745|\n",
            "|0.0  |0.15288092564045508|\n",
            "|1.0  |0.5481684188447077 |\n",
            "|1.0  |0.5840709848613374 |\n",
            "|0.0  |0.9620878577511685 |\n",
            "|0.0  |0.30966436444685896|\n",
            "|0.0  |0.16435897655390452|\n",
            "|0.0  |0.5169441363545112 |\n",
            "|0.0  |0.12874957412572052|\n",
            "|0.0  |0.11651380399853639|\n",
            "|0.0  |0.5064002035880535 |\n",
            "|0.0  |0.2837028425544703 |\n",
            "|0.0  |0.2932739075175833 |\n",
            "|0.0  |0.07917268907216002|\n",
            "|0.0  |0.17012518915648234|\n",
            "|0.0  |0.996117264983622  |\n",
            "|0.0  |0.7187219868315179 |\n",
            "|0.0  |0.09275444825992218|\n",
            "|0.0  |0.8531213404731286 |\n",
            "|1.0  |0.9546033072952524 |\n",
            "|0.0  |0.21686667784154223|\n",
            "|1.0  |0.8408946002339139 |\n",
            "|0.0  |0.19255975107174517|\n",
            "|0.0  |0.9418630792562314 |\n",
            "|0.0  |0.05009553644895548|\n",
            "|0.0  |0.1632647449599588 |\n",
            "|0.0  |0.2938684403394235 |\n",
            "|1.0  |0.20068297933288348|\n",
            "|0.0  |0.1885798567891821 |\n",
            "|0.0  |0.1091862731932679 |\n",
            "|0.0  |0.8948304112735578 |\n",
            "|0.0  |0.5468194476706407 |\n",
            "|1.0  |0.8348473233117408 |\n",
            "|0.0  |0.20220632526484028|\n",
            "|0.0  |0.2946783079692331 |\n",
            "|0.0  |0.584366490450255  |\n",
            "|1.0  |0.10519678928994236|\n",
            "|1.0  |0.1538264445004014 |\n",
            "|1.0  |0.9818862129729685 |\n",
            "|0.0  |0.1886672007196616 |\n",
            "|0.0  |0.8441230750868439 |\n",
            "|0.0  |0.6151181136543262 |\n",
            "|0.0  |0.32283415981678065|\n",
            "|0.0  |0.9105607129002796 |\n",
            "|0.0  |0.18300931465133385|\n",
            "|1.0  |0.5371921757287369 |\n",
            "|1.0  |0.5991144220491517 |\n",
            "|0.0  |0.10763046240550489|\n",
            "|0.0  |0.2158209709275627 |\n",
            "|0.0  |0.9426435786245936 |\n",
            "|0.0  |0.13813261201968796|\n",
            "|0.0  |0.11751621045406568|\n",
            "|0.0  |0.27101141513427995|\n",
            "|0.0  |0.9403656644539423 |\n",
            "|0.0  |0.19717558738945762|\n",
            "|1.0  |0.9720960972366826 |\n",
            "|0.0  |0.12118222139335244|\n",
            "|1.0  |0.8246961888162071 |\n",
            "|0.0  |0.05012790756447505|\n",
            "|1.0  |0.7084908488978406 |\n",
            "|0.0  |0.16209954917941638|\n",
            "|0.0  |0.16486807176139473|\n",
            "|0.0  |0.3546478131157077 |\n",
            "|1.0  |0.9999999999986935 |\n",
            "|0.0  |0.9408150998625124 |\n",
            "|0.0  |0.24231095831277705|\n",
            "|0.0  |0.2829450428311713 |\n",
            "|0.0  |0.6744784347010461 |\n",
            "|0.0  |0.22811751013690684|\n",
            "|0.0  |0.21361375180291808|\n",
            "|0.0  |0.18862926201999675|\n",
            "|1.0  |0.19357257339754153|\n",
            "|0.0  |0.1265577123776599 |\n",
            "|0.0  |0.125222071837379  |\n",
            "|0.0  |0.9579881374418995 |\n",
            "|0.0  |0.22833243529550007|\n",
            "|0.0  |0.2185626558661311 |\n",
            "|1.0  |0.9838072575522421 |\n",
            "|0.0  |0.15948183378627412|\n",
            "|0.0  |0.7570426849608114 |\n",
            "|0.0  |0.8799612991219332 |\n",
            "|0.0  |0.05448754629263686|\n",
            "|0.0  |0.20310555484521176|\n",
            "|0.0  |0.970088180336526  |\n",
            "|1.0  |0.5282428306395228 |\n",
            "|0.0  |0.40393065432024744|\n",
            "|0.0  |0.2654569551816942 |\n",
            "|0.0  |0.8627266093708396 |\n",
            "|0.0  |0.5777391747343369 |\n",
            "|0.0  |0.1058192825418689 |\n",
            "|1.0  |0.761471089841876  |\n",
            "|0.0  |0.24235177649134632|\n",
            "|0.0  |0.8303235187131706 |\n",
            "|0.0  |0.5634500737861093 |\n",
            "|0.0  |0.25408601031272104|\n",
            "|0.0  |0.29703701656001913|\n",
            "|0.0  |0.19915029802163475|\n",
            "|1.0  |0.9650029371053876 |\n",
            "|0.0  |0.5150889876165967 |\n",
            "|1.0  |0.9950715732514513 |\n",
            "|0.0  |0.11677445238355477|\n",
            "|0.0  |0.2543833412000094 |\n",
            "|1.0  |0.9922553708610135 |\n",
            "|1.0  |0.8631937902465525 |\n",
            "|1.0  |0.8852271563843879 |\n",
            "|0.0  |0.43420426377086985|\n",
            "|0.0  |0.39771194188330894|\n",
            "|0.0  |0.9999775125146086 |\n",
            "|0.0  |0.18557458993676113|\n",
            "|0.0  |0.40620215654951186|\n",
            "|0.0  |0.20528127237316096|\n",
            "|0.0  |0.20528478806021455|\n",
            "|0.0  |0.6420287119123851 |\n",
            "|0.0  |0.13495893766780165|\n",
            "|0.0  |0.11011907794739706|\n",
            "|0.0  |0.11864927807399517|\n",
            "|0.0  |0.8794005264841294 |\n",
            "|0.0  |0.3574400082202269 |\n",
            "|0.0  |0.6361356137235273 |\n",
            "|0.0  |0.8916690741436971 |\n",
            "|0.0  |0.4169840151400396 |\n",
            "|0.0  |0.1909075825865154 |\n",
            "|1.0  |0.683534158766968  |\n",
            "|0.0  |0.15663121982844064|\n",
            "|1.0  |0.32121743320890817|\n",
            "|0.0  |0.3151409220997441 |\n",
            "|0.0  |0.3653557516467798 |\n",
            "|0.0  |0.7625479738384838 |\n",
            "|0.0  |0.2212322418187782 |\n",
            "|0.0  |0.6461111225998291 |\n",
            "|0.0  |0.18615732420608755|\n",
            "|0.0  |0.5879727279635693 |\n",
            "|0.0  |0.23706392527760733|\n",
            "|0.0  |0.9541560719093393 |\n",
            "|0.0  |0.10791805032263957|\n",
            "|0.0  |0.12883353316919965|\n",
            "|0.0  |0.12020334102325247|\n",
            "|0.0  |0.5574224767888939 |\n",
            "|0.0  |0.17134727899021818|\n",
            "|0.0  |0.3113690689297589 |\n",
            "|0.0  |0.1402315282497575 |\n",
            "|0.0  |0.5800528378469676 |\n",
            "|0.0  |0.29878107850642   |\n",
            "|0.0  |0.49232570442722234|\n",
            "|0.0  |0.6369486595074558 |\n",
            "|0.0  |0.3740853146017552 |\n",
            "|0.0  |0.8645441734682827 |\n",
            "|0.0  |0.18875103017748696|\n",
            "|1.0  |0.9398804587947952 |\n",
            "|0.0  |0.2553674016898234 |\n",
            "+-----+-------------------+\n",
            "\n",
            "{Param(parent='GBTClassifier_59a4656dfe33', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False, Param(parent='GBTClassifier_59a4656dfe33', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 5, Param(parent='GBTClassifier_59a4656dfe33', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'all', Param(parent='GBTClassifier_59a4656dfe33', name='featuresCol', doc='features column name.'): 'features', Param(parent='GBTClassifier_59a4656dfe33', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'): 'variance', Param(parent='GBTClassifier_59a4656dfe33', name='labelCol', doc='label column name.'): 'label', Param(parent='GBTClassifier_59a4656dfe33', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '', Param(parent='GBTClassifier_59a4656dfe33', name='lossType', doc='Loss function which GBT tries to minimize (case-insensitive). Supported options: logistic'): 'logistic', Param(parent='GBTClassifier_59a4656dfe33', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='GBTClassifier_59a4656dfe33', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='GBTClassifier_59a4656dfe33', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='GBTClassifier_59a4656dfe33', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256, Param(parent='GBTClassifier_59a4656dfe33', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='GBTClassifier_59a4656dfe33', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='GBTClassifier_59a4656dfe33', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0, Param(parent='GBTClassifier_59a4656dfe33', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='GBTClassifier_59a4656dfe33', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='GBTClassifier_59a4656dfe33', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='GBTClassifier_59a4656dfe33', name='seed', doc='random seed.'): 3462945055867051294, Param(parent='GBTClassifier_59a4656dfe33', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='GBTClassifier_59a4656dfe33', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0, Param(parent='GBTClassifier_59a4656dfe33', name='validationTol', doc='Threshold for stopping early when fit with validation is used. If the error rate on the validation input changes by less than the validationTol, then learning will stop early (before `maxIter`). This parameter is ignored when fit without validation is used.'): 0.01} 0.7638502723402485 0.0073866249343843005\n",
            "retrain model based on best hp from CV\n",
            "PERF:0.7638502723402485\n",
            "HP:{Param(parent='GBTClassifier_59a4656dfe33', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False, Param(parent='GBTClassifier_59a4656dfe33', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 5, Param(parent='GBTClassifier_59a4656dfe33', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'all', Param(parent='GBTClassifier_59a4656dfe33', name='featuresCol', doc='features column name.'): 'features', Param(parent='GBTClassifier_59a4656dfe33', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'): 'variance', Param(parent='GBTClassifier_59a4656dfe33', name='labelCol', doc='label column name.'): 'label', Param(parent='GBTClassifier_59a4656dfe33', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '', Param(parent='GBTClassifier_59a4656dfe33', name='lossType', doc='Loss function which GBT tries to minimize (case-insensitive). Supported options: logistic'): 'logistic', Param(parent='GBTClassifier_59a4656dfe33', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='GBTClassifier_59a4656dfe33', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5, Param(parent='GBTClassifier_59a4656dfe33', name='maxIter', doc='max number of iterations (>= 0).'): 20, Param(parent='GBTClassifier_59a4656dfe33', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256, Param(parent='GBTClassifier_59a4656dfe33', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='GBTClassifier_59a4656dfe33', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='GBTClassifier_59a4656dfe33', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0, Param(parent='GBTClassifier_59a4656dfe33', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='GBTClassifier_59a4656dfe33', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='GBTClassifier_59a4656dfe33', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='GBTClassifier_59a4656dfe33', name='seed', doc='random seed.'): 3462945055867051294, Param(parent='GBTClassifier_59a4656dfe33', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1, Param(parent='GBTClassifier_59a4656dfe33', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0, Param(parent='GBTClassifier_59a4656dfe33', name='validationTol', doc='Threshold for stopping early when fit with validation is used. If the error rate on the validation input changes by less than the validationTol, then learning will stop early (before `maxIter`). This parameter is ignored when fit without validation is used.'): 0.01}\n",
            "+--------+----------+--------------------+-------------------+----------------+------------------+------------------+--------------------+--------------------+--------------------+------------------+------------------+-------------------+-----------------+-----------------+-------------------+-----------------+-----------------+--------------------+----------------+------------------+-----------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------+----------------+--------------------+-----------------+-------------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+-------------------+------------------+--------------------+-----------------+--------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-----------------+-----------------+--------------------+-------------------+--------------------+----------------+-------------------+------------------+------------------+--------------------+-----------------+----------------+-------------------+----------------+--------------------+------------------+----------------+-------------------+----------------+-------------------+--------------------+----------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+----------------+--------------------+------------------+------------------+-------------------+-------------------+-------------------+------------------+----------------+-----------------+------------------+-----------------+------------------+--------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+--------------------+--------------------+-------------------+--------------------+----------------+-----------------+-------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+----------------+------------------+------------------+----------------+--------------------+-----------------+--------------------+-----------------+--------------------+-------------------+--------------------+-------------------+--------------------+------------------+------------------+----------------+-------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+------------------+-------------------+----------------+-------------------+-------------------+------------------+-----------------+-----------------+----------------+-----------------+--------------------+--------------------+--------------------+-------------------+----------------+------------------+-----------------+-------------------+-------------------+--------------------+------------------+--------------------+--------------------+--------------------+-------------------+------------------+----------------+----------------+--------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+------------------+------------------+----------------+-----------------+-----------------+----------------+-------------------+----------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+-----------------+-------------------+-------------------+-----------------+------------------+--------------------+-------------------+-----------------+------------------+--------------------+--------------------+------------------+------------------+----------------+----------------+-----------------+------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+-----------------+--------------------+-----------------+--------------------+-------------------+-------------------+------------------+-------------------+--------------------+-----------------+-----------------+-------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+-----------------+--------------------+----------------+--------------------+------------------+----------------+-----------------+-------------------+--------------------+--------------------+-------------------+-------------------+----------------+------------------+-----------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+-----------------+--------------------+-----------------+-------------------+--------------------+--------------------+-------------------+----------------+--------------------+--------------------+------------------+--------------------+----------------+------------------+------------------+--------------------+-------------------+------------------+----------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+-----------------+-----------------+--------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+-----------------+--------------------+------------------+--------------------+------------------+-----------------+-----------------+--------------------+------------------+-----------------+-------------------+--------------------+--------------------+--------------------+----------------------------------+-----------------------------------+-----+--------------------+--------------------+----------+\n",
            "|      ID|  TIME_OBS|           TIME_SPAN|   imp_N_227465_std|imp_N_225625_avg|  imp_N_220179_max|  imp_N_227073_avg|     imp_N_51237_std|     imp_N_220047_TT|      imp_N_51222_LT|  imp_N_220621_min|  imp_N_220181_avg|     imp_N_50960_LT|  imp_N_51006_avg| imp_N_220180_min|    imp_N_223751_LT| imp_N_227442_avg| imp_N_220046_std|     imp_N_220181_TT|imp_N_220180_max|   imp_N_50960_min|  imp_N_51222_avg|    imp_N_220046_LT|  imp_N_220228_std|   imp_N_227442_std|     imp_N_50902_TT|   imp_N_51265_min|   imp_N_223761_std|     imp_N_50902_LT|   imp_N_50902_std|    imp_N_50912_avg|   imp_N_51274_max|   imp_N_51248_min| imp_N_227467_max|    imp_N_227073_TT|    imp_N_227465_LT|   imp_N_51237_avg|imp_N_223769_std|     imp_N_220179_TT| imp_N_223761_min|    imp_N_51301_std|     imp_N_50893_TT|    imp_N_227465_TT| imp_N_220545_min|     imp_N_225664_TT|   imp_N_50902_min|   imp_N_50912_max|  imp_N_223761_avg|      imp_N_51301_TT|     imp_N_220180_TT|    imp_N_227442_LT|   imp_N_51006_std|      imp_N_51221_TT|  imp_N_51279_avg|     imp_N_223770_TT| imp_N_220228_max|  imp_N_220179_std|  imp_N_220181_std| imp_N_227442_max|   imp_N_51221_min|  imp_N_220635_avg|     imp_N_50983_TT|  imp_N_220546_avg|  imp_N_51250_max| imp_N_220179_min|     imp_N_227466_TT|    imp_N_50971_std|      imp_N_51248_TT|imp_N_220046_max|   imp_N_227073_std|  imp_N_225677_avg|   imp_N_50960_avg|      imp_N_51221_LT| imp_N_224161_min|imp_N_223769_min|    imp_N_220635_TT|imp_N_220277_max|      imp_N_51277_LT|  imp_N_220615_max|imp_N_225624_std|    imp_N_51249_std|imp_N_220045_min|    imp_N_227467_TT|    imp_N_220635_std|imp_N_225624_min|  imp_N_227457_avg|     imp_N_225624_LT|  imp_N_220615_min|   imp_N_50971_max|      imp_N_51006_TT|  imp_N_51265_avg|imp_N_225624_avg|     imp_N_225624_TT|   imp_N_224162_TT|  imp_N_227465_min|   imp_N_220277_std|     imp_N_50931_LT|     imp_N_51275_LT|   imp_N_51249_max|imp_N_220602_max|  imp_N_51275_min|  imp_N_225664_avg| imp_N_220545_max|   imp_N_50882_min|     imp_N_220615_TT|    imp_N_220645_TT|  imp_N_225677_max|  imp_N_220179_avg|   imp_N_51279_min|   imp_N_223770_std|   imp_N_51221_max|  imp_N_51274_min|   imp_N_50970_min|     imp_N_220179_LT|  imp_N_224161_max|  imp_N_220228_avg|imp_N_225625_max|   imp_N_50902_avg|  imp_N_220545_avg|    imp_N_227467_LT|  imp_N_223751_max|     imp_N_224161_TT|     imp_N_227457_TT|    imp_N_224161_LT|      imp_N_50912_TT|imp_N_220210_max| imp_N_220546_max|     imp_N_50971_LT|      imp_N_50868_TT|     imp_N_50893_std|  imp_N_220181_min|  imp_N_225664_max|  imp_N_50882_max|     imp_N_220181_LT|   imp_N_50912_min|   imp_N_51265_max|      imp_N_50882_TT|  imp_N_220180_avg|  imp_N_50893_max|  imp_N_220045_avg|  imp_N_220045_std|imp_N_220047_min|   imp_N_226253_TT|  imp_N_220621_max|     imp_N_50971_TT|  imp_N_225664_min| imp_N_224162_max|   imp_N_224162_LT|   imp_N_50931_min|  imp_N_220621_avg|  imp_N_51250_min|  imp_N_225664_std|imp_N_223769_max|   imp_N_226253_LT|   imp_N_51277_min| imp_N_51301_min|      imp_N_51222_TT| imp_N_226253_avg|     imp_N_51279_std|  imp_N_50893_min|      imp_N_50970_TT|    imp_N_51274_std|     imp_N_220277_TT|     imp_N_50960_TT|     imp_N_50960_std|   imp_N_51221_avg|   imp_N_51277_max|imp_N_225625_min|    imp_N_51277_std|  imp_N_220047_avg|  imp_N_50971_avg|  imp_N_227457_max|   imp_N_50970_max|    imp_N_220602_TT|   imp_N_50931_std|     imp_N_51301_LT|  imp_N_227467_min|    imp_N_220645_LT|imp_N_220277_min|    imp_N_220546_LT|     imp_N_50882_LT|   imp_N_51248_avg|  imp_N_51279_max| imp_N_220602_std| imp_N_50893_avg| imp_N_223770_avg|     imp_N_227073_LT|      imp_N_51249_TT|     imp_N_220635_LT|    imp_N_227443_LT|imp_N_220602_avg|   imp_N_50931_avg| imp_N_227466_avg|   imp_N_220545_std|    imp_N_227442_TT|     imp_N_220210_TT|  imp_N_224161_std|     imp_N_220228_LT|     imp_N_223761_TT|     imp_N_220545_LT|    imp_N_220046_TT|   imp_N_50983_std|imp_N_223769_avg|imp_N_227443_min|      imp_N_50931_TT| imp_N_223770_max|  imp_N_51006_min| imp_N_220645_min|     imp_N_51249_LT| imp_N_223761_max|  imp_N_51250_avg|  imp_N_220645_std|   imp_N_51274_avg|imp_N_220635_min|  imp_N_50971_min|  imp_N_51275_avg|imp_N_227443_avg|    imp_N_227466_LT|imp_N_220635_max|     imp_N_51274_LT|  imp_N_227073_max|     imp_N_220180_LT|  imp_N_227073_min|    imp_N_220602_LT|   imp_N_50931_max| imp_N_227466_max|    imp_N_51222_std|    imp_N_227457_LT| imp_N_227457_std|  imp_N_220180_std|      imp_N_50970_LT|   imp_N_220615_avg|  imp_N_51265_std|   imp_N_50882_std|    imp_N_226253_std|      imp_N_51279_LT|  imp_N_227442_min|  imp_N_220210_std|imp_N_227443_max|imp_N_220602_min| imp_N_226253_min|  imp_N_227466_min| imp_N_220546_min|  imp_N_51248_max| imp_N_223752_max|   imp_N_220546_std| imp_N_227443_std| imp_N_225677_min|  imp_N_50983_min|     imp_N_220277_LT|  imp_N_50868_avg|     imp_N_225677_TT|    imp_N_50868_std|    imp_N_223752_LT|   imp_N_223752_TT|   imp_N_223751_std|     imp_N_220047_LT|  imp_N_51222_min| imp_N_220277_avg|     imp_N_51279_TT|      imp_N_50983_LT|     imp_N_50893_LT|    imp_N_51248_std|  imp_N_223751_min|    imp_N_225625_LT|     imp_N_51250_TT| imp_N_220181_max|      imp_N_51006_LT|imp_N_223752_avg|     imp_N_225677_LT|  imp_N_220046_avg|imp_N_220047_max|  imp_N_51222_max|   imp_N_225625_std|      imp_N_51265_LT|    imp_N_223752_std|     imp_N_51237_TT|    imp_N_225625_TT|imp_N_225624_max|  imp_N_224161_avg|  imp_N_50983_max|     imp_N_220546_TT| imp_N_51275_max|   imp_N_223769_TT|  imp_N_50882_avg|     imp_N_220621_TT|      imp_N_51248_LT|imp_N_220046_min|   imp_N_50868_min| imp_N_223752_min|    imp_N_224162_std|     imp_N_227443_TT|  imp_N_51301_max|      imp_N_51277_TT| imp_N_224162_min|    imp_N_223769_LT|      imp_N_51275_TT|     imp_N_223761_LT|    imp_N_225664_LT|imp_N_220210_min|     imp_N_220615_LT|     imp_N_220210_LT|   imp_N_50868_max|     imp_N_220621_LT|imp_N_220228_min|   imp_N_50970_avg|   imp_N_51006_max|    imp_N_227467_std|    imp_N_223770_LT|  imp_N_227465_max|imp_N_220045_max|     imp_N_51274_TT|     imp_N_51237_LT| imp_N_227457_min|      imp_N_50912_LT|   imp_N_51301_avg|   imp_N_51249_min|     imp_N_220045_TT|  imp_N_220621_std|  imp_N_227466_std|     imp_N_220045_LT| imp_N_223751_avg| imp_N_220645_avg| imp_N_224162_avg|      imp_N_50868_LT|   imp_N_50902_max|     imp_N_50912_std|  imp_N_227465_avg|  imp_N_220645_max|    imp_N_51221_std|  imp_N_227467_avg|  imp_N_220210_avg|   imp_N_51249_avg|     imp_N_51250_LT|     imp_N_220228_TT|   imp_N_51237_min|    imp_N_225677_std|   imp_N_50983_avg|   imp_N_51250_std|   imp_N_223751_TT| imp_N_226253_max|      imp_N_51265_TT|   imp_N_51275_std|     imp_N_50970_std|   imp_N_51237_max|  imp_N_50960_max| imp_N_223770_min|    imp_N_220615_std|   imp_N_51277_avg| imp_N_220047_std|    imp_N_220545_TT|    features_imputed|        demo_feature|            features|DISCH_51881_51851_51884_51853_excl|DISCH_51881_51851_51884_51853_label|label|       rawPrediction|         probability|prediction|\n",
            "+--------+----------+--------------------+-------------------+----------------+------------------+------------------+--------------------+--------------------+--------------------+------------------+------------------+-------------------+-----------------+-----------------+-------------------+-----------------+-----------------+--------------------+----------------+------------------+-----------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------+----------------+--------------------+-----------------+-------------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+-------------------+------------------+--------------------+-----------------+--------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-----------------+-----------------+--------------------+-------------------+--------------------+----------------+-------------------+------------------+------------------+--------------------+-----------------+----------------+-------------------+----------------+--------------------+------------------+----------------+-------------------+----------------+-------------------+--------------------+----------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+----------------+--------------------+------------------+------------------+-------------------+-------------------+-------------------+------------------+----------------+-----------------+------------------+-----------------+------------------+--------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+--------------------+--------------------+-------------------+--------------------+----------------+-----------------+-------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+----------------+------------------+------------------+----------------+--------------------+-----------------+--------------------+-----------------+--------------------+-------------------+--------------------+-------------------+--------------------+------------------+------------------+----------------+-------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+------------------+-------------------+----------------+-------------------+-------------------+------------------+-----------------+-----------------+----------------+-----------------+--------------------+--------------------+--------------------+-------------------+----------------+------------------+-----------------+-------------------+-------------------+--------------------+------------------+--------------------+--------------------+--------------------+-------------------+------------------+----------------+----------------+--------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+------------------+------------------+----------------+-----------------+-----------------+----------------+-------------------+----------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+-----------------+-------------------+-------------------+-----------------+------------------+--------------------+-------------------+-----------------+------------------+--------------------+--------------------+------------------+------------------+----------------+----------------+-----------------+------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+-----------------+--------------------+-----------------+--------------------+-------------------+-------------------+------------------+-------------------+--------------------+-----------------+-----------------+-------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+-----------------+--------------------+----------------+--------------------+------------------+----------------+-----------------+-------------------+--------------------+--------------------+-------------------+-------------------+----------------+------------------+-----------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+-----------------+--------------------+-----------------+-------------------+--------------------+--------------------+-------------------+----------------+--------------------+--------------------+------------------+--------------------+----------------+------------------+------------------+--------------------+-------------------+------------------+----------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+-----------------+-----------------+--------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+-----------------+--------------------+------------------+--------------------+------------------+-----------------+-----------------+--------------------+------------------+-----------------+-------------------+--------------------+--------------------+--------------------+----------------------------------+-----------------------------------+-----+--------------------+--------------------+----------+\n",
            "|153202.0|2195-05-21|{2195-05-20 00:00...|0.13065475397959778|             8.9|             125.0|               9.0|  0.0148147169883393| 0.04162341526443389| 0.25736837479277413|              93.0|            75.375| 0.2888504831712819|             12.0|             53.0|0.38626031753797635|              4.1|              0.0|   0.679229372996118|            76.0|               1.9|              8.7| 0.3371881483049508|               0.0|                0.0| 0.8015914916790224|             471.0| 0.9643650760992986| 0.4007957458395112|               0.0|                0.4|16.326121062384175|              29.9|1.477589339794065|0.18596858204010075| 0.4600024796048131|1.4608241195741203|             0.0| 0.47869959975393217|             97.1|                0.0|0.44141736262646103|0.48651583403086374|             26.3|  0.9390680996136072|             102.0|               0.4|              98.0|  0.5873282704184287| 0.38921917141318274| 0.5231770117520154|               0.0|  0.5737610724433981|             2.89|  0.4825208223441543|              8.7| 7.120856494988662| 6.382348705609871|              4.1|              26.3|               1.9|0.21816460208664112|              11.9|             91.0|            100.0| 0.47280115065897854|                0.0|  0.8533746712047077|           120.0|                0.0|               2.6|               1.9| 0.28688053622169907|             35.0|           100.0| 0.5813086081360233|           100.0|  0.3547869743016958|               0.4|             0.0|                0.0|            83.0|0.48908889201931066|                 0.0|            12.0|             471.0| 0.15742229447779182|               0.4|               4.1|  0.3137591402751386|            471.0|            12.0| 0.31484458895558365|0.9738948671571004|16.087061323618695| 2.6127359010984805|0.19593383077174803| 0.4142515026977065|              33.0|           102.0|36.91319672131147|146.66666666666666|             26.3|              26.0|  0.2828588017908533|0.21814832929200006|               2.6|113.95833333333333|              2.89|                0.0|              26.3|16.04014206300184|               2.6| 0.23934979987696609|              40.0|               8.7|             8.9|             102.0|              26.3| 0.4584105459263105|             160.0| 0.08942376662488417|0.009408788879074658| 0.9552881166875579| 0.28199288367483494|            36.0|             11.9| 0.5245125484381217| 0.18687580390398248|                 0.0|              64.0|             156.0|             26.0|  0.6603853135019411|               0.4|             471.0|  0.8617935932847937|63.416666666666664|              8.9| 92.04166666666667|  5.05370463675466|            60.0| 0.981301814901793|              93.0| 0.9509749031237567|             138.0|              8.0|0.5130525664214498|              93.0|              93.0|             91.0| 7.363574011458174|           100.0|0.4906509074508965|              15.5|            11.9|  0.5147367495855483|             85.0|                 0.0|              8.9| 0.47022037610188283|0.12965952398334926|6.924933982718967E-4| 0.5777009663425638|                 0.0|              26.3|              15.5|             8.9|                0.0|              60.0|              4.1|             471.0|               2.6| 0.8032551337067798|               0.0| 0.7063358647907856|1.4457904300423992|0.10907416464600003|            91.0|  0.698483829596674| 0.5691032033576031|              29.9|             2.89|              0.0|             8.9|             90.0| 0.09298429102005037|  0.8475698591732508|  0.2906543040680116| 0.5726742796766917|           102.0|              93.0|37.70331834880121|                0.0| 0.9536459764959693|3.548206420894111...|               2.5|  0.2561239873313129|  0.6825128363987369| 0.28622989668578247| 0.6743762966099016|               0.0|           100.0|            26.0| 0.39186766154349606|             90.0|             12.0|            133.0| 0.4237849295866254|             99.7|             91.0|               0.0| 16.17945696932262|             1.9|              4.1|37.83908909055424|            26.0|0.41496732739917513|             1.9| 0.4594330506661511|               9.0|  0.8053904142934086|               9.0| 0.4016275668533899|              93.0|38.69393271461717|                0.0| 0.9952956055604627|              0.0|  6.76336126164761| 0.23511018805094142|                0.4|              0.0|               0.0|                 0.0| 0.26752923254082395|               4.1| 3.769163995135025|            26.0|           102.0|             85.0|36.781171693735494|             11.9|             29.9|             90.0|                0.0|              0.0|              2.6|            133.0|3.462466991359483...|              9.0| 0.46877014127330285|                0.0| 0.4784520629105555| 0.956904125821111|                0.0|   0.979188292367783|              8.7|95.41666666666667| 0.5350584650816479| 0.10908230104332056| 0.7792913186867695|                0.0|             160.0| 0.7797750402793021| 0.9328320323108141|             89.0|  0.1568795701375693|            90.0| 0.23438507063665143|             120.0|            60.0|              8.7|                0.0|  0.9959158278644086|                 0.0| 0.4884661578947222| 0.4404499194413958|            12.0|              37.5|            133.0|  0.6030323408066521|38.8348594847775|0.9866770743020669|             26.0|  0.3896953305463243| 0.42668733560235383|           120.0|               9.0|             90.0|                 0.0|  0.8546514406466165|             11.9|  0.7095739486033916|              8.0|0.49333853715103343|  0.4708701645239077| 0.34125641819936847| 0.4695340498068036|            22.0| 0.14142940089542666|                 1.0|               9.0| 0.19484766527316216|             8.7|               2.6|              12.0|0.014632153041738868|0.24126041117207714|16.373460837887045|           103.0|0.48486335344055065|0.45745215253325033|            471.0| 0.14099644183741747|              11.9|              33.0|0.033037508972991146|               0.0|0.8705195762144462|  0.9834812455135045|            160.0|            133.0|              8.0| 0.09343790195199124|             102.0|                 0.0|16.227216656547245|             133.0|                0.0|1.4611558651322438|30.291666666666668|              33.0| 0.5335839838445929|  0.5122479746626258|1.4453931203931218|                 0.0|             133.0|               0.0|0.7725206350759527|             85.0|0.008168344271182789| 0.876945766580447|                 0.0|1.4776412776412784|              1.9|             90.0|                 0.0|              15.5|              0.0| 0.5724597933715649|[0.98348124551350...|(166,[0,3,11,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[0.79103181148143...|[0.82949657879499...|       0.0|\n",
            "|159536.0|2126-08-02|{2126-08-01 00:00...|                0.0|             9.4|             182.0|              16.0|                 0.0|  0.5372745772832075|  0.4049927972222716|              99.0|             108.8| 0.6797969315397088|30.34493907672786|             77.0|  0.419016389184504|              4.6|              0.0|2.567495753113565E-7|            95.0|               2.2|              9.3|0.38319833098312733|               0.0|                0.0| 0.9242200327996876|             198.0|                0.0| 0.4621100163998438|               0.0| 1.4766575863383713|              12.5|              27.7|              1.1| 0.5441683213580897| 0.1717482576052679|               1.1|             0.0|3.164683433765737...|             96.1|                0.0|0.14297690547548036| 0.3434965152105358|             26.7| 0.31373313619525717|             103.0|1.5093973872734954|              96.1|   0.269321112260169|9.222293721726914E-5| 0.8320230481388723|0.7100483349760915|  0.6415560614258541|             3.34|  0.6194900007990161|              9.3| 6.689544080129826| 5.564171097297422|              4.6|              26.7|               2.2| 0.9464621090323675|               4.8|             80.0|            164.0|  0.2467179393218596|                0.0| 0.17228219609830928|           120.0|                0.0|               4.5|               2.2| 0.32077803071292704|             30.0|           100.0| 0.6392789015831795|           100.0|  0.2648361152354285|1.5046424090338784|             0.0|                0.0|            67.0| 0.3988801527810958|                 0.0|            88.0|             198.0|  0.9984329781712885|1.4406106231702211|               4.6| 0.43250070550679126|            198.0|            88.0|0.003134043657423079|0.9815392365222636|              12.5| 0.6998542122237652|0.23945102402941437|0.12249567860958703|              34.7|           103.0|             24.0|             110.0|             26.7|              25.0|  0.4538385136849273|  0.946286246363002|               4.5|             171.5|              3.34|                0.0|              26.7|             12.5|               4.5|  0.9999984176582831|              30.0|               9.3|             9.4|             103.0|              26.7| 0.1994400763905479|             160.0|  0.4720685067091678|  0.9941658725039509| 0.2360342533545839| 0.45197895889384554|            19.0|              4.8| 0.8332957593383423|  0.5343214914866725|                 0.0|             100.0|             113.0|             25.0|  0.9999998716252123|1.4444584913611462|             198.0|   0.984857258566092|              86.6|              9.4| 68.66666666666667| 2.494438257849294|            50.0| 0.986777781674111|              99.0|0.33340848132331546|             107.0|              8.0|0.5092303817388681|              99.0|              99.0|             80.0|               3.0|           100.0|0.4933888908370555|              15.0|             4.8|  0.8099855944445432|             85.0|                 0.0|              9.4|  0.3961802903516639|                0.0|0.006471966778966359| 0.6404061369205825|                 0.0|              26.7|              15.0|             9.4|                0.0|              50.0|              4.6|             198.0|               4.5| 0.9239600917072498|               0.0| 0.1346605561300845|               1.1|  0.526856876818499|            98.0| 0.1353516001917399|  0.492428629283046|              27.7|             3.34|              0.0|             9.4|             90.0|  0.7279158393209552| 0.38123253524434286|  0.6803605492084103|0.49610616460362017|           103.0|              99.0|             24.0|                0.0| 0.3359539037222554| 0.02463635785660822|               0.0|  0.4024593678809968| 0.10906706397168528| 0.32001147888941067| 0.7663966619662547|               0.0|           100.0|            25.0| 0.47890204805882874|             90.0|29.59090909090909|            139.0| 0.8093837323778286|             96.1|             80.0|               0.0|              12.5|             2.2|              4.6|             24.0|            25.0| 0.1233589696609298|             2.2|0.17062472051108385|              16.0|  0.9999538885313913|              16.0| 0.4619800458536249|              99.0|             24.0|                0.0| 0.5029170637480245|              0.0|6.6211781428987395|  0.8019098548241681| 1.4724647487602325|              0.0|               0.0|                 0.0|  0.5937318817162773|               4.6|2.9760952365713798|            25.0|           103.0|             85.0|              24.0|              4.8|             27.7|             90.0|                0.0|              0.0|              4.5|            139.0|  0.9967640166105168|             16.0|  0.3996434830089294|                0.0|0.48475960000217266|0.9695192000043453|                0.0| 0.26863728864160374|              9.3|99.71428571428571| 0.8125362365674454|  0.5267689454838163| 0.9285115472622598|                0.0|             160.0| 0.9282902966610607|0.06719303231371578|            116.0|  0.4533263359134597|            90.0|  0.8001782584955353|             120.0|            50.0|              9.3|                0.0|   0.508383110843204|                 0.0|0.39887236892500944|0.14341940667787859|            88.0|              30.0|            139.0|  0.2707032003834798|            24.0|0.9905790501718436|             25.0|  0.4739722956341428| 0.08614109804915464|           120.0|              16.0|             90.0|                 0.0|  0.9922123292072403|              4.8|   0.529672230470857|              8.0| 0.4952895250859218| 0.24499135721917406| 0.05453353198584264|0.15686656809762858|            11.0|  0.4335548314340772| 0.01231817892830411|              16.0|  0.2369861478170714|             9.3|               4.5|31.112068965517242|                 0.0|0.30974500039950803|              12.5|            74.0| 0.3412494410221677|0.19943618446250472|            198.0|  0.4343233352150944|               4.8|              34.7|0.013406047436526089|               0.0|               0.0|0.006703023718263044|            160.0|            139.0|              8.0|  0.7328392542566637|             103.0|  0.0302482200664027|              12.5|             139.0|                0.0|               1.1|              15.0|              34.7|0.03359651615685789|  0.8049187357619936|               1.1|                 0.0|             139.0|               0.0| 0.838032778369008|             85.0|   0.983233778313592|               0.0|                 0.0|               1.1|              2.2|             90.0|0.029776204513543382|              15.0|              0.0| 0.6400229577788213|[0.00670302371826...|(166,[0,1,10,14,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[1.44345305177489...|[0.94719535018278...|       0.0|\n",
            "|102486.0|2141-07-20|{2141-07-19 00:00...|                0.0|             7.4|             118.0|              12.0|                 0.0| 0.28527572776766313| 0.11517747820980694|              99.0| 62.96153846153846| 0.5500704038677933|             13.0|             37.0|0.36165156269653376|              3.4|              0.0|1.609532975782535...|            73.0|               2.1|              7.9| 0.3034253128759712|               0.0|                0.0| 0.8280376885293362|             269.0|  0.604611904907237| 0.5859811557353318|               0.0|                0.8|              16.5|              27.8|              1.5| 0.6199638177152004| 0.5278229597390028|               1.5|             0.0|9.407003443308672E-6|             96.5|                0.0|0.18832487936730066| 0.9443540805219943|             24.7| 0.41545845588492925|             105.0|               0.8| 97.13333333333333|  0.8094959748838978|0.011258207952841326|0.11361441164105651|               0.0|  0.3418651824064497|             2.85|  0.3897484515890689|              7.9| 9.576923076923077| 8.178211057112343|              3.4|              24.7|               2.1|0.21816460208664112|              10.6|             87.0|             82.0|0.005928443580563616|                0.0|  0.1897631695704932|           120.0|                0.0|               2.9|               2.1| 0.17093259120322485|             30.0|           100.0| 0.8976366291296707|           100.0|  0.8180545575122569|               0.8|             0.0|                0.0|            70.0|  0.924140058910544|                 0.0|            13.0|             269.0| 0.17029535686832742|               0.8|               3.4|  0.3397684387664792|            269.0|            13.0| 0.34059071373665484|0.9680307246992478|              16.5| 1.8401344175239518|0.23945102402941437|  0.996660567933498|              32.1|           105.0|             60.7|151.38370222803474|             24.7|              19.0| 0.49040166949984454|0.21814832929200006|               2.9| 97.11538461538461|              2.85|                0.0|              24.7|             16.5|               2.9|4.703501721654336E-6|              30.0|               7.9|             7.4|             105.0|              24.7|  0.537929970544728|             160.0| 0.21294704427559902|  0.4958161604191571|0.10647352213779951|  0.4894491185800768|            28.0|             10.6|0.11379437944827117|   0.625578218093795|                 0.0|              35.0|178.49948822927328|             19.0|8.047664878912676E-5|               0.8|             269.0| 0.23907235505648927|              53.5|              7.4| 79.61538461538461|7.2274951671054435|            50.0|0.9771005412364924|              99.0|0.22758875889654234|127.71084953940634|              8.0| 0.515984637650376|              99.0|              99.0|             87.0| 19.70452579251507|           100.0|0.4885502706182462|              18.0|            10.6| 0.23035495641961387|             85.0|                 0.0|              7.4|  0.6353988240798489|                0.0|  0.1761690015719151| 0.8998591922644134|                 0.0|              24.7|              18.0|             7.4|                0.0|              50.0|              3.4|             269.0|               2.9| 0.8321581944717855|               0.0| 0.5952520125580512|               1.5|0.10907416464600003|            93.0| 0.5882873748526358|0.11953617752824464|              27.8|             2.85|              0.0|             7.4|             90.0|  0.3099819088576002|  0.4487228200802237|  0.5511816854351647|0.12153457193935024|           105.0|              99.0|            66.85|                0.0|0.22722882328211302|6.966582880204182E-4|               0.0| 0.11512114991246207|0.044142363530349005| 0.17068183734445713| 0.6068506257519424|               0.0|           100.0|            19.0| 0.47890204805882874|             90.0|             13.0|            133.0|0.22436141004011184|             98.4|             87.0|               0.0|              16.5|             2.1|              3.4|            66.85|            19.0| 0.9970357782097182|             2.1| 0.5307242995796353|              12.0|0.005629103976420663|              12.0| 0.5839209027641072|              99.0|             73.0|                0.0| 0.7520919197904214|              0.0| 6.834584000620554| 0.31769941203992447|                0.8|              0.0|               0.0|                 0.0|  0.2430530355475481|               3.4|2.4654416170057454|            19.0|           105.0|             85.0|              60.7|             10.6|             27.8|             90.0|                0.0|              0.0|              2.9|            133.0|  0.9119154992140425|             12.0|  0.6332838797950224|                0.0|0.47361569343253623|0.9472313868650725|                0.0| 0.14263786388383157|              7.9| 97.8076923076923| 0.4861060710950962| 0.10908230104332056|0.09416243968365033|                0.0|             160.0| 0.0960885863228818| 0.5404647089190597|             77.0|  0.1698842193832396|            90.0|  0.3166419398975112|             120.0|            50.0|              7.9|                0.0|  0.7592155070105975|                 0.0| 0.9275073699266075| 0.1921771726457636|            13.0|              30.0|            133.0|  0.8234252502947285|            73.0|0.9836831939012491|             19.0|  0.4739722956341428|  0.0948815847852466|           120.0|              12.0|             90.0|                 0.0|  0.2430691438787005|             10.6|  0.3638908849754864|              8.0|0.49184159695062457|0.006678864133004063|0.022071181765174502|0.48473795362972405|            17.0| 0.24520083474992227|  0.9996516708559898|              12.0|  0.2369861478170714|             7.9|               2.9|              13.0|                 0.0|0.19487422579453445|              16.5|            94.0| 0.9385514008407294| 0.5362463150366963|            269.0|  0.2447245592900384|              10.6|              32.1|  0.0896588765165506|               0.0| 6.149999999999999|  0.0448294382582753|            160.0|            133.0|              8.0|  0.3127891090468975|             105.0|                 0.0|              16.5|             133.0|                0.0|               1.5|23.192307692307693|              32.1|0.27023235445952987| 0.23024229982492414|               1.5|                 0.0|             133.0|               0.0|0.7233031253930675|             85.0| 0.48156898597880493| 6.149999999999999|                 0.0|               1.5|              2.1|             90.0|                 0.0|              18.0|              0.0|0.34136367468891426|[0.04482943825827...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[-0.4816973264157...|[0.27619904387904...|       1.0|\n",
            "|149546.0|2155-02-08|{2155-02-07 00:00...|                0.0|             7.8|138.94057916509965|              12.0|                 0.0|  0.1496787525087407|  0.5677343256979304|             183.0| 74.77826247362239|0.10763011189452963|             31.0|47.70463975858167|  0.426930727592382|              3.5|              0.0| 0.20718381381747253|78.0369671821954|               1.7|              9.9|0.38319833098312733|               0.0|                0.0| 0.8015914916790224|             202.0|0.31874754901018426| 0.4007957458395112|               0.0|                1.0|              15.9|              30.2|              1.4| 0.6199638177152004|0.46701465347425664|               1.4|             0.0| 0.19619776364057873|             95.5|                0.0|0.44753280614666313| 0.9340293069485133|             29.1| 0.41545845588492925|             102.0|               1.0| 96.02000000000001|  0.8638571815134771| 0.22323189276593913|0.15227043484729885|               0.0|  0.9072741796744047|             3.28|  0.6194900007990161|              9.9|11.487286830973543| 8.168515431713185|              3.5|              29.1|               1.7|  0.714557794942773|              10.3|             89.0|97.67732230161715|  0.2872524231483276|                0.0|  0.9809592404305372|           120.0|                0.0|               2.6|               1.7|  0.5463629101627976|             30.0|           100.0|0.21813709089826688|           100.0|  0.3174428980309364|               1.0|             0.0|                0.0|            77.0| 0.8890503192515382|                 0.0|            31.0|             202.0| 0.49405282941353673|               1.0|               3.5|  0.9959011481158101|            202.0|            31.0|  0.9881056588270735|0.9815392365222636|              15.9|0.45175395145262565| 0.9140790661626669|0.14250626275444325|              34.2|           102.0|             25.3|151.38370222803474|             29.1|              27.0|  0.6188162389705184|  0.714656964940277|               2.6|117.87633609613528|              3.28|                0.0|              29.1|             15.9|               2.6|   0.472376144412589|              30.0|               9.9|             7.8|             102.0|              29.1| 0.4445251596257691|160.55733211512106|  0.4720685067091678|  0.9638900806513879| 0.2360342533545839|  0.6178960502701973|            12.0|             10.3|0.15257210330660537|   0.625578218093795|                 0.0|60.782215523737754|178.49948822927328|             27.0|  0.4711329744042347|               1.0|             202.0|  0.7134994830130421| 61.39591571522619|              7.8| 86.33333333333333| 8.711422896914653|            60.0|0.9745232284758952|             183.0|0.30514420661321073|127.71084953940634|              8.0|0.5092303817388681|             183.0|             183.0|             89.0| 19.70452579251507|           100.0| 0.491807068783402|              15.3|            10.3|  0.8645313486041392|85.00246212121212|                 0.0|              7.8| 0.47022037610188283|                0.0|0.006471859609530...|0.21526022378905926|                 0.0|              29.1|              15.3|             7.8|                0.0|              60.0|              3.5|             202.0|               2.6| 0.8032551337067798|               0.0| 0.5680714092432615|               1.4| 0.3573284824701385|            99.0| 0.5614410652003854| 0.6432502584934789|              30.2|             3.28|              0.0|             7.8|             90.0|  0.3099819088576002|  0.5744044309274503| 0.10906854544913344| 0.6465904979035804|           102.0|             183.0|             25.3|                0.0| 0.3045408696945977|5.845218422829997E-4|               0.0|  0.5641055546303895|2.011716691154084...|  0.5449646922845189| 0.7663966619662547|               0.0|           100.0|            27.0| 0.17184186767466622|             90.0|             31.0|            137.0| 0.7127977845362748|             96.3|             89.0|               0.0|              15.9|             1.7|              3.5|             25.3|            27.0| 0.1436262115741638|             1.7| 0.4692157220967054|              12.0| 0.48581197505212126|              12.0| 0.4016275668533899|             183.0|             25.3|                0.0|  0.518054959674306|              0.0| 8.132272964076716| 0.23511018805094142|                1.0|              0.0|               0.0|0.002728073736398...|   0.548877544645678|               3.5|               0.0|            27.0|           102.0|84.99962121212121|              25.3|             10.3|             30.2|90.01611459265891|                0.0|              0.0|              2.6|            137.0|  0.9967640701952347|             12.0| 0.46877014127330285|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.9251606237456297|              9.9|99.71428571428571|  0.902244910708644|  0.3572788974713865|0.22376640307333157|                0.0|160.30150753768845|0.22640214539090547| 0.7918405167998113|90.91899020346646| 0.49795057405790505|90.0066025067144| 0.23438507063665143|             120.0|            60.0|              9.9|                0.0|  0.5237159142692422|0.007491553859143...| 0.8865360792227868|0.45280429078181095|            31.0|              30.0|            137.0|  0.8771178695992291|            25.3|0.9905790501718436|             27.0| 0.19291933244858292|  0.4904796202152686|           120.0|              12.0|90.00044762757386|                 0.0|  0.7068190041928392|             10.3|  0.6348857960618728|              8.0| 0.4952895250859218|  0.2850125255088865|1.005858345577042...|0.48473795362972405|            12.0|  0.3094081194852592|2.922609211414998...|              12.0|  0.9035403337757085|             9.9|               2.6|              31.0|                 0.0|0.30974500039950803|              15.9|            99.0| 0.9384314441934108| 0.4432680396113934|            202.0| 0.30894802513509867|              10.3|              34.2|  0.8401739988337379|               0.0|               0.0|   0.579913000583131|160.4163621135982|            137.0|              8.0|  0.3127891090468975|             102.0|                 0.0|              15.9|             137.0|                0.0|               1.4|              12.0|              34.2|0.39592025839990563|  0.8717888907392212|               1.4|                 0.0|             137.0|               0.0|0.7269868524702858|85.00530303030303|  0.9525681714615156|               0.0|                 0.0|               1.4|              1.7|             90.0|                 0.0|              15.3|              0.0| 0.9100706154309621|[0.57991300058313...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[0.57146312721593...|[0.75821649764562...|       0.0|\n",
            "|111375.0|2135-04-04|{2135-04-03 00:00...|                0.0|             8.1|             149.0|              14.0|  0.0148147169883393|  0.5602141238488558|  0.5007014305921953|120.72483482316362|              78.5|0.48713427104996304|30.34493907672786|             41.0|  0.426930727592382|              3.4|              0.0|  0.5592490181072254|            43.0|2.0192751891676624|9.720783890168976| 0.3371881483049508|               0.0|                0.0|0.46900135508873325|204.55184887459808|                0.0| 0.4976453997824787|0.4203854376206732| 1.4766575863383713|16.326121062384175|30.123507616302994|              1.1| 0.9558889475438066| 0.1783015799355559|1.4608241195741203|             0.0| 0.04969568184349138|             96.8|0.15238186232786088| 0.4720913015670395| 0.3566031598711118|             28.6| 0.35182833735787733|103.13290175171363|1.5093973872734954|              96.8| 0.48196839886325465|0.026929756396005068|0.11361441164105651|0.7100483349760915| 0.45219772949982334|3.250759740695953|  0.4825208223441543|              9.9| 4.109609335312651|18.980252896102307|              3.4|28.889421157684648|               2.5|0.47292877765230995|  9.43330216554195|90.84011276681434|            139.0|  0.4782614367924135|0.08596788964012393| 0.47373916357820256|           120.0|                0.0|               3.2| 2.056371584077676|  0.5286978729187907|             30.0|           100.0|0.13656657361269778|            95.0|  0.4709935406778632|               0.5|             0.0|0.06995517975068115|            70.0| 0.3988801527810958|                 0.0|            16.0|             287.0| 0.21282318310624115|               0.5|4.1610394537177555| 0.43250070550679126|206.9605004019292|            16.0|  0.4256463662124823|0.9738948671571004|              12.6|  1.632993161855452|0.46314413213559713| 0.4142515026977065|33.248717948717946|            99.0|36.91319672131147|              98.0|             28.6|25.074626865671643|  0.3281425073977985|  0.714656964940277|               3.2|143.66666666666666|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|3.4006276150627603|  0.9751521590782544|              30.0|               9.9|             8.1|103.59088827838833|              28.6| 0.1994400763905479|160.55733211512106|  0.3091690311323449| 0.39427655072486156|0.15458451556617245| 0.45197895889384554|            22.0|9.599003202562052|0.48414255054546573| 0.46370842439089255|0.051237573780987374|              63.0|              98.0|25.83084577114428|  0.7203754909463873|1.4444584913611462|209.46905144694534|  0.4752646286819739|              42.0|8.429773195876288|              71.0|               1.0|            55.0|0.9745232284758952|132.22386319471434| 0.4773693026559077|              98.0|              8.0|0.5130525664214498|120.49256068911511|126.38537745451853|90.55054369714055|               0.0|           100.0| 0.491807068783402|16.114291481631014|9.21408502024291| 0.47109294943321767|85.00246212121212|0.022153573700935885|8.320536082474234|   0.475782102493217|0.12965952398334926|0.004019416683953692|0.46459083063785256| 0.03490935761855885| 29.31268022684791|16.177069035123125|             8.1|0.02918013555493569|              55.0|4.068660082014597|             287.0|3.5946443514644364| 0.4775870080559247| 4.798857346195361| 0.4686834829104542|               1.1| 0.3573284824701385|            91.0|0.46784589154325545|   0.51281308899984|30.178889460683365|3.274385328496573|              0.0|8.37549739813451|             90.0|  0.5220555262280967|  0.4894464120957203|  0.9317167131936511| 0.6465904979035804|            99.0|125.57075735540884|             30.2|                0.0|0.22722882328211302|  0.2929552677201489|               0.0|  0.5641055546303895| 0.28300602368577227| 0.49680314683739135| 0.6743762966099016|0.3717226033966161|           100.0|            27.0|  0.4831275084671001|             90.0|29.59090909090909|            137.0| 0.4729044061266951|             96.8|90.69301248489731|               0.0| 16.17945696932262|             2.5|3.977200303490134|37.83908909055424|            27.0|0.23913071839620675|             2.5| 0.4594330506661511|              14.0|0.013464878198002534|              14.0|0.23879350402796234|130.73140172278778|             30.2|0.07060400796808293| 0.8028617246375692|              0.0| 0.816496580927726| 0.47827446509141863|                0.5|2.297622738931195|0.3525454384054092|0.002728073736398...|  0.5043438780045272|               3.4| 3.344772040064913|            27.0|            99.0|84.99962121212121|              30.2|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|              0.0|              3.2|138.3512996941896|0.002009708341976846|13.55895896170368|  0.8183048093200608|0.36128275365036766| 0.4784520629105555| 0.956904125821111|0.12368084276523614|  0.7198929380755721|9.644677419354842|             93.0|0.46473433340591286|  0.5004252396055716| 0.5084698186832426|0.05272455247871184|160.30150753768845|0.36857957876464764|0.47024088066356073|            111.0|  0.4533263359134597|            90.0|  0.4091524046600304|             120.0|            55.0|9.796491935483868|                0.0|   0.506758958686583|                 0.0| 0.4884661578947222| 0.7371591575292953|            16.0|              30.0|139.1452599388379|  0.4838445299068336|38.8348594847775|0.9866770743020669|25.46104914985511| 0.47954800041801254| 0.49055292792469574|           120.0|13.177351247600768|             90.0|                 0.0|  0.7068190041928392|9.539477732793522|  0.4579845075940477|              8.0|0.49333853715103343|  0.4708701645239077| 0.14150301184288613|0.17591416867893866|            13.0| 0.16407125369889924| 0.14647763386007445|13.949328214971208|  0.4602773778694809|             9.9|3.4959720063757715|31.112068965517242|                 0.0|0.24126041117207714|              12.6|            72.0|0.48486335344055065|0.45745215253325033|            287.0|  0.4343233352150944| 9.375520512820508|33.100986193293885| 0.08351638591410156| 5.296645179203497|               0.0| 0.04175819295705078|160.4163621135982|            137.0|              8.0| 0.46799099320339343|104.03693830921554|  0.0302482200664027|              12.6|             137.0| 0.3720366581314043|               1.1|             16.75| 33.17546745562131| 0.4987639065100168|  0.8717888907392212|1.4453931203931218|                 0.0|138.75297937600118|0.1363245068214134|0.7269868524702858|85.00530303030303|  0.4866650863530708| 0.876945766580447|  0.0911977288017119|1.4776412776412784|2.093508562325766|             90.0|                 0.0| 16.14547301843629|              0.0| 0.9936062936747827|[0.04175819295705...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[1.14595677712709...|[0.90820510505468...|       0.0|\n",
            "|190933.0|2179-05-06|{2179-05-05 00:00...|                0.0|             8.0|             153.0|               7.0|                 0.0|0.057278801648846335|  0.5677343256979304|             116.0| 79.20833333333333| 0.5500704038677933|             19.0|             56.0|0.38626031753797635|              4.3|              0.0| 0.09675591595982397|            88.0|               2.1|              9.9| 0.3034253128759712|               0.0|                0.0| 0.8015914916790224|             190.0|0.42687494916218766| 0.4007957458395112|               0.0|                1.3|              15.5|              32.3|              1.5|0.06099136445681324| 0.4268135584383741|               1.5|             0.0|   0.269874854997331|             98.4|                0.0| 0.6301718789138533| 0.8536271168767482|             29.9|  0.5398417522311024|             102.0|               1.3| 99.03333333333332| 0.30065261692383516|0.004492087021199578| 0.6626731324989932|               0.0|  0.7561972406006011|             3.05|0.005037189085355657|              9.9|15.184741976368544| 9.526188318991437|              4.3|              29.9|               2.1| 0.9464621090323675|               5.1|             98.0|             83.0|  0.6280738235650517|                0.0|  0.2701707007750812|           120.0|                0.0|               2.7|               2.1|  0.6219013796996995|             30.0|           100.0| 0.8976366291296707|           100.0| 0.04421492552303007|               1.3|             0.0|                0.0|            65.0|  0.924140058910544|                 0.0|            19.0|             190.0|  0.2609818352397814|               1.3|               4.3|  0.5233774772761552|            190.0|            19.0|  0.5219636704795628|0.9738948671571004|              15.5| 1.5231546211727816| 0.3865822674435661| 0.3107236091383373|              33.0|           102.0|             33.3|129.66666666666666|             29.9|              34.0|  0.8342110872286047|  0.946286246363002|               2.7|112.08333333333333|              3.05|                0.0|              29.9|             15.5|               2.7|  0.1349374274986655|              30.0|               9.9|             8.0|             102.0|              29.9|  0.537929970544728|             160.0|  0.3091690311323449|  0.9453009530699499|0.15458451556617245|  0.8334373893315923|            28.0|              5.1|  0.664149413571955|0.060887183075146165|                 0.0|              66.0|             154.0|             34.0|   0.951622042020088|               1.3|             190.0|  0.0857324151258644|            69.375|              8.0| 78.20833333333333| 9.251032224688347|            55.0|0.9745232284758952|             116.0|   0.67170117285609|             109.0|              8.0|0.5130525664214498|             116.0|             116.0|             98.0| 18.55322673343433|           100.0| 0.491807068783402|              12.9|             5.1|  0.8645313486041392|85.00246212121212|                 0.0|              8.0|  0.5225219629359406|                0.0|  0.4888857989399821| 0.8998591922644134|                 0.0|              29.9|              12.9|             8.0|                0.0|58.333333333333336|              4.3|             190.0|               2.7| 0.8032551337067798|               0.0|0.15032630846191758|               1.5|  0.526856876818499|            94.0|0.15081504517481623| 0.9571337924370678|              32.3|             3.05|              0.0|             8.0|             92.0| 0.03049568222840662|  0.8475698591732508|  0.5511816854351647| 0.9578671679188786|           102.0|             116.0|             33.3|                0.0| 0.6746537350020136|   0.422268861898241|               0.0|  0.5641055546303895| 0.13280217786032092|  0.6203836768157764| 0.6068506257519424|               0.0|           100.0|            34.0|  0.7731645348871322|             92.0|             19.0|            139.0| 0.4237849295866254|             99.8|             98.0|               0.0|              15.5|             2.1|              4.3|             33.3|            34.0|0.31403691178252585|             2.1|0.42852561497701547|               7.0|  0.9977539564894002|               7.0| 0.4016275668533899|             116.0|             33.3|                0.0|0.47265047653497494|              0.0| 8.489270188498734|  0.2612609814679703|                1.3|              0.0|               0.0|0.002728073736398...|  0.3762146866068509|               4.3| 4.667968568398416|            34.0|           102.0|84.99962121212121|              33.3|              5.1|             32.3|             90.0|                0.0|              0.0|              2.7|            139.0| 0.24444289946999104|              7.0|  0.5208562344507215|                0.0| 0.4784520629105555| 0.956904125821111|                0.0|  0.9713605991755768|              9.9|             96.8| 0.7524293732137018|  0.5267689454838163|0.31508593945692664|                0.0|             160.0| 0.3177504216415489|0.19263200419169912|            105.0|  0.2616887386380776|            90.0| 0.26042811722536074|             120.0|            60.0|              9.9|                0.0| 0.47770299815503436|                 0.0| 0.9275073699266075| 0.6355008432830977|            19.0|              30.0|            139.0| 0.30163009034963245|            33.3|0.9866770743020669|             34.0|  0.7583789029340601|  0.8649146496124593|           120.0|               7.0|             90.0|                 0.0|  0.0842656641622429|              5.1| 0.08842985104606015|              8.0|0.49333853715103343|  0.6214472182766746|  0.9335989110698395| 0.2699208761155512|             8.0| 0.41710554361430235|  0.2111344309491205|               7.0| 0.37918945146703004|             9.9|               2.7|              19.0|                 0.0| 0.9974814054573222|              15.5|           102.0| 0.8570512299540309| 0.5362463150366963|            190.0| 0.41671869466579614|               5.1|              33.0|0.039727230996929895|               0.0|               0.0|0.019863615498464948|            160.0|            139.0|              8.0|0.030443591537573082|             102.0|                 0.0|              15.5|             139.0|                0.0|               1.5|18.708333333333332|              33.0| 0.9036839979041504|  0.8717888907392212|               1.5|                 0.0|             139.0|               0.0|0.7725206350759527|85.00530303030303|  0.9554059963100687|               0.0|                 0.0|               1.5|              2.1|             92.0|                 0.0|              12.9|2.357022603955158| 0.7592326463684471|[0.01986361549846...|(166,[0,2,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[0.05857647161605...|[0.52925478375846...|       0.0|\n",
            "|153202.0|2195-04-29|{2195-04-28 00:00...|  0.408248290463863|           8.625|             140.0|              10.5|0.047140452079103105| 0.04162341526443389|  0.8431024015484478|             164.0| 68.08333333333333|0.27374663159948043|              8.5|             56.0|  0.419016389184504|            3.925|              0.0|  0.1659286917366149|            74.0|               1.8|             10.5| 0.3371881483049508|0.8640987597877147| 0.6057020719792857| 0.6712194574650666|              66.0|  0.696818165345563| 0.3356097287325333| 1.920286436967152|0.42500000000000004|              15.7|              31.2|              1.4|0.06902322717598802|0.32575197775339026|1.3333333333333333|             0.0|0.001768947919892...|             98.3| 1.9362047641943474|0.43838383105788703| 0.6515039555067805|             29.1|0.008098527062300609|              99.0|               0.5| 99.76666666666667|  0.8494628281506669|  0.9525129301560137|0.30278713523977224|               1.5| 0.40557024194924596|3.276666666666667|  0.6194900007990161|             11.7|14.522013940527977| 6.861223570828231|              4.6|              29.1|1.9749999999999999| 0.8490206736979797|10.033333333333333|             94.0|             84.0|  0.6052527037538802| 0.6057020719792857|    0.12404305925363|           120.0|                0.5|              3.45|             1.975|   0.797214879025377|             30.0|           100.0| 0.5532977763525597|           100.0|  0.9349046060342232|               0.5|             1.5| 0.8178562764256864|            83.0|  0.608193204587065| 0.10897247358851685|             7.0| 72.66666666666667|0.008790211551509018|               0.4|               4.6|0.017159653494764907|72.66666666666667|             8.5|0.017580423103018036|0.9738948671571004|              14.7|  2.196904387744011| 0.9998288078963181|0.29614535867609537|              35.3|           104.0|             32.6|             233.0|             33.2|              28.0|0.035786285288719695| 0.8493151428602235|               4.0| 96.33333333333333|               3.1|                0.0|              33.2|             14.7|               3.1|8.844739599462277E-4|              35.0|10.499999999999998|             8.8|            102.25|30.600000000000005| 0.3040966022935325|             160.0|  0.9110001498850737| 0.04067212149795718|0.45550007494253686|0.035451976506521564|            28.0|             12.2| 0.3047091003597849| 0.07066746085710292| 0.12990381056766592|              57.0|             292.0|             31.0| 0.08296434586830745|               0.4|              77.0| 0.08925251206302239| 61.09090909090909|              8.8|              96.5| 6.123724356957945|            60.0| 0.981301814901793|             244.0| 0.6094182007195698|             190.0|              8.0|0.5130525664214498|             164.0|            200.25|             93.0| 43.15089802078283|           100.0|0.4906509074508965|              17.7|             7.5|  0.3137951969031044|             85.0| 0.20237478982214055|              8.5|  0.9689128468503373|  0.408248290463863| 0.15261931459751882| 0.5474932631989609| 0.10897247358851685|30.600000000000005|              18.1|             8.5| 0.1699673171197603|              60.0|            3.925|              77.0|               4.0| 0.6734540407572737|35.765730804780155| 0.5752685859246666|               1.3|0.42465757143011174|            92.0| 0.5644714692735042| 0.9553737439684888|31.900000000000002|             3.56|1.920286436967152|           8.625|             90.0| 0.03451161358799401| 0.29599038671453903| 0.27664888817627986| 0.9569803168927646|          102.25|            200.25|35.86666666666667|  1.845715759987618| 0.6055742704795445|6.188307332960431E-4|               2.5|  0.8381016513907719|0.004238520562854932|  0.7950601880596517| 0.6743762966099016|  0.82915619758885|           100.0|            28.0|3.423842073637671...|             90.0|              7.0|            137.0| 0.8520048066427305|            100.5|93.33333333333333|  0.82915619758885|15.199999999999998|             1.8|              3.0|35.86666666666667|            29.5| 0.3026263518769401|             2.1| 0.3279293138286811|              11.0|  0.5237435349219932|              10.0|0.33672702037863683|             244.0|             38.4| 0.8640987597877147|0.02033606074897859|4.784233364802441|  4.99917348540637| 0.48445642342516865|0.42500000000000004|4.784233364802441| 1.118033988749895|                 0.0|  0.5799360825996185|               3.0|3.2121189787013393|            31.0|            99.0|             85.0|              32.6|              7.5|             32.8|             90.0| 1.9362047641943472|1.118033988749895|              3.1|            137.0| 0.07630965729875941|             10.5|  0.9624065679270641|                0.5|0.48475960000217266|0.9695192000043453|                0.0|   0.979188292367783|              9.7|96.41666666666667| 0.8401278348007629| 0.42451033684898987| 0.7808080844710565| 0.6683312551921131|             160.0| 0.7828239690976695| 0.3955696577933736|             86.0|0.008579826747382453|            90.0| 0.48120328396353207|             120.0|            60.0|             11.7|0.12990381056766592|0.020152374101803705|                 0.0| 0.6051932225998237| 0.4343520618046611|            10.0|              32.5|            139.0|  0.8710570614529914|            38.4|0.9866770743020669|             29.5|6.042135353805138E-4|   0.937978470373185|           120.0|              10.0|             90.0|                 0.0|  0.0860393662144708|             12.2| 0.13019078793155348|              8.0|0.49333853715103343|  0.5922907173521907|  0.9978807397185725| 0.9959507364688497|            14.0|0.017893142644359847|   0.999690584633352|              11.0|  0.9996978932323097|             9.7|              3.45|              10.0|0.047140452079103105|0.30974500039950803|              15.7|           107.0| 0.6558586276573622|0.30259661129991183|             66.0|0.017725988253260782|10.033333333333333|              33.3|4.989014219217635E-4|35.765730804780155|2.4239545283597113|  0.9997505492890392|            160.0|           138.25|              8.0| 0.03533373042855146|             104.0|0.043301270189221926|15.199999999999998|             139.0|  1.845715759987618|1.3333333333333333|            23.375|34.266666666666666| 0.8022151711033132|  0.3237966972184563|               1.3| 0.33541019662496846|            138.25|0.4714045207910317| 0.838032778369008|             85.0| 0.04030474820360741|2.4239545283597113| 0.33541019662496846|               1.4|              2.1|             90.0|0.043301270189221926|17.933333333333334|              0.0|0.40987962388069654|[0.99975054928903...|(166,[0,3,11,13,5...|[0.99975054928903...|                               0.0|                                0.0|  0.0|[0.76010017918292...|[0.82056798248557...|       0.0|\n",
            "|192399.0|2152-11-20|{2152-11-19 00:00...|                0.0|             8.4|138.94057916509965|               7.0|                 0.0|   0.382950425126365|  0.3529159189500134|             130.0| 74.77826247362239| 0.2888504831712819|             22.0|47.70463975858167|  0.426930727592382|              4.9|              0.0| 0.20718381381747253|78.0369671821954|               1.9|              9.1| 0.3371881483049508|               0.0|                0.0|0.13349940828805268|             189.0|  1.078579312490896|0.06674970414402634|               0.0|                0.4|              13.4|              25.4|              1.1|0.06099136445681324| 0.2362347480348828|               1.1|             0.0| 0.19619776364057873|             96.1|                0.0| 0.9404912526956775| 0.4724694960697656|             26.6|  0.9570763498264294|              94.0|               0.4|              98.0|  0.2899493992878918| 0.22323189276593913|  0.933775530824686|               0.0|   0.499365353901846|              3.6|  0.4825208223441543|              9.1|11.487286830973543| 8.168515431713185|              4.9|              26.6|               1.9| 0.3100940370970886|               5.0|90.84011276681434|97.67732230161715|  0.4344678286732502|                0.0|0.009385393945498236|           120.0|                0.0|               3.0|               1.9|   0.249682676950923|             30.0|           100.0| 0.5813086081360233|           100.0|  0.4334657180999039|               0.4|             0.0|                0.0|            62.0| 0.3988801527810958|                 0.0|            22.0|             189.0|  0.3142024319562725|               0.4|               4.9|    0.63129818205617|            189.0|            22.0|   0.628404863912545|0.9738948671571004|              13.4| 1.3481839637082174| 0.5229352225169951|0.21515138439841197|              34.3|            94.0|             29.2|             147.0|             26.7|              38.0|  0.2828588017908533| 0.3100943452944951|               3.0|117.87633609613528|               3.6|                0.0|              26.7|             13.4|               3.0|   0.472376144412589|              40.0|               9.1|             8.4|              94.0|             26.65| 0.1994400763905479|160.55733211512106|  0.4275832354176189|  0.9377493143624959| 0.7862083822911905| 0.28199288367483494|            18.0|              5.0| 0.9345585982645828|0.060887183075146165|                 0.0|60.782215523737754|             154.0|             38.0|  0.4711329744042347|               0.4|             189.0|0.012774276706124677| 61.39591571522619|              8.4|              68.5| 8.426149773176359|            50.0| 0.981301814901793|             139.0|0.13088280347083456|             140.0|              8.0|0.5130525664214498|             130.0|             134.5|90.55054369714055|               7.0|           100.0|0.4906509074508965|              15.9|             5.0|  0.7058318379000268|             85.0|                 0.0|              8.4|  0.6954431369445988|                0.0| 0.28432187610548393| 0.5777009663425638|                 0.0|             26.65|              15.9|             8.4|                0.0|              50.0|              4.9|             189.0|               3.0|0.13928096576623245|               0.0| 0.1449746996439459|               1.1|0.15504717264724754|            94.0|0.14553486893706977| 0.9936128616469376|              25.4|              3.6|              0.0|             8.4|             90.0| 0.03049568222840662|  0.5323719280239783|  0.2906543040680116| 0.9937482742314291|            94.0|             130.0|             29.2|0.04999999999999894|0.13244893835062796|1.348819913327819...|               5.0| 0.35081975965318957|  0.6825190749297709| 0.24873446274435135| 0.6743762966099016|               0.0|           100.0|            38.0|  0.9541295549660098|             90.0|             22.0|            134.0| 0.7338140359880109|             99.6|90.69301248489731|               0.0|              13.4|             1.9|              4.9|             29.2|            38.0| 0.2172339143366251|             1.9|0.23568464098766218|               7.0| 0.48581197505212126|               7.0|0.06964048288311622|             130.0|             29.2|                0.0|0.46887465718124793|              0.0| 8.132272964076716|  0.3477215684722994|                0.4|              0.0|               0.0|                 0.0|  0.7680859606806065|               4.9| 1.562916611125921|            38.0|            94.0|             85.0|              29.2|              5.0|             25.4|90.01611459265891|                0.0|              0.0|              3.0|            134.0|   0.857839061947258|              7.0|  0.6931015094555795|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.1914752125631825|              9.1|            97.68|0.46382807863878706|  0.1550470185485443| 0.5297543736521613|                0.0|160.30150753768845| 0.5316972155492664|0.47024088066356073|90.91899020346646|   0.315649091028085|90.0066025067144| 0.34655075472778973|             120.0|            50.0|              9.1|                0.0|   0.473873539291878|0.007491553859143...|0.39887236892500944| 0.9366055689014672|            22.0|              35.0|            134.0| 0.29106973787413953|            29.2|0.9866770743020669|             38.0|  0.8465201023477212|0.004692696972749118|           120.0|               7.0|90.00044762757386|                 0.0|0.012503451537141734|              5.0|  0.8669314361998078|              8.0|0.49333853715103343| 0.43030276879682394| 0.34125953746488547| 0.4785381749132147|             9.0| 0.14142940089542666|6.744099566639096...|               7.0|  0.5767399488261393|             9.1|               3.0|              22.0|                 0.0|0.24126041117207714|              13.4|           106.0|0.47136928197532435|0.19943618446250472|            189.0| 0.14099644183741747|               5.0|              34.3|5.867880230609641E-7|               4.5|               0.0|2.933940115304820...|160.4163621135982|            134.0|              8.0|0.030443591537573082|              94.0|                 0.0|              13.4|             134.0|0.04999999999999894|               1.1|            12.125|              34.3| 0.4987639065100168|  0.7016395193063791|               1.1|                 0.0|             134.0|0.1363245068214134|0.7269868524702858|             85.0|   0.947747078583756|               0.0|                 0.0|               1.1|              1.9|             90.0|                 0.0|              15.9|              0.0| 0.4974689254887027|[2.93394011530482...|(166,[0,2,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|  1.0|[-0.0556238447020...|[0.47221672566934...|       1.0|\n",
            "|192031.0|2156-01-13|{2156-01-12 00:00...|                0.0|             8.8|             107.0|              16.0|                 0.0|   0.382950425126365| 0.27995452739864224|             245.0|              69.0| 0.6797969315397088|             83.0|             57.0|  0.426930727592382|              4.5|              0.0|  0.7345681439735754|            57.0|               2.2|              8.8| 0.3371881483049508|               0.0|                0.0| 0.8015914916790224|             208.0| 0.9603240193925283| 0.4007957458395112|               0.0|                3.4|              14.8|              29.2|              1.4| 0.5441683213580897| 0.3584920829189963|               1.4|             0.0|  0.6571337059718874|             96.5|                0.0| 0.5281843266082891| 0.7169841658379926|             26.5|  0.5548448754664719|             102.0|               3.4| 97.46666666666668| 0.04265072686571611|  0.7951496277877806| 0.7827139078451968|               0.0|  0.6072360034596276|             3.01|  0.4825208223441543|              8.8|               0.0|               0.0|              4.5|              26.5|               2.2| 0.9464621090323675|              18.3|             88.0|            107.0|  0.5149651415231561|                0.0|   0.575242294926473|           120.0|                0.0|               5.3|               2.2|  0.3036180017298138|             30.0|           100.0| 0.6392789015831795|           100.0| 0.49445409396101137|               3.4|             0.0|                0.0|            65.0| 0.8890503192515382|                 0.0|            83.0|             208.0|  0.9964707149631455|               3.4|               4.5|0.006206086595056...|            208.0|            83.0|0.007058570073708911|0.9738948671571004|              14.8|  2.724792588294953| 0.9981109669028437|  0.254876925303715|              33.1|           102.0|             31.0|             172.0|             26.5|              26.0| 0.07061754250774531|  0.946286246363002|               5.3|             107.0|              3.01|                0.0|              26.5|             14.8|               5.3|  0.3285668529859437|              30.0|               8.8|             8.8|             102.0|              26.5| 0.4445251596257691|160.55733211512106|  0.3091690311323449|  0.9185874654221396|0.15458451556617245| 0.07042982902042424|            23.0|             18.3|  0.784103490487847|  0.5343214914866725|                 0.0|              69.0|             175.0|             26.0|  0.3672840719867877|               3.4|             208.0|  0.8617935932847937|              57.0|              8.8| 75.70967741935483| 7.458243105351445|            50.0| 0.981301814901793|             245.0| 0.4317930190243059|             169.0|              8.0|0.5130525664214498|             245.0|             245.0|             88.0|               3.0|           100.0|0.4906509074508965|              16.2|            18.3|  0.5599090547972845|             85.0|                 0.0|              8.8| 0.13114797918555343|                0.0| 0.05115272165615324| 0.6404061369205825|                 0.0|              26.5|              16.2|             8.8|                0.0|              50.0|              4.5|             208.0|               5.3| 0.8032551337067798|               0.0| 0.9786746365671419|               1.4|  0.526856876818499|            90.0| 0.9762149801646576| 0.5691032033576031|              29.2|             3.01|              0.0|             8.8|             90.0|  0.7279158393209552|  0.8970388908978291|  0.6803605492084103| 0.5726742796766917|           102.0|             245.0|             31.0|                0.0| 0.4345721843096064| 0.31395121931067227|               0.0| 0.27850623881793624| 0.16274348333623853| 0.30290980149227265| 0.6743762966099016|               0.0|           100.0|            26.0|0.003778066194312...|             90.0|             83.0|            139.0|0.44851944544891453|             99.2|             88.0|               0.0|              14.8|             2.2|              4.5|             31.0|            26.0|0.25748257076157804|             2.2|0.35935662036455807|              16.0|  0.3975748138938903|              16.0| 0.4016275668533899|             245.0|             31.0|                0.0| 0.5407062672889302|              0.0|               0.0|  0.9344260104072233|                3.4|              0.0|               0.0|                 0.0|  0.3476563156502173|               4.5| 2.388863048955856|            26.0|           102.0|             85.0|              31.0|             18.3|             29.2|90.01611459265891|                0.0|              0.0|              5.3|            139.0| 0.02557636082807662|             16.0| 0.13315642569210542|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.1914752125631825|              8.8|96.24137931034483| 0.6953126313004346|  0.5267689454838163| 0.7359078366958555|                0.0|160.30150753768845| 0.7366535148353723| 0.6613725803138346|             69.0|  0.9968969567024717|90.0066025067144|  0.9334217871539473|             120.0|            50.0|              8.8|                0.0|  0.5466423544654097|0.007491553859143...| 0.8865360792227868| 0.5266929703292552|            83.0|              30.0|            139.0|0.047570039670684905|            31.0|0.9866770743020669|             26.0|0.005264404985588896|  0.2876211474632365|           120.0|              16.0|90.00044762757386|                 0.0|  0.8546514406466165|             18.3|  0.9889081879220227|              8.0|0.49333853715103343|    0.50975385060743| 0.08137174166811927| 0.7225775622667641|            15.0|  0.9646912287461273| 0.15697560965533613|              16.0|  0.9973677975072055|             8.8|               5.3|              83.0|                 0.0|0.24126041117207714|              14.8|            85.0| 0.7187132407291161| 0.4432680396113934|            208.0|  0.9647850854897879|              18.3|              33.1|0.001388452382281...|               0.0|               0.0|6.942261911408973E-4|160.4163621135982|            139.0|              8.0|  0.7328392542566637|             102.0|                 0.0|              14.8|             139.0|                0.0|               1.4|              18.6|              33.1| 0.3306862901569173|  0.5570124776358725|               1.4|                 0.0|             139.0|               0.0|0.7269868524702858|             85.0|  0.9067152910691807|               0.0|                 0.0|               1.4|              2.2|             90.0|                 0.0|              16.2|              0.0| 0.6058196029845453|[6.94226191140897...|(166,[0,4,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|  1.0|[1.23977266248503...|[0.92269537275237...|       0.0|\n",
            "|153202.0|2195-04-30|{2195-04-29 00:00...|                0.0|             8.4|             120.0|              12.0|                 0.0| 0.01259737760848169|  0.4049927972222716|             187.0| 72.16666666666667| 0.6797969315397088|              9.0|             56.0|  0.426930727592382|             3.75|4.714045207910316|  0.7525644409036717|            69.0|               2.2|              9.3| 0.9509843869310113|               0.0| 0.1499999999999999| 0.8280376885293362|              77.0| 0.8919137873593111| 0.5859811557353318|               0.0|                0.4|              15.1|              30.4|              1.3| 0.6199638177152004| 0.3873596567133406|               1.3|             0.0|  0.2543187358349703|             98.7|                0.0| 0.9404912526956775| 0.7747193134266812|             28.2|0.009907873611381032|             105.0|               0.4|100.21428571428571|  0.8780959765512513|  0.8670727514831013| 0.2081716340654819|               0.0|  0.9189350272326766|             3.05| 0.29305270223556673|              9.3| 9.604686356149273| 5.983774357005415|              3.9|              28.2|               2.2| 0.7767197448113609|               8.9|             93.0|             95.0|  0.6229405283478351| 0.1499999999999999|  0.9335075430380584|           130.0|                0.0|               3.3|               2.2|  0.4594675136163383|             30.0|           100.0| 0.6392789015831795|            99.0|   0.742773258338693|               0.4|             0.0|                0.0|            95.0| 0.7082352766381776|                 0.0|             9.0|              77.0| 0.12273320750410596|               0.4|               3.9|  0.2437814798147677|             77.0|             9.0| 0.24546641500821192|0.9738948671571004|              15.1| 1.9183326093250879| 0.9285476807510574| 0.3081881343209921|              32.9|           105.0|             33.2|             212.4|             28.2|              27.0|  0.2828588017908533| 0.7765167104772168|               3.3|             106.5|              3.05|                1.0|              28.2|             15.1|               3.3| 0.12715936791748514|              30.0|               9.3|             8.4|             105.0|              28.2| 0.3541176383190888|160.55733211512106|  0.3091690311323449|  0.2539183130095153|0.15458451556617245| 0.28199288367483494|            35.0|              8.9|0.20904204835722584|   0.625578218093795|                 0.0|              64.0|             260.0|             27.0| 0.37628222045183585|               0.4|              77.0|  0.7134994830130421|61.833333333333336|              8.4|            109.48| 8.095035515672555|            60.0| 0.981301814901793|             187.0| 0.4180840967144517|             144.0|              8.0|0.5130525664214498|             187.0|             187.0|             93.0|44.840160570631326|           100.0|0.4906509074508965|              17.5|             8.9|  0.8099855944445432|             85.0|                 0.0|              8.4|  0.8859069447322555|                0.0| 0.05824493960187936| 0.6404061369205825|                 0.0|              28.2|              17.5|             8.4|                0.0|              60.0|             3.75|              77.0|               3.3| 0.8321581944717855|               0.0|0.43904798827562563|               1.3| 0.6117416447613916|            93.0| 0.4344216204281218| 0.6432502584934789|              30.4|             3.05|              0.0|             8.4|             91.0|  0.3099819088576002|   0.798694628619848|  0.6803605492084103| 0.6465904979035804|           105.0|             187.0|             33.2|                0.0| 0.4163432681309638| 6.19464980416478E-4|               0.0|  0.4024593678809968|6.807275681867517E-5|  0.4582737176022218| 0.0980312261379774|               0.0|           100.0|            27.0| 0.14290463849788512|             92.0|              9.0|            140.0|  0.399347314309924|            101.1|             93.0|               0.0|              15.1|             2.2|              3.6|             33.2|            27.0|0.31147026417391754|             2.2|0.38858248780445526|              12.0|  0.5664636242584493|              12.0| 0.5839209027641072|             187.0|             33.2|                0.0|0.12695915650475764|              0.0|  5.30461015427985| 0.44295347236612775|                0.4|              0.0|               0.0|                 0.0|  0.3762146866068509|               3.6| 5.006766255112509|            27.0|           105.0|             85.0|              33.2|              8.9|             30.4|90.01611459265891|                0.0|              0.0|              3.3|            140.0| 0.02912246980093968|             12.0|  0.8829245426316886|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.9937013111957591|              9.3|             96.2| 0.7524293732137018|  0.6116401275943195| 0.5297543736521613|                0.0|160.30150753768845| 0.5316972155492664| 0.6653917172247079|             81.0| 0.12189073990738385|90.0066025067144|  0.4414622713158443|123.33333333333333|            60.0|              9.3|                0.0| 0.12662174821627248|0.007491553859143...| 0.7066539121412764| 0.9366055689014672|             9.0|              30.0|            140.0|  0.8688432408562436|            33.2|0.9866770743020669|             27.0|  0.1620942269935893|  0.5332462284809708|           120.0|              12.0|90.00044762757386|                 0.0|  0.7068190041928392|              8.9|  0.5144534833226139|              8.0|0.49333853715103343|  0.6163762686419842|  0.9999659636215906| 0.9950460631943094|            15.0| 0.14142940089542666|  0.9996902675097917|              12.0|  0.9189528865032054|             9.3|               3.3|               9.0|                 0.0| 0.8534736488822167|              15.1|           128.0| 0.7771649756089105| 0.3533269560706382|             77.0| 0.14099644183741747|               8.9|              32.9|3.950196653134012...|               0.0|               0.0|  0.9999999999999802|160.4163621135982|            140.0|              8.0|  0.3127891090468975|             105.0|                 0.0|              15.1|             140.0|                0.0|               1.3|            23.375|              32.9|  0.667304141387646|  0.8049187357619936|               1.3|                 0.0|             140.0|               0.0|0.7269868524702858|             85.0| 0.25324349643254496|               0.0|                 0.0|               1.3|              2.2|             90.0|                 0.0|              17.5|              0.0| 0.9165474352044436|[0.99999999999998...|(166,[0,3,11,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[0.80946798609341...|[0.83464833509137...|       0.0|\n",
            "|192031.0|2156-01-15|{2156-01-14 00:00...|0.13065475397959778|            8.35|138.94057916509965|              17.5|  0.0148147169883393| 0.04162341526443389|0.040297070646207224|             214.0| 74.77826247362239| 0.6624985272602849|             75.0|47.70463975858167|  0.426930727592382|              3.7|              0.0| 0.20718381381747253|78.0369671821954|               2.1|              7.1| 0.3371881483049508|               0.0|0.09999999999999987|0.33219014566891736|             186.0| 0.4323350324076383| 0.8339049271655413|               0.0|               3.05|16.326121062384175|              28.9|1.477589339794065|0.14923423582698966| 0.4600024796048131|1.4608241195741203|             0.0| 0.19619776364057873|             96.5|                0.0| 0.9942067011828839|0.48651583403086374|             21.9| 0.05588986633636901|             108.0|               3.1| 97.34444444444445| 0.20699158713329455| 0.22323189276593913| 0.1734475277599536|               1.0| 0.04749156811343164|             2.44|0.005037189085355657|              7.1|11.487286830973543| 8.168515431713185|              3.8|              21.9|2.1500000000000004| 0.3896881429944603|              15.0|             90.0|97.67732230161715| 0.47280115065897854|0.09999999999999987|  0.4707367688966103|           120.0|                0.5|3.9499999999999997|2.1500000000000004| 0.02374578405671582|             35.0|           100.0|  0.672738960713646|           100.0|  0.5352743488716517|               3.1|             1.0|                0.0|            62.0|0.48908889201931066|0.050000000000000044|            74.0|             186.0|  0.9993589769724416|               3.0|               3.8|0.001063912774962...|            186.0|            75.0|0.001282046055116901|0.9738948671571004|16.087061323618695| 1.9418633662885072| 0.9834743263700748| 0.4142515026977065|              32.2|           108.0|36.91319672131147|209.66666666666666|             25.1|              20.0| 0.03741613870152961|  0.389430211420007|               4.1|117.87633609613528|              2.44|                0.0|              25.1|16.04014206300184|               3.8|   0.472376144412589|              35.0|               7.1|             8.6|             108.0|23.900000000000002| 0.4584105459263105|160.55733211512106| 0.42752968906694533|  0.9151306816627606| 0.7862351554665273| 0.03730755191194887|            22.0|             15.0|0.17416298723263302| 0.14237693807153542|                0.25|60.782215523737754|             249.0|             20.0|  0.4711329744042347|               3.0|             186.0| 0.16395339086435168| 61.39591571522619|              8.6| 66.79166666666667|3.2529367073803055|            60.0| 0.981301814901793|             251.0|0.34832597446526603|             163.0|              8.0|0.5130525664214498|             214.0|             232.5|             90.0|35.490217744549774|           100.0|0.4906509074508965|              16.4|            15.0| 0.08059414129241445|             85.0|                 0.0|              8.1|  0.5775513041973412|0.12965952398334926|3.628436036180445E-5| 0.6750029454794302|0.050000000000000044|23.900000000000002|              16.4|             8.1|                0.0|              60.0|              3.7|             186.0|               4.1| 0.3412361445026926|               0.0| 0.8965042064333527|1.4457904300423992| 0.8052848942899965|            92.0| 0.8902648724442614|0.08197669543217584|              28.9|             2.44|              0.0|            8.35|             92.0|  0.9253828820865052|  0.4872208418737004|   0.663630519643177|0.08410314387031852|           108.0|             214.0|37.70331834880121| 1.4236104336041757| 0.3468950555199072|  0.1360464926152493|               0.0|0.040581944679715466|0.046959848095491724| 0.02369477797914215| 0.6743762966099016|               0.5|           100.0|            20.0|0.033051347259850275|             92.0|             74.0|            141.0| 0.2436104209368502|             98.1|             90.0|               0.5| 16.17945696932262|             2.1|              3.6|37.83908909055424|            20.0|0.41496732739917513|             2.2| 0.4594330506661511|              18.0| 0.48581197505212126|              17.0| 0.8293819277486537|             214.0|38.69393271461717|                0.0| 0.4575653408313803|              0.0| 8.132272964076716|  0.7112243479013294|               3.05|              0.0|               0.0|                 0.0| 0.06976359570043217|               3.6| 2.668871174473532|            20.0|           108.0|             85.0|36.781171693735494|             15.0|             28.9|90.01611459265891|                0.0|              0.0|              3.8|            141.0|  0.9999818578198191|             17.5|  0.5824817849974406|                0.5|0.48009629871768866|0.9530305562536405|0.12368084276523614|   0.979188292367783|              7.1|            99.25|0.13952719140086434|  0.8051559285027698|  0.502896649408558|                0.0|160.30150753768845| 0.5058357084693346| 0.9284301130900702|90.91899020346646|  0.9994680436125188|90.0066025067144|  0.7087591075012797|             120.0|            60.0|              7.1|               0.25| 0.46240105402401876|0.007491553859143...| 0.4884661578947222| 0.9883285830613309|            76.0|              35.0|            142.0|  0.2194702551114771|38.8348594847775|0.9866770743020669|             20.0|4.305652646541797...| 0.23536838444830516|           120.0|              17.0|90.00044762757386|                 0.0| 0.16820628774063703|             15.0|  0.9294513022566966|              8.0|0.49333853715103343|  0.4708701645239077|0.023479924047745862| 0.9720550668318155|            14.0|  0.9812919306492351| 0.06802324630762464|              18.0|  0.9997847173676729|             7.1|3.9499999999999997|              76.0|0.014632153041738868| 0.9974814054573222|16.373460837887045|            74.0|0.48486335344055065|0.45745215253325033|            186.0|  0.9813462240440256|              15.0|              32.2|3.531888631677236E-8|              18.5|0.8705195762144462|1.765944315838618E-8|160.4163621135982|            141.5|              8.0|  0.9288115309642323|             108.0|0.050000000000000044|16.227216656547245|             142.0| 1.4236104336041757|1.4611558651322438| 17.91304347826087|              32.2| 0.4642150565450351| 0.08116388935943093|1.4453931203931218|  0.1499999999999999|             141.5|               0.0|0.7269868524702858|             85.0|  0.9248021080480375| 0.876945766580447|  0.1499999999999999|1.4776412776412784|              2.2|             92.0|0.050000000000000044|              16.4|              0.0| 0.0473895559582843|[1.76594431583861...|(166,[0,4,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|  1.0|[0.83495717880331...|[0.84156440246684...|       0.0|\n",
            "|193970.0|2106-08-11|{2106-08-10 00:00...|0.13065475397959778|             9.1|138.94057916509965|              13.0|  0.0148147169883393|0.021539254199842435|  0.5007014305921953|             130.0| 74.77826247362239| 0.2888504831712819|             14.0|47.70463975858167|  0.426930727592382|              3.9|              0.0| 0.20718381381747253|78.0369671821954|               1.9|9.720783890168976| 0.2761968333658741|0.0720476814472478|                0.0|0.24844064562599855|             215.0| 0.6262764742685327| 0.8757796771870008|               0.0|                1.0|16.326121062384175|              30.2|1.477589339794065| 0.8256396060702549| 0.4600024796048131|1.4608241195741203|             0.0| 0.19619776364057873|             97.8|                0.0|0.29471885349913585|0.48651583403086374|28.88809523809525|  0.4102348126700548|             111.0|               1.0| 99.16666666666667|  0.2715464826535922| 0.22323189276593913| 0.3807488946785406|               0.0| 0.45219772949982334|3.250759740695953|   0.026695742333049|9.798362619808303|11.487286830973543| 8.168515431713185|              3.9|28.889421157684648|               1.9| 0.8813192766007132|              14.3|             92.0|97.67732230161715| 0.47280115065897854|                0.0|  0.9809592404305372|           120.0|                0.0|               1.2|               1.9|  0.5286978729187907|             30.0|           100.0| 0.5813086081360233|           100.0|  0.4536919046531941|               1.0|             0.0|                0.0|            74.0|0.48908889201931066|                 0.0|            14.0|             215.0| 0.18382394812673275|               1.0|               3.9| 0.36712102996921425|            215.0|            14.0|  0.3676478962534655|0.9738948671571004|16.087061323618695|  0.877900939270256| 0.5229352225169951| 0.4142515026977065|              32.9|           111.0|36.91319672131147|             123.0|29.72134920634922|              18.0|  0.6188162389705184| 0.8814588626735432|               1.2|117.87633609613528|3.2267190648931874| 0.9797958971132712|29.732255489021973|16.04014206300184|               1.2|   0.472376144412589|              35.0|  9.71992725924236|             9.1|             111.0|29.305063649533878| 0.4584105459263105|160.55733211512106|  0.9110001498850737|  0.8660768673410002|0.45550007494253686|  0.6178960502701973|            34.0|             14.3|0.38176365461985073|  0.8331874204840826|                 0.0|60.782215523737754|             149.0|             18.0|  0.4711329744042347|               1.0|             215.0| 0.17058632694447423| 61.39591571522619|              9.1|             86.12| 7.895922998611372|            45.0|0.9676197184512532|             130.0| 0.7635273092397015|             108.0|              8.0|0.5130525664214498|             130.0|             130.0|             92.0|18.457157599876172|           100.0|0.4838098592256266|              16.0|            14.3| 0.47109294943321767|             85.0|0.022153573700935885|              9.1|0.060244296801609754|0.12965952398334926|6.850889715508595E-4| 0.5777009663425638|                 0.0| 29.31268022684791|              16.0|             9.1|                0.0|              48.0|              3.9|             215.0|               1.2|  0.256797006526039|               0.0| 0.8642267586732039|1.4457904300423992| 0.4407294313367716|            97.0| 0.8572645277239717|0.08529316347223712|              30.2|3.274385328496573|              0.0|             9.1|             91.2| 0.41281980303512744|   0.798694628619848|  0.2906543040680116| 0.0868768492027246|           111.0|             130.0|37.70331834880121| 0.3685342915673636| 0.7614977893570812|7.18620931537853E-13|               2.5|  0.4983362270214471|  0.0801488656603275|  0.5276163794601939| 0.5523936667317482|               0.0|           100.0|            18.0|  0.9541295549660098|             92.0|             14.0|            138.0|  0.399347314309924|             99.7|             92.0|               0.0| 16.17945696932262|             1.9|              3.9|37.83908909055424|            18.0|0.41496732739917513|             1.9| 0.4594330506661511|              13.0| 0.48581197505212126|              13.0| 0.8716014967369805|             130.0|38.69393271461717|0.07060400796808293| 0.5669615663294999|              0.0| 8.132272964076716|0.030122148400804877|                1.0|              0.0|               0.0|                 0.0|  0.5043438780045272|               3.9| 2.512050954897213|            18.0|           111.0|             85.0|36.781171693735494|             14.3|             30.2|90.01611459265891|                0.0|              0.0|              1.2|            138.0|  0.9996574555142246|             13.0|0.060308485894252806|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|0.010769627099921218|9.644677419354842| 98.8076923076923|0.46473433340591286|  0.4406596383003566| 0.8526405732504321|                0.0|160.30150753768845| 0.8527168007896625| 0.7961109513546751|90.91899020346646| 0.18356051498460713|90.0066025067144|0.030154242947126403|             120.0|            60.0|9.796491935483868|                0.0|  0.5731893363862514|0.007491553859143...| 0.4884661578947222|  0.294566398420675|            14.0|              32.5|            138.0|  0.2854709445520568|38.8348594847775|0.9789360719579988|             18.0|  0.9770627723234001|  0.4904796202152686|           120.0|              13.0|90.00044762757386|                 0.0|  0.1737536984054492|             14.3|  0.9073838093063882|              8.0| 0.4894680359789994|  0.4708701645239077|  0.9599255671698362| 0.2051174063350274|            23.0|  0.3094081194852592|  0.9999999999996407|              13.0|     0.5114686138383|9.64237220447285|               1.2|              14.0|0.014632153041738868| 0.9866521288334755|16.373460837887045|           103.0|0.48486335344055065|0.45745215253325033|            215.0| 0.30894802513509867|              14.3|              32.9|   0.729549274173344|               0.0|0.8705195762144462|   0.635225362913328|160.4163621135982|            138.0|              8.0|  0.4165937102420413|             111.0|                 0.0|16.227216656547245|             138.0| 0.3720366581314043|1.4611558651322438|             27.36|              32.9| 0.6019445243226624|  0.4707463743072148|1.4453931203931218|                 0.0|             138.0|               0.0|0.7269868524702858|             85.0|  0.8536213272274973| 0.876945766580447|                 0.0|1.4776412776412784|              1.9|             90.0|                 0.0|              16.0|              6.0|0.45356404462486793|[0.63522536291332...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|  1.0|[0.90816159608254...|[0.86012435408747...|       0.0|\n",
            "|190933.0|2179-05-04|{2179-05-03 00:00...|0.13065475397959778|             7.7|             137.0|               8.0|  0.0148147169883393| 0.04162341526443389|  0.2357680912969468|             123.0| 76.23076923076923| 0.2888504831712819|             24.0|             50.0|  0.419016389184504|              4.0|              0.0|  0.4713917759958851|            80.0|               1.9|              8.6| 0.9431797313702612|               0.0|                0.0| 0.8280376885293362|             128.0|0.29101779674908385| 0.5859811557353318|               0.0|                1.1|16.326121062384175|              32.6|1.477589339794065|0.11002043007475264| 0.4600024796048131|1.4608241195741203|             0.0|  0.3834754873861216|             98.0|                0.0| 0.3688919952001902|0.48651583403086374|             26.2|  0.7742023475313612|             105.0|               1.1| 98.34444444444445| 0.27950583694201114| 0.12104109764211429|  0.451174902920182|               0.0| 0.47011793018534964|             2.64| 0.29305270223556673|              8.6|13.476310576176335| 8.172692298642108|              4.0|              26.2|               1.9|   0.56044520340909|               4.9|             99.0|             86.0| 0.47280115065897854|                0.0| 0.20638593804862984|           125.0|                0.0|               3.1|               1.9| 0.23505896509267482|             30.0|           100.0| 0.5813086081360233|           100.0| 0.04421492552303007|               1.1|             0.0|                0.0|            66.0|0.48908889201931066|                 0.0|            24.0|             128.0|  0.3520697403198724|               1.1|               4.0|  0.7081070364697271|            128.0|            24.0|  0.7041394806397449|0.9738948671571004|16.087061323618695|  2.114762923408253|  0.454080366485757| 0.4142515026977065|              32.9|           105.0|36.91319672131147|             140.0|             28.1|              27.0|  0.6880850697254509| 0.5605050419662186|               3.1|113.34615384615384|              2.64|                1.0|              28.1|16.04014206300184|               3.1|  0.1917377436930608|              30.0|               8.6|             7.7|             105.0|26.899999999999995| 0.4584105459263105|             160.0|  0.3091690311323449|  0.5111966203433471|0.15458451556617245|  0.6872013059321129|            22.0|              4.9|  0.452366173438544| 0.11023924458650793|                 0.0|              56.0|             148.0|             27.0|  0.7643041120020575|               1.1|             128.0|  0.7134994830130421|  65.3076923076923|              7.7| 82.53333333333333| 8.023853327561653|            60.0| 0.986777781674111|             123.0|  0.904732346877088|             131.0|              8.0|0.5130525664214498|             123.0|             123.0|             99.0|  6.97614984548545|           100.0|0.4933888908370555|              12.9|             4.9|  0.4715361825938936|             85.0|                 0.0|              7.7|   0.757462028133137|0.12965952398334926|0.031742700748989904| 0.5777009663425638|                 0.0|26.899999999999995|              12.9|             7.7|                0.0|              60.0|              4.0|             128.0|               3.1| 0.8321581944717855|               0.0|0.13975291847100557|1.4457904300423992| 0.2802525209831093|            91.0| 0.1403805125425674| 0.6432502584934789|              32.6|             2.64|              0.0|             7.7|             91.0| 0.05501021503737632|   0.798694628619848|  0.2906543040680116| 0.6465904979035804|           105.0|             123.0|37.70331834880121|  0.852447456836296|  0.902349805840364|1.603939058765450...|               0.0| 0.23471809842150815|  0.7797246007836699| 0.23385876595952015|0.11364053725947755|               0.0|           100.0|            27.0|   0.908160732971514|             92.0|             24.0|            136.0|  0.399347314309924|             99.0|             99.0|               0.0| 16.17945696932262|             1.9|              4.0|37.83908909055424|            27.0|0.41496732739917513|             1.9| 0.4594330506661511|               8.0|  0.9394794511789428|               8.0| 0.5839209027641072|             123.0|38.69393271461717|                0.0|0.25559831017167356|              0.0| 6.407743097037609|  0.3787310140665685|                1.1|              0.0|               0.0|                 0.0| 0.13640873108917484|               4.0| 3.186778240724565|            27.0|           105.0|             85.0|36.781171693735494|              4.9|             32.6|             90.0|                0.0|              0.0|              3.1|            136.0|0.015871350374494952|              8.0|  0.7548975237528397|                0.0|0.48475960000217266|0.9695192000043453|                0.0|   0.979188292367783|              8.6|96.16666666666667| 0.2728174621783497|   0.280222601704545| 0.1844459976000951|                0.0|             160.0|0.18697084018903326| 0.1397136135656805|             92.0| 0.35405351823486353|            90.0| 0.37744876187641985|             125.0|            60.0|              8.6|                0.0|  0.2571554357993772|                 0.0| 0.4884661578947222| 0.3739416803780665|            24.0|              30.0|            136.0|  0.2807610250851348|38.8348594847775|0.9866770743020669|             27.0|  0.8891102789193863|   0.896807030975685|           125.0|               8.0|             90.0|                 0.0|  0.7068190041928392|              4.9| 0.08842985104606015|              8.0|0.49333853715103343|  0.4708701645239077|  0.6101376996081651| 0.3871011737656806|             9.0| 0.34404253486272546|8.019695293827252E-6|               8.0| 0.44455513945969316|             8.6|               3.1|              24.0|0.014632153041738868| 0.8534736488822167|16.373460837887045|           100.0|0.48486335344055065|0.45745215253325033|            128.0| 0.34360065296605646|               4.9|              32.9|  0.4035172653727185|               0.0|0.8705195762144462| 0.20175863268635924|            160.0|            136.0|              8.0| 0.05511962229325396|             105.0|                 0.0|16.227216656547245|             136.0|  0.852447456836296|1.4611558651322438|15.333333333333334|              32.9| 0.9301431932171598|  0.4694361968430163|1.4453931203931218|                 0.0|             136.0|               0.0| 0.838032778369008|             85.0|  0.5143108715987544| 0.876945766580447|                 0.0|1.4776412776412784|              1.9|             90.0|                 0.0|              12.9|              0.0| 0.4677175319190403|[0.20175863268635...|(166,[0,2,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[1.09230240377862...|[0.89885847354927...|       0.0|\n",
            "|107462.0|2149-03-31|{2149-03-30 00:00...|                0.0|             8.6|             158.0|              14.0|                 0.0| 0.28527572776766313|  0.6465908663186931|             226.0| 79.08695652173913| 0.9319952880517142|             20.0|             40.0|0.38626031753797635|              4.2|              0.0| 0.11249775635899914|            81.0|               2.5|             10.2| 0.3034253128759712|               0.0|                0.0| 0.9242200327996876|             174.0| 0.5878397362849472| 0.4621100163998438|               0.0|                1.1|              16.6|              29.9|              1.5| 0.9558889475438066| 0.5379329597891574|               1.5|             0.0| 0.15940566981918122|             97.0|                0.0| 0.7242968595418335| 0.9241340804216851|             31.9| 0.00536638992872238|             103.0|               1.1| 97.96666666666665|  0.5369463042591698| 0.10467086171649842| 0.5944280559604681|               0.0|  0.4263476888853164|             3.41|  0.3738713374251535|             10.2| 20.43689474129244|12.279049118680941|              4.2|              31.9|               2.5| 0.7767197448113609|               6.9|             94.0|             87.0|  0.4430364437634935|                0.0|  0.8533746712047077|           120.0|                0.0|               2.7|               2.5|  0.7868261555573418|             40.0|           100.0|0.13656657361269778|            99.0| 0.41341241113830723|               1.1|             0.0|                0.0|            73.0|  0.924140058910544|                 0.0|            20.0|             174.0|  0.2781970402192187|               1.1|               4.2|  0.5582792758189525|            174.0|            20.0|  0.5563940804384374|0.9680307246992478|              16.6|  2.421855614066333| 0.9923988721345066|0.21937954559340883|              31.9|           103.0|             29.4|             225.5|             31.9|              27.0|  0.6880850697254509| 0.7765167104772168|               2.7|             124.0|              3.41|0.06445004758462232|              31.9|             16.6|               2.7|  0.9202971650904094|              45.0|              10.2|             8.6|             103.0|              31.9|  0.537929970544728|             160.0|8.641555893638878E-5|  0.8255206810795768| 0.9999567922205318|  0.6872013059321129|            36.0|              6.9| 0.5958616702270787|   0.946792473534848|                 0.0|              55.0|             290.0|             27.0|  0.9437511218205005|               1.1|             174.0|  0.7134994830130421| 65.70833333333333|              8.6| 85.83333333333333|7.7549267494212275|            50.0|0.9771005412364924|             226.0| 0.8082766595458425|             191.0|              8.0| 0.515984637650376|             226.0|             226.0|             94.0| 38.16084380618437|           100.0|0.4885502706182462|              15.8|             6.9|  0.7068182673626138|             85.0|                 0.0|              8.6|  0.5225219629359406|                0.0|9.720227269803277...|0.13600942389657175|                 0.0|              31.9|              15.8|             8.6|                0.0|              50.0|              4.2|             174.0|               2.7| 0.9239600917072498|               0.0| 0.2684731521295849|               1.5| 0.6117416447613916|            90.0| 0.2670040526736528| 0.6432502584934789|              29.9|             3.41|              0.0|             8.6|90.44908692476263|  0.5220555262280967| 0.37714868718356476|  0.9317167131936511| 0.6465904979035804|           103.0|             226.0|             29.4|                0.0| 0.8111438880790638|9.941391251594837...| 2.357022603955158|  0.6426572428052503|  0.6378248271353548|  0.7853276039752664| 0.6068506257519424|               0.0|           100.0|            27.0|0.015202255730986752|90.51460920379839|             20.0|            140.0|0.18857434359178238|             98.5|             94.0|               0.0|              16.6|             2.5|              4.2|             29.4|            27.0|0.22151822188174675|             2.5| 0.5409441735152294|              14.0|  0.9476645691417508|              14.0| 0.4619800458536249|             226.0|             29.4|                0.0| 0.4127603405397884|              0.0|10.982862281249314|  0.2612609814679703|                1.1|              0.0|               0.0|                 0.0|  0.6445091313191611|               4.2|  4.24575847503781|            27.0|           103.0|             85.0|              29.4|              6.9|             29.9|90.01611459265891|                0.0|              0.0|              2.7|            140.0|4.860113634901638...|             14.0|  0.5208562344507215|                0.0|0.48009629871768866|0.9530305562536405|                0.0| 0.14263786388383157|             10.2|             93.5| 0.7109817373616778|  0.6116401275943195| 0.6378515702290832|                0.0|             160.0| 0.6391940422251249| 0.5441343679229096|             96.0| 0.27913963790947627|90.0066025067144| 0.26042811722536074|             120.0|            50.0|             10.2|                0.0|  0.4169167995122752|0.007491553859143...| 0.9275073699266075| 0.7216119155497502|            20.0|41.666666666666664|            140.0|  0.5340081053473056|            29.4|0.9836831939012491|             27.0|0.019571788506886224| 0.42668733560235383|           120.0|              14.0|90.00044762757386|                 0.0|  0.7068190041928392|              6.9|  0.8268248222766145|              8.0|0.49184159695062457| 0.43875909118681766|  0.3189124135676774| 0.9973168050356388|            20.0| 0.34404253486272546|                 1.0|              14.0|  0.9902141057465569|            10.2|               2.7|              20.0|                 0.0| 0.4225132067981789|              16.6|            99.0| 0.9181116529695413| 0.5362463150366963|            174.0| 0.34360065296605646|               6.9|              31.9|  0.8010808660789625|               0.0|               0.0|  0.5994595669605187|            160.0|            140.0|              8.0|   0.526603763232576|             103.0|                 0.0|              16.6|             140.0|                0.0|               1.5|30.130434782608695|              31.9| 0.7279328160385452|  0.7146855143894995|               1.5|                 0.0|             140.0|               0.0|0.7725206350759527|             85.0|  0.8338335990245505|               0.0|                 0.0|               1.5|              2.5|90.38166544923301|                 0.0|              15.8|              0.0| 0.4293447920494673|[0.59945956696051...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|  1.0|[0.84632390635455...|[0.84457205571495...|       0.0|\n",
            "|176986.0|2124-03-30|{2124-03-29 00:00...| 0.6531972647421806|             8.4|             127.0|13.597910537212597| 0.08164965809277258|  0.5602426599302645|   0.867178898040382|             153.0| 76.77777777777777| 0.7905702978199138|             28.0|             58.0|  0.419016389184504|4.068208670260556|              0.0|  0.5941955873550857|            87.0|               2.3|             10.8| 0.3371881483049508|               0.0|0.08476868946084137|0.07530862398670389|             198.0|  0.570643557622579| 0.9623456880066481|               0.0|                1.0|              14.9|              30.6|              1.3| 0.4634458150587124|0.17461602194619852|1.2000000000000002|             0.0| 0.07340145945951213|97.29775093569233|                0.0| 0.9404912526956775|0.34923204389239704|             31.4|  0.9286722931816589|             115.0|               1.0| 98.08017781384638|0.008547259694383564| 0.12097119743533971| 0.4833624831267787|               0.0| 0.21953721146551025|             3.54|0.005037189085355657|             10.8| 9.673688382079519| 8.270130695968176|4.159509433962263|              31.4|               2.3|0.47292877765230995|              20.9|             93.0|             94.0| 0.22417756989297666|0.08596788964012393|  0.8487362437179414|           120.0|0.35617271464321204| 3.500057344901359|               2.3|  0.8902313942672448|             30.0|           100.0|0.41866125589013137|           100.0|  0.0977978224852912|               1.0|             0.0|                0.0|            80.0|0.29160361267884305|                 0.0|            28.0|             211.5| 0.43200767862601536|               1.0|4.1610394537177555|  0.8702085090882137|            211.5|            28.0|  0.8640153572520307|0.9738948671571004|              13.3|  0.759202798262025| 0.7341924406223514|0.10956527476958616|              32.8|           115.0|             24.5|             154.0|             33.0|              22.0|  0.6188162389705184| 0.4721770330141089|3.5965474209650576|103.44444444444444|              3.54|                0.0|              33.0|             13.3|3.4006276150627603| 0.03670072972975606|              35.0|              10.8|             8.4|             115.0|              32.2|0.14580180633942152|             160.0|  0.9110001498850737|  0.8481149845477995|0.45550007494253686|  0.6178960502701973|            18.0|             20.9|0.48414255054546573| 0.46370842439089255|                 0.0|              67.0|             154.0|             22.0|  0.7029022063224571|               1.0|             225.0|  0.5497190532886032| 68.44444444444444|              8.4|              84.0|3.6514837167011076|            50.0| 0.981301814901793|             153.0| 0.4773693026559077|             154.0|              8.0|0.5130525664214498|             153.0|             153.0|             93.0|               0.0|           100.0|0.4906509074508965|              13.7|            20.9| 0.26564220391923604|             85.0|                 0.0|              8.4|   0.475782102493217| 0.6531972647421806|0.007158299831221294| 0.4188594043601722|                 0.0|              32.2|              13.7|             8.4|                0.0|              55.0|4.068660082014597|             225.0|3.5946443514644364|0.08037252201688713|               0.0| 0.9957263701528082|               1.1| 0.5004475598958745|            98.0| 0.9949779708054476| 0.2748595266443016|              30.6|             3.54|              0.0|             8.4|             92.0|  0.4678802538173802|  0.7505962587175995|  0.7906693720549343|  0.278067730126483|           115.0|             153.0|             30.3| 0.8000000000000007|0.47723030968144614|0.016019025906931352|               2.5|  0.8631174214841814| 0.32834702258044673|  0.8888133940424412| 0.6743762966099016|0.3717226033966161|           100.0|            22.0|  0.5316151187552971|             92.0|             28.0|138.3575503993914|0.37529812935879975|98.87376658727456|             93.0|0.3680998820137272|              14.1|             2.3|3.977200303490134|             30.3|            22.0|0.11208878494648833|             2.3|  0.174733806517274|13.981693363844393|  0.9395144012823301|13.220061022120518| 0.9598137389915564|             153.0|             33.8|                0.0| 0.5759425077261002|             13.5| 8.001543061061703| 0.47827446509141863|                1.0|             13.5|               0.0|                 0.0|   0.731791270962617|3.9778867924528267|1.5723301886761007|            22.0|           115.0|             85.0|              24.5|             20.9|             30.6|             90.0|                0.0|              0.0|3.405948419301164|138.3512996941896|  0.9964208500843893|13.55895896170368| 0.47673291112742694|0.36128275365036766| 0.4784520629105555| 0.956904125821111|                0.0|  0.7198786700348678|             10.8|99.08333333333333|  0.536417458074766|  0.5004252396055716| 0.5297543736521613|                0.0|             160.0| 0.5316972155492664| 0.6653917172247079|             96.0| 0.43510425454410684|            90.0| 0.47783318356312104|             120.0|            60.0|             10.8|                0.0|  0.5844616893429506|                 0.0|0.29075700255816966| 0.9366055689014672|            28.0|              32.5|139.1452599388379|0.010044058389104727|            33.8|0.9866770743020669|             22.0|  0.5610135642774978|  0.5756318781410292|           120.0|13.177351247600768|             90.0|                 0.0|   0.556135460252966|             20.9|  0.1955956449705824|              8.0|0.49333853715103343| 0.21913054953917233| 0.43721795594277313| 0.5356638534091706|            11.0|  0.3094081194852592|0.008009512953465676|13.949328214971208|  0.7194932178612511|            10.8|3.4959720063757715|              28.0| 0.08164965809277258| 0.9974814054573222|              14.9|            88.0|  0.349467613034548|0.14537850127908483|            198.0| 0.30894802513509867|              20.9|              32.8|  0.8302773434616422|               0.0|4.1303752856126765|  0.4151386717308211|            160.0|138.7550739009944|              8.0| 0.46799099320339343|             115.0|                 0.0|14.100000000000001|139.14416127805248| 0.8000000000000007|1.2000000000000002|15.833333333333334|              32.8|  0.667304141387646| 0.27376515703163723|               1.1| 0.08957582974112871|138.75297937600118|               0.0| 0.838032778369008|             85.0|  0.8310766213140989|4.1303752856126765|  0.0911977288017119|               1.3|              2.3|             92.0|                 0.0|              13.7|              5.0|0.22237321191511766|[0.41513867173082...|(166,[0,3,11,20,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[1.05380939501223...|[0.89164148245769...|       0.0|\n",
            "|196271.0|2141-12-23|{2141-12-22 00:00...|0.13065475397959778|             7.7|             123.0|               9.5|  0.0148147169883393| 0.04162341526443389|0.011396308873774743|              83.0|              74.0| 0.5706230715907137|              8.5|             53.0|0.38626031753797635|              3.8|              0.0|   0.977905834042727|            80.0|               2.0|              7.3| 0.3371881483049508|               0.0|                0.0| 0.6413598398090137|             455.0| 0.5134138194478215|0.32067991990450684|               0.5|                0.7|16.326121062384175|              29.4|1.477589339794065|0.09384414268745607| 0.4600024796048131|1.4608241195741203|             0.0|0.021322770247424946|             98.0|                0.5| 0.2038457891785212|0.48651583403086374|             21.2|  0.4762383440546457|             101.0|               0.7|           98.7875|0.029423277459913376|  0.3105711659425305| 0.2466909119612835|               0.5|0.015713230646250614|             2.45| 0.29305270223556673|              7.3|10.040348288281637| 7.176350047203662|              3.8|              21.2|               2.1|0.41033388138496085|              16.2|             90.0|             90.0| 0.47280115065897854|                0.0|  0.6519614795193027|           120.0|                0.5|              3.75|               2.1|0.007856615323125307|             30.0|           100.0| 0.8556360563526966|           100.0| 0.20713751356900506|               0.7|             0.5| 0.7999999999999972|            82.0|0.48908889201931066| 0.10000000000000009|             8.0|             472.0|0.046555652428750656|               0.7|               3.8| 0.09188636640086657|            455.0|             8.5| 0.09311130485750131|0.9738948671571004|16.087061323618695| 1.8320484120467573|0.05938207800495983| 0.4142515026977065|              34.3|           102.0|36.91319672131147|             110.0|             25.2|              29.0|  0.2665018632198425| 0.4104052681191437|               3.8|          103.9375|              2.43|                1.0|              25.2|16.04014206300184|               3.7|0.010661385123712473|              30.0|               7.3|             7.7|             101.5|22.866666666666664| 0.4584105459263105|             160.0|  0.3091690311323449|2.295717223618402...|0.15458451556617245|  0.2655174401587249|            19.0|             16.7|0.24772586211147224| 0.09484403985556165|                 0.0|              63.0|             110.0|             29.0|  0.4889529170213635|               0.7|             455.0|  0.2867574507362795|           64.5625|              7.7| 87.66666666666667|4.2163702135578385|            60.0| 0.986777781674111|             108.0| 0.4954517242229445|             110.0|              8.0|0.5130525664214498|              83.0| 91.33333333333333|             87.0|               0.0|           100.0|0.4933888908370555|              15.1|            15.7|0.022792617747549485|             85.0|0.020000000000000018|              7.7|  0.7465730375201259|0.12965952398334926|  0.3064038946652724| 0.8587538568185726| 0.10000000000000009|22.866666666666664|              15.1|             7.7|                0.0|              60.0|              3.8|             489.0|               3.8| 0.6447961715696787|               0.0| 0.9852883612700433|1.4457904300423992|0.20520263405957184|            95.0| 0.9831495269191155| 0.8566212746318602|             29.65|             2.47|              0.5|             7.7|             91.0|0.046922071343728035|  0.8631707688029249|  0.5721819718236517| 0.8593932611385096|           101.5|              83.0|37.70331834880121|  1.699673171197595|  0.493381823922567|0.010539285415788123|               0.0|0.011497149501100342| 0.22613234770607032|0.007859187012409915| 0.6743762966099016|               1.0|           100.0|            29.0| 0.11876415600991966|             92.0|              8.0|            135.0| 0.5684146155985376|             99.7|             88.5|               1.0| 16.17945696932262|             2.0|              3.8|37.83908909055424|            29.0|0.41496732739917513|             2.2| 0.4594330506661511|              10.0|  0.8447144170287347|               9.0|0.32239808578483936|              83.0|38.69393271461717|                0.0|  0.999885214138819|             17.0| 7.210831696136029|  0.6267134812399371|                0.7|              0.0|               0.0|                 0.0|0.019589096011496766|               3.8|2.0548046676563256|            29.0|           101.0|             85.0|36.781171693735494|             15.7|             29.9|             90.0|                0.5|              0.0|              3.7|            135.0|  0.8467980526673637|              9.5|  0.7515991411877838|                0.5| 0.4784520629105555| 0.956904125821111|                0.0|   0.979188292367783|              7.3|97.76470588235294|0.03917819202299353| 0.20516694069248043| 0.1019228945892606|               0.25|             160.0|0.10431744232962346|  0.619656051275024|             88.0| 0.04594318320043329|            90.0|  0.6242004294061081|             120.0|            60.0|              7.3|                0.0|  0.9936377309023947|                 0.0| 0.4884661578947222|0.20863488465924693|             9.0|              30.0|            137.0| 0.03370094616176906|38.8348594847775|0.9866770743020669|             29.0| 0.11899204696629205| 0.32598073975965136|           120.0|               9.0|             90.0|                 0.0|  0.2812134777229809|             16.7|  0.4142750271380101|              8.0|0.49333853715103343|  0.4708701645239077|  0.8869338261469648|0.23811917202732286|            13.0| 0.13325093160992124|0.005269642707894062|              10.0|0.059496023483146025|             7.3|              3.75|               9.0|0.014632153041738868| 0.8534736488822167|16.373460837887045|            97.0|0.48486335344055065|0.45745215253325033|            455.0| 0.13275872007936246|              16.2|              32.7| 0.48460389543673454|11.785113019775793|0.8705195762144462|  0.7576980522816328|            160.0|            136.0|              8.0| 0.04742201992778083|             102.0|                 0.0|16.227216656547245|             137.0|  1.699673171197595|1.4611558651322438|16.333333333333332|              33.5|  0.309828025637512|0.022994299002200683|1.4453931203931218| 0.04999999999999982|             136.0|               1.5|0.7725206350759527|             85.0|0.012724538195210536| 0.876945766580447| 0.04999999999999982|1.4776412776412784|              2.2|             90.0|                 0.0|              15.1|              0.0|0.01571837402481983|[0.75769805228163...|(166,[0,2,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[0.90524626406543...|[0.85942139020929...|       0.0|\n",
            "|107462.0|2149-04-04|{2149-04-03 00:00...|                0.0|             8.3|138.94057916509965|              13.0|                 0.0|1.563940361854594...|  0.6717097527396186|             142.0| 74.77826247362239|  0.966519207113261|             34.0|47.70463975858167|  0.426930727592382|              3.4|              0.0| 0.20718381381747253|78.0369671821954|               2.6|             10.3| 0.3371881483049508|               0.0|                0.0| 0.7088611790207303|             460.0| 1.1368817000902063| 0.6455694104896348|               0.0|                1.2|              15.6|              29.1|              1.4| 0.8256396060702549| 0.4368093972444698|               1.4|             0.0| 0.19619776364057873|             96.5|                0.0| 0.9486646067167785| 0.8736187944889396|             32.6| 0.41545845588492925|             106.0|               1.2| 98.05000000000001|  0.7384634103524592| 0.22323189276593913|0.11361441164105651|               0.0| 0.33445158855806834|             3.53|  0.3738713374251535|             10.3|11.487286830973543| 8.168515431713185|              3.4|              32.6|               2.6|0.17203839893891715|              11.0|             92.0|97.67732230161715|  0.3851058352521204|                0.0|  0.5392200114022563|           120.0|                0.0|               3.5|               2.6|  0.8327742057209658|             40.0|           100.0|0.06746205695622363|           100.0| 0.41341241113830723|               1.2|             0.0|                0.0|            51.0| 0.8890503192515382|                 0.0|            34.0|             460.0|  0.5562425322172879|               1.2|               3.4|  0.8783041593254626|            460.0|            34.0|   0.887514935565424|0.9738948671571004|              15.6|  2.357468123778428| 0.6382877706103647|0.19079476169985227|              31.6|           106.0|             28.0|151.38370222803474|             32.6|              29.0|  0.7600767323102067|0.17188604316907938|               3.5|117.87633609613528|              3.53|0.06445004758462232|              32.6|             15.6|               3.5|   0.472376144412589|              40.0|              10.3|             8.3|             106.0|              32.6| 0.4445251596257691|160.55733211512106|  0.0656202747032537|0.012681546647063037| 0.9671898626483731|  0.7592421727640487|            36.0|             11.0|0.11379437944827117|  0.8331874204840826|                 0.0|60.782215523737754|178.49948822927328|             29.0|  0.4711329744042347|               1.2|             460.0| 0.45128162827208385| 61.39591571522619|              8.3|62.458333333333336| 6.337580812546343|            40.0| 0.981301814901793|             142.0|0.22758875889654234|127.71084953940634|              8.0|0.5130525664214498|             142.0|             142.0|             92.0| 19.70452579251507|           100.0|0.4906509074508965|              15.8|            11.0|  0.6565804945207627|             85.0|                 0.0|              8.3|  0.9825704584833852|                0.0| 0.04199066384315559|0.06696158577347804|                 0.0|              32.6|              15.8|             8.3|                0.0|              40.0|              3.4|             460.0|               3.5| 0.7146464602556497|               0.0| 0.6307682948237704|               1.4| 0.9140569784154603|            91.0| 0.6234285794009405|  0.774359185863958|              29.1|             3.53|              0.0|             8.3|90.44908692476263| 0.41281980303512744| 0.28391127426390905|  0.9662689715218882| 0.7769710045951528|           106.0|             142.0|             28.0|                0.0|0.22722882328211302|6.655943652961386...|               0.0|  0.6677216531680673|  0.7516197469345433|  0.8313814676603787| 0.6743762966099016|               0.0|           100.0|            29.0|  0.7234244587792705|90.51460920379839|             34.0|            145.0|0.14195563713195453|             99.8|             92.0|               0.0|              15.6|             2.6|              3.4|             28.0|            29.0| 0.1925529176260602|             2.6| 0.4386443108440325|              13.0| 0.48581197505212126|              13.0| 0.6426767698721751|             142.0|             28.0|                0.0| 0.9936592266764684|              0.0| 8.132272964076716|  0.5087147707583074|                1.2|              0.0|               0.0|                 0.0|  0.7254755977431124|               3.4| 4.681523968396046|            29.0|           106.0|             85.0|              28.0|             11.0|             29.1|90.01611459265891|                0.0|              0.0|              3.5|            145.0|0.020995331921577796|             13.0|   0.985906794023877|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|7.819701809272973E-5|             10.3|96.08695652173913| 0.5490488045137751|  0.9139808005305414| 0.4743323033583893|                0.0|160.30150753768845|0.47653626657293524| 0.7961109513546751|90.91899020346646|  0.5608479203372687|90.0066025067144|  0.5070466029880615|             120.0|            40.0|             10.3|                0.0|  0.9944479197697371|0.007491553859143...| 0.8865360792227868| 0.9530725331458705|            34.0|              40.0|            145.0|  0.7531428411981189|            28.0|0.9905790501718436|             29.0|  0.7511971742166561| 0.26961000570112814|           120.0|              13.0|90.00044762757386|                 0.0|  0.4460579908096943|             11.0|  0.8268248222766145|              8.0| 0.4952895250859218| 0.38158952339970453|  0.3758098734672716|0.48473795362972405|            15.0| 0.38003836615510334|  0.9999999966720282|              13.0|   0.624401412891672|            10.3|               3.5|              34.0|                 0.0| 0.4225132067981789|              15.6|            71.0|  0.877288621688065| 0.4432680396113934|            460.0| 0.37962108638202435|              11.0|              31.6|8.843657344815311...|               0.0|               0.0|4.421828672407655...|160.4163621135982|            145.0|              8.0|  0.4165937102420413|             106.0|                 0.0|              15.6|             145.0|                0.0|               1.4|              26.0|              31.6| 0.6019445243226624|  0.6645566936638654|               1.4|                 0.0|             145.0|               0.0|0.7269868524702858|             85.0|0.011104160460525848|               0.0|                 0.0|               1.4|              2.6|90.38166544923301|                 0.0|              15.8|              0.0|0.33723706467924264|[4.42182867240765...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[0.90503581080853...|[0.85937053016319...|       0.0|\n",
            "|122619.0|2164-05-23|{2164-05-22 00:00...|0.13065475397959778|            8.45|             149.0|              14.5|  0.0148147169883393| 0.19113899790625108|  0.5007014305921953|             103.0|              81.0|0.06537548397442225|             10.5|             51.0|0.36165156269653376|              3.5|              0.0|0.045879108361798496|            81.0|               1.7|9.720783890168976| 0.3034253128759712|0.0720476814472478| 0.2999999999999998| 0.3641563464936197|204.55184887459808| 0.6454972243679028|0.18207817324680986|               0.5|                0.5|16.326121062384175|30.123507616302994|1.477589339794065| 0.7847731072252886| 0.4600024796048131|1.4608241195741203|             0.0|0.006294550143638595|             97.7|0.15238186232786088| 0.8384467361807976|0.48651583403086374|28.88809523809525|  0.9854346785591696|              99.0|               0.6|              98.7| 0.48196839886325465| 0.19475238740146078|0.07326473219685131|               0.5| 0.45219772949982334|3.250759740695953|  0.6194900007990161|9.798362619808303|10.259243518034205| 7.225685179676006|              3.8|28.889421157684648|              1.75|0.01861913933091351|  9.43330216554195|90.84011276681434|            103.0| 0.47280115065897854| 0.2999999999999998| 0.47373916357820256|           120.0|                1.5|              1.75|              1.75|  0.5286978729187907|             35.0|           100.0|   0.13333412130835|           100.0|  0.4709935406778632|               0.6|             0.5|0.06995517975068115|            83.0|0.48908889201931066|0.050000000000000044|            10.0|207.85274463007156|  0.0627778825394596|               0.4|               3.8| 0.12444099126590709|206.9605004019292|            10.5|  0.1255557650789192|0.9680307246992478|16.087061323618695| 1.1575161985907585|0.48368971676867756| 0.4142515026977065|33.248717948717946|           100.0|36.91319672131147|149.66666666666666|29.72134920634922|              19.0| 0.16672124155971146|0.01860971492201124|               1.8|131.89473684210526|3.2267190648931874|                0.0|29.732255489021973|16.04014206300184|               1.7|  0.9968527249281807|              35.0|  9.71992725924236|             8.8|              99.5|29.305063649533878| 0.4584105459263105|             160.0|  0.3311830982240087|  0.4886900771438565| 0.8344084508879956| 0.16592954814705455|            29.0|9.599003202562052|0.07351684342824598|  0.7714436273711858| 0.35000000000000053|              64.0|             213.0|             22.0|  0.9770604458191008|               0.4|209.46905144694534|  0.2093311783634658| 65.21052631578948|              8.8|              97.5| 7.978095010715277|            50.0|0.9745232284758952|             150.0|0.14703368685649196|             103.0|              8.0| 0.515984637650376|             103.0|             126.5|90.55054369714055| 46.42796092394706|           100.0| 0.491807068783402|16.114291481631014|9.21408502024291| 0.47109294943321767|85.00246212121212|0.022153573700935885|              8.1|0.043967096451587896|0.12965952398334926| 0.38508085865314434| 0.1307509679488445|0.050000000000000044| 29.31268022684791|16.177069035123125|             8.1|0.02918013555493569|56.666666666666664|              3.5|210.35680190930788|               1.8| 0.3704290814255442|              23.5| 0.4686834829104542|1.4457904300423992|0.00930485746100562|            96.0|0.46784589154325545| 0.1046655891817329|30.178889460683365|3.274385328496573|              0.5|            8.45|             90.0|  0.6076134463873557|  0.4894464120957203|   0.066667060654175| 0.1071947043737671|            99.5|             126.5|37.70331834880121| 0.3685342915673636|0.14652946439370262|  0.5443390498748227|               0.0|  0.4983362270214471|   0.375451439017075|  0.5276163794601939| 0.6068506257519424|               1.0|           100.0|            19.0|  0.9673794335373551|             90.0|             10.0|            130.0| 0.4729044061266951|             99.7|90.69301248489731|               1.0| 16.17945696932262|             1.7|              3.2|37.83908909055424|            20.5|0.41496732739917513|             1.8| 0.4594330506661511|              16.0|  0.9026238062992696|              13.0| 0.1852145407127721|             150.0|38.69393271461717|0.07060400796808293| 0.5049095001727325|2.305587200599279| 7.345452924793685|0.021983548225793948|                0.5|2.297622738931195|               1.5|0.002728073736398...|  0.5043438780045272|               3.2| 4.579854719538335|            22.0|            99.0|84.99962121212121|36.781171693735494|9.271773418734984|30.23589954713873|             90.0|0.15403168443235046|              1.5|              1.7|            130.0|  0.8074595706734278|             14.5| 0.04387195048768025|                1.5|0.47361569343253623|0.9472313868650725|                0.0|  0.9044305010468745|9.644677419354842|          97.6875|0.46473433340591286|0.009309569665456756| 0.5807766319096013|0.05272455247871184|             160.0|  0.583294241900559|0.47024088066356073|             95.0|0.062220495632953544|            90.0|0.021935975243840125|             120.0|            60.0|9.796491935483868|0.35000000000000053|   0.506758958686583|                 0.0| 0.4884661578947222|  0.833411516198882|            11.0|              35.0|            132.0|  0.4838445299068336|38.8348594847775|0.9836831939012491|             20.5|  0.9376223534774848| 0.49055292792469574|           120.0|              13.0|             90.0|                 0.0|  0.2143894087475342|9.539477732793522|  0.4579845075940477|              8.0|0.49184159695062457|  0.4708701645239077|  0.8122742804914624| 0.5072826607204153|            13.0| 0.08336062077985573| 0.27216952493741137|              16.0|  0.4688111767387424|9.64237220447285|              1.75|              11.0|0.014632153041738868|0.30974500039950803|16.373460837887045|           117.0|0.48486335344055065|0.45745215253325033|205.4315831344471| 0.08296477407352727| 9.375520512820508|33.100986193293885|5.515855430906425E-4|              23.5|0.8705195762144462|  0.9997242072284547|            160.0|            131.0|              8.0|  0.6142781863144071|             100.0| 0.09999999999999998|16.227216656547245|             132.0| 0.3720366581314043|1.4611558651322438|18.842105263157894| 33.17546745562131| 0.4987639065100168|  0.4707463743072148|1.4453931203931218|0.050000000000000044|             131.0|0.1363245068214134|0.7233031253930675|85.00530303030303|  0.4866650863530708| 0.876945766580447|0.050000000000000044|1.4776412776412784|              1.8|             90.0| 0.09999999999999998| 16.14547301843629|4.714045207910317|0.45356404462486793|[0.99972420722845...|(166,[0,2,10,13,5...|[0.99972420722845...|                               0.0|                                0.0|  0.0|[0.77654123642372...|[0.82535849088275...|       0.0|\n",
            "|116807.0|2117-02-07|{2117-02-06 00:00...|                0.0|             6.7|             103.0|              15.0|                 0.0|  0.1496787525087407|   0.594492698538468|             110.0|62.333333333333336|0.05700811392212522|             14.0|             40.0|  0.426930727592382|              4.1|              0.0|0.055471419158142334|            66.0|               1.6|             10.0|0.38319833098312733|               0.0|                0.0| 0.3998651360945944|204.55184887459808|0.23570226039551584| 0.8000674319527028|               0.0|                0.8|              18.5|              30.9|              1.7| 0.7407032844532456| 0.7184899722686522|               1.7|             0.0|0.003195742693544208|             97.4|0.15238186232786088|0.02213034619658222| 0.5630200554626956|             30.7| 0.33329657944584723|             109.0|               0.8| 97.73333333333335| 0.48196839886325465| 0.22335891754995538| 0.5231770117520154|               0.0|  0.6139275363102388|             3.24| 0.04731287585814677|             10.0|13.199326582148887|  9.94428926011753|              4.1|              30.7|               1.6|   0.56044520340909|  9.43330216554195|             95.0|             67.0|  0.9875101370703736|                0.0|   0.725080657807811|           120.0|                0.0|               4.1|               1.6|  0.6930362318448806|32.15018688413184|           100.0|0.11608214361493663|            99.0|  0.6153947686560318|               0.8|             0.0|                0.0|            70.0| 0.5723090162781292|                 0.0|            14.0|207.85274463007156| 0.18382394812673275|               0.8|               4.1| 0.36712102996921425|206.9605004019292|            14.0|  0.3676478962534655| 0.964593531955711|              18.5| 1.6072751268321592| 0.3312668735370495| 0.5009964792894596|              32.5|           109.0|             40.2|              96.0|             30.7|              16.0| 0.49040166949984454| 0.5605050419662186|               4.1| 89.33333333333333|              3.24|                0.0|              30.7|             18.5|               4.1|0.001597871346772104|33.498131158681616|              10.0|             6.7|             109.0|              30.7| 0.7138454918609354|160.55733211512106| 0.37029854772356713|  0.4886900771438565|  0.454664934364283|  0.4894491185800768|            18.0|9.599003202562052| 0.5245125484381217|  0.7307831554495909|                 0.0|              48.0|              96.0|             16.0|0.027735709579071167|               0.8|209.46905144694534| 0.07903882459641288|              53.5|              6.7| 75.66666666666667|   3.8873012632302|            60.0| 0.986777781674111|             110.0| 0.9509749031237567|              96.0|8.001711156741958|0.5122275324512284|             110.0|             110.0|             95.0|               0.0|           100.0|0.4933888908370555|              16.8|9.21408502024291|  0.8110146029230639|             85.0|                 0.0|              6.7|  0.6045752569230266|                0.0|  0.7279231634644692|0.11401622784425045|                 0.0|              30.7|              16.8|             6.7|                0.0|              60.0|              4.1|210.35680190930788|               4.1|0.40842693744767955|               0.0| 0.4686834829104542|               1.7| 0.2802525209831093|            95.0|0.46784589154325545|0.03951941229820644|              30.9|             3.24|              0.0|             6.7|             92.0|  0.6296483577733771|  0.6126470557419207|0.058041071807468314|0.04040852575860842|           109.0|             110.0|             40.2|                0.0| 0.9536459764959693|0.002359306067165...|0.6456096427150202|  0.5907398170442795|  0.5233400198111846|  0.6914708202684547| 0.7663966619662547|               0.0|           100.0|            16.0|   0.662533747074099|             92.0|             14.0|            136.0|0.30632352787096034|             97.9|             95.0|               0.0|              18.5|             1.6|              4.1|             40.2|            16.0| 0.5062449314648132|             1.6| 0.7229104968886264|              15.0| 0.11167945877497769|              15.0| 0.7957865312761603|             110.0|             40.2|                0.0| 0.5049095001727325|2.305587200599279|10.372238588334406|  0.6977123715384868|                0.8|2.297622738931195|               0.0|                 0.0|  0.5185863354890904|               4.1| 2.078698548207745|            16.0|           109.0|             85.0|              40.2|9.271773418734984|             30.9|90.01611459265891|0.15403168443235046|              0.0|              4.1|            136.0|  0.6360384182677654|             15.0|  0.6083456795889751|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614|  0.9251606237456297|             10.0|             97.5| 0.9628273290218192|   0.280222601704545|0.01106517309829111|                0.0|160.30150753768845|0.01153722911082979|0.43500466140042404|             74.0| 0.18356051498460713|90.0066025067144|  0.6958271602055124|             120.0|            60.0|             10.0|                0.0|   0.506758958686583|0.007491553859143...| 0.5766368313274335|0.02307445822165958|            14.0| 32.81576379787387|            136.0|  0.4838445299068336|            40.2|0.9905790501718436|             16.0|  0.6514403098293393|  0.6374596710960945|           120.0|              15.0|90.00044762757386|0.003037197636785...| 0.08081705151721684|9.539477732793522|  0.7692104626879364|7.995208761122519| 0.4952895250859218|  0.9980070414210809|  0.2616700099055923|0.16664828972292361|            12.0| 0.24520083474992227|0.001179653033582...|              15.0| 0.32572015491466966|            10.0|               4.1|              14.0|                 0.0| 0.9763435620709267|              18.5|            83.0| 0.5541790062227472| 0.7116815843362833|205.4315831344471|  0.2447245592900384| 9.375520512820508|              32.5| 0.08350439152559527|               0.0|               0.0|0.041752195762797636|160.4163621135982|            136.0|7.997900981063198|  0.6346084222752045|             109.0|                 0.0|              18.5|             136.0|                0.0|               1.7| 14.11111111111111|              32.5|  0.782497669299788|  0.8185203659114411|               1.7|                 0.0|             136.0|               0.0|0.7269868524702858|             85.0|  0.4866650863530708|               0.0|                 0.0|               1.7|              1.6|             92.0|                 0.0|              16.8|              0.0| 0.6170583594630905|[0.04175219576279...|(166,[0,1,10,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                1.0|  1.0|[1.12033546945749...|[0.90384278606607...|       0.0|\n",
            "|167106.0|2184-06-11|{2184-06-10 00:00...|                0.0|             8.4|             151.0|              13.0|                 0.0| 0.28527572776766313|  0.9948733461022559|              67.0| 83.66666666666667| 0.5500704038677933|             11.0|             57.0|  0.426930727592382|              3.6|              0.0|   0.119741270001636|            79.0|               2.1|             13.4| 0.3034253128759712|               0.0|                0.0| 0.7088611790207303|             142.0|0.29439202887759586| 0.6455694104896348|               0.0|                1.0|              15.1|              30.1|              1.3| 0.8256396060702549| 0.3873596567133406|               1.3|             0.0| 0.05327298400206616|            100.2|                0.0| 0.9404912526956775| 0.7747193134266812|             36.2| 0.41545845588492925|             106.0|               1.0|100.60000000000001|  0.9517022615938819|  0.2555793785383002|0.19879058326481908|               0.0| 0.06607903118648298|             4.44|  0.3897484515890689|             13.4|10.159833769418782| 8.556998435328957|              3.6|              36.2|               2.1| 0.9464621090323675|               9.3|             82.0|            118.0|  0.4344678286732502|                0.0|  0.9382132371331686|           120.0|                0.0|               1.6|               2.1|  0.9669604844067585|             30.0|           100.0| 0.8976366291296707|            96.0|0.028165863154629392|               1.0|             0.0|                0.0|            76.0| 0.7082352766381776|                 0.0|            11.0|             142.0| 0.14520620727291608|               1.0|               3.6|  0.2890958536245729|            142.0|            11.0| 0.29041241454583216|0.9680307246992478|              15.1|  1.049781318335648|0.06704255485263781|0.21515138439841197|              36.9|           106.0|             29.2|151.38370222803474|             36.2|              24.0|  0.6188162389705184|  0.946286246363002|               1.6|135.66666666666666|              4.44|                0.0|              36.2|             15.1|               1.6|  0.9733635079989669|              40.0|              13.4|             8.4|             106.0|              36.2| 0.3541176383190888|160.55733211512106|  0.8160678784568325|  0.6001922151232196| 0.5919660607715838|  0.6178960502701973|            22.0|              9.3|0.19924435279217279|  0.8331874204840826|                 0.0|              71.0|178.49948822927328|             24.0|   0.940129364999182|               1.0|             142.0|    0.83206748784093| 67.66666666666667|              8.4| 83.14285714285714| 5.329930887479322|            50.0|0.9745232284758952|              67.0|0.39848870558434557|127.71084953940634|              8.0| 0.515984637650376|              67.0|              67.0|             82.0| 19.70452579251507|           100.0| 0.491807068783402|              12.5|             9.3|0.010253307795488314|85.00246212121212|                 0.0|              8.4| 0.12149134092137374|                0.0|0.003978308517472698| 0.8998591922644134|                 0.0|              36.2|              12.5|             8.4|                0.0|              50.0|              3.6|             142.0|               1.6| 0.7146464602556497|               0.0|0.47585113079694097|               1.3|  0.526856876818499|            93.0| 0.4705965170838848|  0.416033743920465|              30.1|             4.44|              0.0|             8.4|             90.0| 0.41281980303512744|0.024020233373387774|  0.5511816854351647|  0.419681718607656|           106.0|              67.0|             29.2|                0.0|0.39758116652963815| 0.47770121709823954| 4.714045207910317|  0.9944948028832138|0.001854732736824...|  0.9663949066742558| 0.6068506257519424|               0.0|           100.0|            24.0| 0.13408510970527562|             90.0|             11.0|            139.0| 0.9879898833133061|            100.9|             82.0|               0.0|              15.1|             2.1|              3.6|             29.2|            24.0| 0.2172339143366251|             2.1|0.38858248780445526|              13.0|  0.8722103107308499|              13.0| 0.6426767698721751|              67.0|             29.2|                0.0| 0.3000961075616098|              0.0|7.5203427817856525| 0.06074567046068687|                1.0|              0.0|               0.0|0.002728073736398...|  0.9901562765522123|               3.6| 2.415933503612538|            24.0|           106.0|84.99962121212121|              29.2|              9.3|             30.1|90.01611459265891|                0.0|              0.0|              1.6|            139.0|0.001989154258736349|             13.0| 0.12140996424143871|                0.0|0.48009629871768866|0.9530305562536405|0.12368084276523614| 0.14263786388383157|             13.4|94.42857142857143|0.01968744689557546|  0.5267689454838163| 0.5297543736521613|                0.0|160.30150753768845| 0.5316972155492664|0.13823561327589817|             95.0| 0.14454792681228645|90.0066025067144|0.060704982120719356|             120.0|            50.0|             13.4|                0.0|  0.3023982933889825|0.007491553859143...| 0.7066539121412764| 0.9366055689014672|            11.0|33.333333333333336|            139.0|  0.9411930341677696|            29.2|0.9836831939012491|             24.0| 0.13762805081724974|  0.4691066185665843|           120.0|              13.0|90.00044762757386|                 0.0|   0.839363437215312|              9.3|0.056331726309258784|              8.0|0.49184159695062457| 0.43030276879682394|  0.9990726336315876|0.48473795362972405|            14.0|  0.3094081194852592| 0.23885060854911977|              13.0| 0.06881402540862487|            13.4|               1.6|              11.0|                 0.0|0.19487422579453445|              15.1|            91.0| 0.7771649756089105| 0.3533269560706382|            142.0| 0.30894802513509867|               9.3|              36.9|  0.7612294089236227|               0.0|               0.0| 0.38061470446181134|160.4163621135982|            139.0|              8.0|  0.4165937102420413|             106.0|                 0.0|              15.1|             139.0|                0.0|               1.3|18.142857142857142|              36.9|0.06911780663794909|0.011010394233572316|               1.3|                 0.0|             139.0|               0.0|0.7269868524702858|85.00530303030303|   0.604796586777965|               0.0|                 0.0|               1.3|              2.1|             90.0|                 0.0|              12.5|              0.0|0.06721018665148852|[0.38061470446181...|(166,[0,3,11,13,5...|(514,[0,1,2,3,4,5...|                               0.0|                                0.0|  0.0|[1.49797491158540...|[0.95239081760579...|       0.0|\n",
            "+--------+----------+--------------------+-------------------+----------------+------------------+------------------+--------------------+--------------------+--------------------+------------------+------------------+-------------------+-----------------+-----------------+-------------------+-----------------+-----------------+--------------------+----------------+------------------+-----------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+------------------+-----------------+-------------------+-------------------+------------------+----------------+--------------------+-----------------+-------------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+------------------+--------------------+--------------------+-------------------+------------------+--------------------+-----------------+--------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-----------------+-----------------+--------------------+-------------------+--------------------+----------------+-------------------+------------------+------------------+--------------------+-----------------+----------------+-------------------+----------------+--------------------+------------------+----------------+-------------------+----------------+-------------------+--------------------+----------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+----------------+--------------------+------------------+------------------+-------------------+-------------------+-------------------+------------------+----------------+-----------------+------------------+-----------------+------------------+--------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+-----------------+------------------+--------------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+--------------------+--------------------+-------------------+--------------------+----------------+-----------------+-------------------+--------------------+--------------------+------------------+------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+-----------------+------------------+------------------+----------------+------------------+------------------+-------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------+----------------+------------------+------------------+----------------+--------------------+-----------------+--------------------+-----------------+--------------------+-------------------+--------------------+-------------------+--------------------+------------------+------------------+----------------+-------------------+------------------+-----------------+------------------+------------------+-------------------+------------------+-------------------+------------------+-------------------+----------------+-------------------+-------------------+------------------+-----------------+-----------------+----------------+-----------------+--------------------+--------------------+--------------------+-------------------+----------------+------------------+-----------------+-------------------+-------------------+--------------------+------------------+--------------------+--------------------+--------------------+-------------------+------------------+----------------+----------------+--------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+------------------+------------------+----------------+-----------------+-----------------+----------------+-------------------+----------------+-------------------+------------------+--------------------+------------------+-------------------+------------------+-----------------+-------------------+-------------------+-----------------+------------------+--------------------+-------------------+-----------------+------------------+--------------------+--------------------+------------------+------------------+----------------+----------------+-----------------+------------------+-----------------+-----------------+-----------------+-------------------+-----------------+-----------------+-----------------+--------------------+-----------------+--------------------+-------------------+-------------------+------------------+-------------------+--------------------+-----------------+-----------------+-------------------+--------------------+-------------------+-------------------+------------------+-------------------+-------------------+-----------------+--------------------+----------------+--------------------+------------------+----------------+-----------------+-------------------+--------------------+--------------------+-------------------+-------------------+----------------+------------------+-----------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+----------------+------------------+-----------------+--------------------+--------------------+-----------------+--------------------+-----------------+-------------------+--------------------+--------------------+-------------------+----------------+--------------------+--------------------+------------------+--------------------+----------------+------------------+------------------+--------------------+-------------------+------------------+----------------+-------------------+-------------------+-----------------+--------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+-----------------+-----------------+-----------------+--------------------+------------------+--------------------+------------------+------------------+-------------------+------------------+------------------+------------------+-------------------+--------------------+------------------+--------------------+------------------+------------------+------------------+-----------------+--------------------+------------------+--------------------+------------------+-----------------+-----------------+--------------------+------------------+-----------------+-------------------+--------------------+--------------------+--------------------+----------------------------------+-----------------------------------+-----+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXttzS4KhlTl",
        "outputId": "c08c1477-19fe-4f91-c9c0-88563aea129b"
      },
      "source": [
        "for i in [5]:\n",
        "  print(i)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZufcacCJUxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4409a35b-daaa-4455-a6df-e9b703b9dede"
      },
      "source": [
        "#training and testing raw accuracy from Dae's code (GBT w/ 5-fold CV)\n",
        "#tr_resultdf became te_result to corrrect for backwards return, can verify by checking the length\n",
        "tr_resultdf = te_result.toPandas()\n",
        "cor = 0\n",
        "for i in range(len(tr_resultdf)):\n",
        "  if(tr_resultdf[\"prediction\"][i] == tr_resultdf[\"label\"][i]):\n",
        "    cor += 1\n",
        "print(\"training accuracy :\" + str(cor / len(tr_resultdf)))\n",
        "te_resultdf = tr_result.toPandas()\n",
        "cor = 0\n",
        "for i in range(len(te_resultdf)):\n",
        "  if(te_resultdf[\"prediction\"][i] == te_resultdf[\"label\"][i]):\n",
        "    cor += 1\n",
        "print(\"testing accuracy: \" + str(cor / len(te_resultdf)))\n",
        "print(\"len training: \" + str(len(tr_resultdf)))\n",
        "print(\"len testing: \" + str(len(te_resultdf)))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy :0.9351214208046393\n",
            "testing accuracy: 0.735202492211838\n",
            "len training: 2759\n",
            "len testing: 321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwHf8IZyq8iw"
      },
      "source": [
        "from pyspark.ml.linalg import DenseVector\n",
        "#double check whether to take from label column name or the other one -> perhaps try both and see which is better (that should be the combined one), the .map is to uncondense Dense Vectorss\n",
        "X_train = tr_resultdf[\"features_imputed\"]\n",
        "X_test = te_resultdf[\"features_imputed\"]\n",
        "y_train = tr_resultdf[\"label\"]\n",
        "y_test = te_resultdf[\"label\"]\n",
        "X_train = X_train.map(lambda vector: vector.toArray())\n",
        "X_test = X_test.map(lambda vector: vector.toArray())"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bSfoOQMuiEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ec6cd3-8c24-4de8-d035-38907d10b3be"
      },
      "source": [
        "#vstack to increase shape for sklearn / tf\n",
        "#double check if training set split is supposed to be this large (closer to 90 rather than 70-80)\n",
        "import numpy as np\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.vstack(X_test)\n",
        "print(X_train.shape)\n",
        "X_test.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2759, 348)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(321, 348)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUhw_FO6Lvtp"
      },
      "source": [
        "def print_counts(y_actual, y_hat):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    for i in range(len(y_hat)): \n",
        "        if y_actual[i]==y_hat[i]==1:\n",
        "           TP += 1\n",
        "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
        "           FP += 1\n",
        "        if y_actual[i]==y_hat[i]==0:\n",
        "           TN += 1\n",
        "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
        "           FN += 1\n",
        "\n",
        "    print(\"true positive count: \" + str(TP))\n",
        "    print(\"false positive count: \" + str(FP))\n",
        "    print(\"true negative count: \" + str(TN))\n",
        "    print(\"false negative count: \" + str(FN))\n",
        "    if(TP + FP == 0):\n",
        "      precision = 1\n",
        "    else:\n",
        "      precision = TP/ (TP + FP)\n",
        "    recall = TP / (TP + FN)\n",
        "    print(\"precision = \" + str(precision))\n",
        "    print(\"recall = \" + str(recall))\n",
        "    print(\"F1 = \" + str(2*((precision * recall) / (precision + recall))))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SG6ToPF06Jf"
      },
      "source": [
        "## Attempting Machine Learning and Deep Learning Models W/O Class Weights or Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lbHO81srCi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109b8dce-df50-417e-bb3b-b85da9ea8893"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "model = LogisticRegressionCV(cv = 10)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score \n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.7632398753894081\n",
            "true positive count: 23\n",
            "false positive count: 28\n",
            "true negative count: 222\n",
            "false negative count: 48\n",
            "precision = 0.45098039215686275\n",
            "recall = 0.323943661971831\n",
            "F1 = 0.3770491803278689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo9XhOwe13ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5b3fd0-2a80-4825-aed8-4d802e1905af"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.svm import SVC\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.778816199376947\n",
            "true positive count: 0\n",
            "false positive count: 0\n",
            "true negative count: 250\n",
            "false negative count: 71\n",
            "precision = 1\n",
            "recall = 0.0\n",
            "F1 = 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SAZn5B12LgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98fe9747-dcca-4e90-ab66-7f554f42918a"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors= 5)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.7165109034267912\n",
            "true positive count: 14\n",
            "false positive count: 34\n",
            "true negative count: 216\n",
            "false negative count: 57\n",
            "precision = 0.2916666666666667\n",
            "recall = 0.19718309859154928\n",
            "F1 = 0.2352941176470588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsfk6Qth2eIR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "4f38ac33-09c9-4ed8-c8ec-595840fd9ceb"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "model = GaussianProcessClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.7632398753894081\n",
            "true positive count: 0\n",
            "false positive count: 5\n",
            "true negative count: 245\n",
            "false negative count: 71\n",
            "precision = 0.0\n",
            "recall = 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-ce6e097c0ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw acc \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-46d82d00c596>\u001b[0m in \u001b[0;36mprint_counts\u001b[0;34m(y_actual, y_hat)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recall = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1 = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKEL3yAo1xzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75b3ace-703f-4846-e715-8f675d632483"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.6479750778816199\n",
            "true positive count: 20\n",
            "false positive count: 62\n",
            "true negative count: 188\n",
            "false negative count: 51\n",
            "precision = 0.24390243902439024\n",
            "recall = 0.28169014084507044\n",
            "F1 = 0.261437908496732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QOCWD4J45vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f62c69c-6a0d-41f5-ccbc-40e620639152"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "model = GradientBoostingClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "from sklearn.metrics import f1_score\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.7320872274143302\n",
            "true positive count: 15\n",
            "false positive count: 30\n",
            "true negative count: 220\n",
            "false negative count: 56\n",
            "precision = 0.3333333333333333\n",
            "recall = 0.2112676056338028\n",
            "F1 = 0.2586206896551724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EsgwVqtz426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdaf88e0-44b4-440e-cc1b-a70ba649c244"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"precision score \" + str(precision_score(preds, y_test, average='macro')))\n",
        "print(\"recall score \" + str(recall_score(preds, y_test, average='macro')))\n",
        "print(\"f1 score \" + str(f1_score(preds, y_test, average='macro')))\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision score 0.48904225352112674\n",
            "recall score 0.437459807073955\n",
            "f1 score 0.4419356968376576\n",
            "raw acc 0.7538940809968847\n",
            "true positive count: 1\n",
            "false positive count: 9\n",
            "true negative count: 241\n",
            "false negative count: 70\n",
            "precision = 0.1\n",
            "recall = 0.014084507042253521\n",
            "F1 = 0.02469135802469136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXAtIKnuFG2z"
      },
      "source": [
        "y_trainencoded = [[] for i in range(len(y_train))] \n",
        "y_testencoded = [[] for i in range(len(y_test))] \n",
        "count = 0\n",
        "for element in y_train:\n",
        "  if(element == 1):\n",
        "    y_trainencoded[count].append(1)\n",
        "    y_trainencoded[count].append(0)\n",
        "  else:\n",
        "    y_trainencoded[count].append(0)\n",
        "    y_trainencoded[count].append(1)\n",
        "  count += 1\n",
        "\n",
        "count2 = 0\n",
        "for element in y_test:\n",
        "  if(element == 1):\n",
        "    y_testencoded[count2].append(1)\n",
        "    y_testencoded[count2].append(0)\n",
        "  else:\n",
        "    y_testencoded[count2].append(0)\n",
        "    y_testencoded[count2].append(1)\n",
        "  count2 += 1\n",
        "y_trainencoded = np.array(y_trainencoded)\n",
        "y_testencoded = np.array(y_testencoded)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEB5yJIK-Xnp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, LSTM\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation = 'relu')) \n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(50, activation = 'relu')) \n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(2, activation = 'softmax'))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9hGB7r70ROx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a4774b92-7c4e-4298-82c4-48d9ab733934"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, y_trainencoded, batch_size = 64, epochs = 10, validation_split= .2, shuffle = True)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-8431ed42886e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.compile(loss='binary_crossentropy',\n\u001b[1;32m      3\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trainencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Adam' from 'keras.optimizers' (/usr/local/lib/python3.7/dist-packages/keras/optimizers.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtksM0gFGTeg"
      },
      "source": [
        "modelOutput = model.predict(X_test)\n",
        "preds = []\n",
        "for element in modelOutput:\n",
        "  preds.append(np.argmax(element))\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"precision score \" + str(precision_score(preds, y_test, average='macro')))\n",
        "print(\"recall score \" + str(recall_score(preds, y_test, average='macro')))\n",
        "print(\"f1 score \" + str(f1_score(preds, y_test, average='macro')))\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == np.argmax(y_testencoded[i])):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_testencoded)))\n",
        "tempPreds = []\n",
        "for i in preds:\n",
        "  tempPreds.append(np.argmax(i))\n",
        "print_counts(y_test, tempPreds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FRpAp5LHcFz"
      },
      "source": [
        "## Attempting Machine Learning and Deep Learning Models w/ Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu8SIZHGHbcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea5d7b0d-2400-4559-e291-65cb29296b53"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "d_class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "d_class_weights = {i : d_class_weights[i] for i in range(2)}\n",
        "d_class_weights"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.6404363974001857, 1: 2.2801652892561983}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO6BOoPKVwPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6bdf0c-8014-4b06-c2a5-1fe5fd39ca4e"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(class_weight= d_class_weights)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.5171339563862928\n",
            "true positive count: 42\n",
            "false positive count: 126\n",
            "true negative count: 124\n",
            "false negative count: 29\n",
            "precision = 0.25\n",
            "recall = 0.5915492957746479\n",
            "F1 = 0.3514644351464435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G66ZP_ZIWS_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afaa463a-b134-4c41-a2fc-0e897c85a62f"
      },
      "source": [
        "import sklearn\n",
        "model = SVC(class_weight= d_class_weights)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.5856697819314641\n",
            "true positive count: 38\n",
            "false positive count: 100\n",
            "true negative count: 150\n",
            "false negative count: 33\n",
            "precision = 0.2753623188405797\n",
            "recall = 0.5352112676056338\n",
            "F1 = 0.3636363636363636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1auP5GnJKYMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18b95e1-5408-4299-fbc3-604a5172a514"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(class_weight= d_class_weights)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.6853582554517134\n",
            "true positive count: 10\n",
            "false positive count: 40\n",
            "true negative count: 210\n",
            "false negative count: 61\n",
            "precision = 0.2\n",
            "recall = 0.14084507042253522\n",
            "F1 = 0.16528925619834714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8oM2NxsJ3QI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59830414-d435-4108-e44d-9f95e04ecfa1"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(class_weight= d_class_weights)\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.7507788161993769\n",
            "true positive count: 1\n",
            "false positive count: 10\n",
            "true negative count: 240\n",
            "false negative count: 70\n",
            "precision = 0.09090909090909091\n",
            "recall = 0.014084507042253521\n",
            "F1 = 0.02439024390243903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2SzESGJHZjg"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, LSTM\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(5000, activation = 'relu')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(50, activation = 'relu')) \n",
        "model.add(Dense(2, activation = 'softmax'))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkTxWxxGH3p9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdba4f2c-c581-4831-be9e-106a15f470d6"
      },
      "source": [
        "import keras.optimizers\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_train, y_trainencoded, batch_size = 64, epochs = 20, validation_split= .2, shuffle = True, class_weight = d_class_weights)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "35/35 [==============================] - 1s 9ms/step - loss: 1.2821 - accuracy: 0.7775 - val_loss: 0.6718 - val_accuracy: 0.7935\n",
            "Epoch 2/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.2550 - accuracy: 0.7775 - val_loss: 0.6625 - val_accuracy: 0.7935\n",
            "Epoch 3/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.7775 - val_loss: 0.6536 - val_accuracy: 0.7935\n",
            "Epoch 4/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.2033 - accuracy: 0.7775 - val_loss: 0.6451 - val_accuracy: 0.7935\n",
            "Epoch 5/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.1789 - accuracy: 0.7775 - val_loss: 0.6368 - val_accuracy: 0.7935\n",
            "Epoch 6/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.1551 - accuracy: 0.7775 - val_loss: 0.6290 - val_accuracy: 0.7935\n",
            "Epoch 7/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.1322 - accuracy: 0.7775 - val_loss: 0.6216 - val_accuracy: 0.7935\n",
            "Epoch 8/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.1099 - accuracy: 0.7775 - val_loss: 0.6144 - val_accuracy: 0.7935\n",
            "Epoch 9/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.0885 - accuracy: 0.7775 - val_loss: 0.6076 - val_accuracy: 0.7935\n",
            "Epoch 10/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.0677 - accuracy: 0.7775 - val_loss: 0.6011 - val_accuracy: 0.7935\n",
            "Epoch 11/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.0476 - accuracy: 0.7775 - val_loss: 0.5949 - val_accuracy: 0.7935\n",
            "Epoch 12/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.0281 - accuracy: 0.7775 - val_loss: 0.5891 - val_accuracy: 0.7935\n",
            "Epoch 13/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 1.0094 - accuracy: 0.7775 - val_loss: 0.5834 - val_accuracy: 0.7935\n",
            "Epoch 14/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9912 - accuracy: 0.7775 - val_loss: 0.5782 - val_accuracy: 0.7935\n",
            "Epoch 15/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9737 - accuracy: 0.7775 - val_loss: 0.5731 - val_accuracy: 0.7935\n",
            "Epoch 16/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9568 - accuracy: 0.7775 - val_loss: 0.5684 - val_accuracy: 0.7935\n",
            "Epoch 17/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9405 - accuracy: 0.7775 - val_loss: 0.5638 - val_accuracy: 0.7935\n",
            "Epoch 18/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9247 - accuracy: 0.7775 - val_loss: 0.5596 - val_accuracy: 0.7935\n",
            "Epoch 19/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.9096 - accuracy: 0.7775 - val_loss: 0.5555 - val_accuracy: 0.7935\n",
            "Epoch 20/20\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.8948 - accuracy: 0.7775 - val_loss: 0.5517 - val_accuracy: 0.7935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f27d7ae30d0>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19cWc801IHWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8fcc93-0997-4d8a-c1b1-c78ce209dc76"
      },
      "source": [
        "modelOutput = model.predict(X_test)\n",
        "preds = []\n",
        "for element in modelOutput:\n",
        "  preds.append(np.argmax(element))\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"precision score \" + str(precision_score(preds, y_test, average='macro')))\n",
        "print(\"recall score \" + str(recall_score(preds, y_test, average='macro')))\n",
        "print(\"f1 score \" + str(f1_score(preds, y_test, average='macro')))\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == np.argmax(y_testencoded[i])):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_testencoded)))\n",
        "tempPreds = []\n",
        "for i in preds:\n",
        "  tempPreds.append(np.argmax(i))\n",
        "print_counts(y_test, tempPreds)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision score 0.5\n",
            "recall score 0.11059190031152648\n",
            "f1 score 0.18112244897959184\n",
            "raw acc 0.778816199376947\n",
            "true positive count: 0\n",
            "false positive count: 0\n",
            "true negative count: 250\n",
            "false negative count: 71\n",
            "precision = 1\n",
            "recall = 0.0\n",
            "F1 = 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YVkWPdPMCk8"
      },
      "source": [
        "## Attempting Machine Learning and Deep Learning Models w/ Simple Random Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSfXEQ4GM2Vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b0778e-144f-407c-bdf6-40b89081adbb"
      },
      "source": [
        "X_train = tr_resultdf[\"features_imputed\"]\n",
        "X_test = te_resultdf[\"features_imputed\"]\n",
        "y_train = tr_resultdf[\"label\"]\n",
        "y_test = te_resultdf[\"label\"]\n",
        "X_train = X_train.map(lambda vector: vector.toArray())\n",
        "X_test = X_test.map(lambda vector: vector.toArray())\n",
        "#vstack to increase shape for sklearn / tf\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.vstack(X_test)\n",
        "print(X_train.shape)\n",
        "X_test.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2759, 348)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(321, 348)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IseeHSp6MFCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313105d3-c4e7-471b-9ce6-466c331029c5"
      },
      "source": [
        "import imblearn\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "X_trainoversampled, y_trainoversampled = oversample.fit_resample(X_train, y_train)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvXjAPeqbTyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb068f05-75e8-42d1-8857-7e42649a6c49"
      },
      "source": [
        "import sklearn\n",
        "model = LogisticRegression()\n",
        "model.fit(X_trainoversampled, y_trainoversampled)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.5700934579439252\n",
            "true positive count: 40\n",
            "false positive count: 107\n",
            "true negative count: 143\n",
            "false negative count: 31\n",
            "precision = 0.272108843537415\n",
            "recall = 0.5633802816901409\n",
            "F1 = 0.3669724770642202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrlnVE3OMaGj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4010e134-a2d6-4ea0-da7d-e30bc2357ca7"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.svm import SVC\n",
        "model = SVC()\n",
        "model.fit(X_trainoversampled, y_trainoversampled)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.5887850467289719\n",
            "true positive count: 40\n",
            "false positive count: 101\n",
            "true negative count: 149\n",
            "false negative count: 31\n",
            "precision = 0.28368794326241137\n",
            "recall = 0.5633802816901409\n",
            "F1 = 0.37735849056603776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loAVPMwTb31W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4fae89-9bb0-49ed-b2d3-4d8b4666947a"
      },
      "source": [
        "import sklearn\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_trainoversampled, y_trainoversampled)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.5545171339563862\n",
            "true positive count: 37\n",
            "false positive count: 109\n",
            "true negative count: 141\n",
            "false negative count: 34\n",
            "precision = 0.2534246575342466\n",
            "recall = 0.5211267605633803\n",
            "F1 = 0.34101382488479265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68qOhiqvcJyv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "8b21d685-e162-4fdc-adba-8535d8074c94"
      },
      "source": [
        "import sklearn\n",
        "model = GaussianProcessClassifier()\n",
        "model.fit(X_trainoversampled, y_trainoversampled)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.7632398753894081\n",
            "true positive count: 0\n",
            "false positive count: 5\n",
            "true negative count: 245\n",
            "false negative count: 71\n",
            "precision = 0.0\n",
            "recall = 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-151d20ceaa93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw acc \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-46d82d00c596>\u001b[0m in \u001b[0;36mprint_counts\u001b[0;34m(y_actual, y_hat)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recall = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1 = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03f8Sj8QNfcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3715f4e-1783-4ea1-83b8-4c0d29576e57"
      },
      "source": [
        "import sklearn\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_trainoversampled, y_trainoversampled)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.6822429906542056\n",
            "true positive count: 24\n",
            "false positive count: 55\n",
            "true negative count: 195\n",
            "false negative count: 47\n",
            "precision = 0.3037974683544304\n",
            "recall = 0.3380281690140845\n",
            "F1 = 0.31999999999999995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Arf5G6cug4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7df5d1-dee4-41ad-cff9-638292c69864"
      },
      "source": [
        "import sklearn\n",
        "model = GradientBoostingClassifier()\n",
        "model.fit(X_trainoversampled, y_trainoversampled)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.6230529595015576\n",
            "true positive count: 27\n",
            "false positive count: 77\n",
            "true negative count: 173\n",
            "false negative count: 44\n",
            "precision = 0.25961538461538464\n",
            "recall = 0.38028169014084506\n",
            "F1 = 0.3085714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw-62wLfMa2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1b2ae2-0ba0-4314-822b-bbaeb9488932"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_trainoversampled, y_trainoversampled)\n",
        "preds = model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == y_test[i]):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_test)))\n",
        "print_counts(y_test, preds)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raw acc 0.7414330218068536\n",
            "true positive count: 5\n",
            "false positive count: 17\n",
            "true negative count: 233\n",
            "false negative count: 66\n",
            "precision = 0.22727272727272727\n",
            "recall = 0.07042253521126761\n",
            "F1 = 0.10752688172043011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jb_cDEPOUDO"
      },
      "source": [
        "y_trainencodedoversampled = [[] for i in range(len(y_trainoversampled))] \n",
        "y_testencoded = [[] for i in range(len(y_test))] \n",
        "count = 0\n",
        "for element in y_trainoversampled:\n",
        "  if(element == 1):\n",
        "    y_trainencodedoversampled[count].append(1)\n",
        "    y_trainencodedoversampled[count].append(0)\n",
        "  else:\n",
        "    y_trainencodedoversampled[count].append(0)\n",
        "    y_trainencodedoversampled[count].append(1)\n",
        "  count += 1\n",
        "\n",
        "count2 = 0\n",
        "for element in y_test:\n",
        "  if(element == 1):\n",
        "    y_testencoded[count2].append(1)\n",
        "    y_testencoded[count2].append(0)\n",
        "  else:\n",
        "    y_testencoded[count2].append(0)\n",
        "    y_testencoded[count2].append(1)\n",
        "  count2 += 1\n",
        "y_trainencodedoversampled = np.array(y_trainencodedoversampled)\n",
        "y_testencoded = np.array(y_testencoded)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncM9a8iSOFWX"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, LSTM\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation = 'relu')) \n",
        "model.add(Dense(50, activation = 'relu')) \n",
        "model.add(Dense(2, activation = 'softmax'))"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Fl7wqLOGEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e31703f5-0baf-414a-af54-c7c1330b2e40"
      },
      "source": [
        "import keras.optimizers\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"Adam\",\n",
        "              metrics=['accuracy'])\n",
        "model.fit(X_trainoversampled, y_trainencodedoversampled , batch_size = 64, epochs = 20, shuffle = True)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "68/68 [==============================] - 1s 3ms/step - loss: 2.8572 - accuracy: 0.5571\n",
            "Epoch 2/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.7188 - accuracy: 0.6144\n",
            "Epoch 3/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.8049 - accuracy: 0.5861\n",
            "Epoch 4/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.7089 - accuracy: 0.6202\n",
            "Epoch 5/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.6764\n",
            "Epoch 6/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.6551\n",
            "Epoch 7/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.6486\n",
            "Epoch 8/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.6968\n",
            "Epoch 9/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7073\n",
            "Epoch 10/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6869\n",
            "Epoch 11/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6910\n",
            "Epoch 12/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.7101\n",
            "Epoch 13/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6938\n",
            "Epoch 14/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7173\n",
            "Epoch 15/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.6852\n",
            "Epoch 16/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6968\n",
            "Epoch 17/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.5501\n",
            "Epoch 18/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f27306525d0>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1qqtdCHOKRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b9de3e-fb41-4655-ada2-337de6a97ba1"
      },
      "source": [
        "modelOutput = model.predict(X_test)\n",
        "preds = []\n",
        "for element in modelOutput:\n",
        "  preds.append(np.argmax(element))\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"precision score \" + str(precision_score(preds, y_test, average='macro')))\n",
        "print(\"recall score \" + str(recall_score(preds, y_test, average='macro')))\n",
        "print(\"f1 score \" + str(f1_score(preds, y_test, average='macro')))\n",
        "count = 0\n",
        "for i in range(len(preds)):\n",
        "  if(preds[i] == np.argmax(y_testencoded[i])):\n",
        "    count += 1\n",
        "print(\"raw acc \" + str(count / len(y_testencoded)))\n",
        "tempPreds = []\n",
        "for i in preds:\n",
        "  tempPreds.append(np.argmax(i))\n",
        "print_counts(y_test, tempPreds)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision score 0.5\n",
            "recall score 0.11059190031152648\n",
            "f1 score 0.18112244897959184\n",
            "raw acc 0.778816199376947\n",
            "true positive count: 0\n",
            "false positive count: 0\n",
            "true negative count: 250\n",
            "false negative count: 71\n",
            "precision = 1\n",
            "recall = 0.0\n",
            "F1 = 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFr11rYKZL8f"
      },
      "source": [
        "## Preprocessing Clinical Note Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdOwm2BMY761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "df4b32c1-a8df-433b-a87e-5ccb288a61f4"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv.gz\", low_memory= False)\n",
        "df.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROW_ID</th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>CHARTDATE</th>\n",
              "      <th>CHARTTIME</th>\n",
              "      <th>STORETIME</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>CGID</th>\n",
              "      <th>ISERROR</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>174</td>\n",
              "      <td>22532</td>\n",
              "      <td>167853.0</td>\n",
              "      <td>2151-08-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175</td>\n",
              "      <td>13702</td>\n",
              "      <td>107527.0</td>\n",
              "      <td>2118-06-14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>176</td>\n",
              "      <td>13702</td>\n",
              "      <td>167118.0</td>\n",
              "      <td>2119-05-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>177</td>\n",
              "      <td>13702</td>\n",
              "      <td>196489.0</td>\n",
              "      <td>2124-08-18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>178</td>\n",
              "      <td>26880</td>\n",
              "      <td>135453.0</td>\n",
              "      <td>2162-03-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ROW_ID  ...                                               TEXT\n",
              "0     174  ...  Admission Date:  [**2151-7-16**]       Dischar...\n",
              "1     175  ...  Admission Date:  [**2118-6-2**]       Discharg...\n",
              "2     176  ...  Admission Date:  [**2119-5-4**]              D...\n",
              "3     177  ...  Admission Date:  [**2124-7-21**]              ...\n",
              "4     178  ...  Admission Date:  [**2162-3-3**]              D...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zspvpsmwnKr5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "dcbd2a6d-6dae-42c7-ecd1-f92d4c3d10d7"
      },
      "source": [
        "tr_resultdf.head()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>TIME_OBS</th>\n",
              "      <th>TIME_SPAN</th>\n",
              "      <th>imp_N_227465_std</th>\n",
              "      <th>imp_N_225625_avg</th>\n",
              "      <th>imp_N_220179_max</th>\n",
              "      <th>imp_N_227073_avg</th>\n",
              "      <th>imp_N_51237_std</th>\n",
              "      <th>imp_N_220047_TT</th>\n",
              "      <th>imp_N_51222_LT</th>\n",
              "      <th>imp_N_220621_min</th>\n",
              "      <th>imp_N_220181_avg</th>\n",
              "      <th>imp_N_50960_LT</th>\n",
              "      <th>imp_N_51006_avg</th>\n",
              "      <th>imp_N_220180_min</th>\n",
              "      <th>imp_N_223751_LT</th>\n",
              "      <th>imp_N_227442_avg</th>\n",
              "      <th>imp_N_220046_std</th>\n",
              "      <th>imp_N_220181_TT</th>\n",
              "      <th>imp_N_220180_max</th>\n",
              "      <th>imp_N_50960_min</th>\n",
              "      <th>imp_N_51222_avg</th>\n",
              "      <th>imp_N_220046_LT</th>\n",
              "      <th>imp_N_220228_std</th>\n",
              "      <th>imp_N_227442_std</th>\n",
              "      <th>imp_N_50902_TT</th>\n",
              "      <th>imp_N_51265_min</th>\n",
              "      <th>imp_N_223761_std</th>\n",
              "      <th>imp_N_50902_LT</th>\n",
              "      <th>imp_N_50902_std</th>\n",
              "      <th>imp_N_50912_avg</th>\n",
              "      <th>imp_N_51274_max</th>\n",
              "      <th>imp_N_51248_min</th>\n",
              "      <th>imp_N_227467_max</th>\n",
              "      <th>imp_N_227073_TT</th>\n",
              "      <th>imp_N_227465_LT</th>\n",
              "      <th>imp_N_51237_avg</th>\n",
              "      <th>imp_N_223769_std</th>\n",
              "      <th>imp_N_220179_TT</th>\n",
              "      <th>imp_N_223761_min</th>\n",
              "      <th>...</th>\n",
              "      <th>imp_N_223751_avg</th>\n",
              "      <th>imp_N_220645_avg</th>\n",
              "      <th>imp_N_224162_avg</th>\n",
              "      <th>imp_N_50868_LT</th>\n",
              "      <th>imp_N_50902_max</th>\n",
              "      <th>imp_N_50912_std</th>\n",
              "      <th>imp_N_227465_avg</th>\n",
              "      <th>imp_N_220645_max</th>\n",
              "      <th>imp_N_51221_std</th>\n",
              "      <th>imp_N_227467_avg</th>\n",
              "      <th>imp_N_220210_avg</th>\n",
              "      <th>imp_N_51249_avg</th>\n",
              "      <th>imp_N_51250_LT</th>\n",
              "      <th>imp_N_220228_TT</th>\n",
              "      <th>imp_N_51237_min</th>\n",
              "      <th>imp_N_225677_std</th>\n",
              "      <th>imp_N_50983_avg</th>\n",
              "      <th>imp_N_51250_std</th>\n",
              "      <th>imp_N_223751_TT</th>\n",
              "      <th>imp_N_226253_max</th>\n",
              "      <th>imp_N_51265_TT</th>\n",
              "      <th>imp_N_51275_std</th>\n",
              "      <th>imp_N_50970_std</th>\n",
              "      <th>imp_N_51237_max</th>\n",
              "      <th>imp_N_50960_max</th>\n",
              "      <th>imp_N_223770_min</th>\n",
              "      <th>imp_N_220615_std</th>\n",
              "      <th>imp_N_51277_avg</th>\n",
              "      <th>imp_N_220047_std</th>\n",
              "      <th>imp_N_220545_TT</th>\n",
              "      <th>features_imputed</th>\n",
              "      <th>demo_feature</th>\n",
              "      <th>features</th>\n",
              "      <th>DISCH_51881_51851_51884_51853_excl</th>\n",
              "      <th>DISCH_51881_51851_51884_51853_label</th>\n",
              "      <th>label</th>\n",
              "      <th>rawPrediction</th>\n",
              "      <th>probability</th>\n",
              "      <th>prediction</th>\n",
              "      <th>Prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>194216.0</td>\n",
              "      <td>2125-11-06</td>\n",
              "      <td>(2125-11-05 00:00:00, 2125-11-06 00:00:00)</td>\n",
              "      <td>0.130655</td>\n",
              "      <td>8.373489</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.014815</td>\n",
              "      <td>0.041623</td>\n",
              "      <td>0.822296</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>59.181818</td>\n",
              "      <td>0.487134</td>\n",
              "      <td>44.0</td>\n",
              "      <td>31.00000</td>\n",
              "      <td>0.426931</td>\n",
              "      <td>4.750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.344461e-06</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>2.019275</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.383198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.35000</td>\n",
              "      <td>0.892992</td>\n",
              "      <td>247.0</td>\n",
              "      <td>0.698570</td>\n",
              "      <td>0.446496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.40</td>\n",
              "      <td>16.326121</td>\n",
              "      <td>29.8</td>\n",
              "      <td>1.477589</td>\n",
              "      <td>0.047244</td>\n",
              "      <td>0.460002</td>\n",
              "      <td>1.460824</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.163641e-02</td>\n",
              "      <td>96.9</td>\n",
              "      <td>...</td>\n",
              "      <td>160.416362</td>\n",
              "      <td>136.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.977662</td>\n",
              "      <td>103.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>16.227217</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.461156</td>\n",
              "      <td>27.708333</td>\n",
              "      <td>33.8</td>\n",
              "      <td>0.330686</td>\n",
              "      <td>0.362813</td>\n",
              "      <td>1.445393</td>\n",
              "      <td>0.089576</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.726987</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.622558</td>\n",
              "      <td>0.876946</td>\n",
              "      <td>0.091198</td>\n",
              "      <td>1.477641</td>\n",
              "      <td>2.093509</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>15.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.349556</td>\n",
              "      <td>[0.5050020692768213, 0.9899958614463573, 85.04...</td>\n",
              "      <td>(79.64109589041095, 0.0, 1.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>(0.5050020692768213, 0.9899958614463573, 85.04...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[1.3963874412694455, -1.3963874412694455]</td>\n",
              "      <td>[0.9422841413262901, 0.057715858673709874]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057715858673709874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>170247.0</td>\n",
              "      <td>2156-09-17</td>\n",
              "      <td>(2156-09-16 00:00:00, 2156-09-17 00:00:00)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.600000</td>\n",
              "      <td>183.000000</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285276</td>\n",
              "      <td>0.540661</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>101.967742</td>\n",
              "      <td>0.011833</td>\n",
              "      <td>67.0</td>\n",
              "      <td>62.00000</td>\n",
              "      <td>0.426931</td>\n",
              "      <td>4.500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.158139e-25</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>9.8</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.016272</td>\n",
              "      <td>237.0</td>\n",
              "      <td>0.794090</td>\n",
              "      <td>0.991864</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.70</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>34.3</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.185969</td>\n",
              "      <td>0.244142</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.609251e-22</td>\n",
              "      <td>97.4</td>\n",
              "      <td>...</td>\n",
              "      <td>160.416362</td>\n",
              "      <td>143.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.093438</td>\n",
              "      <td>119.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>143.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>18.161290</td>\n",
              "      <td>35.2</td>\n",
              "      <td>0.870506</td>\n",
              "      <td>0.925646</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>143.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.726987</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.692057</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>21.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.878265</td>\n",
              "      <td>[1.0, 4.086259906247097e-24, 115.4482758620689...</td>\n",
              "      <td>(47.8986301369863, 0.0, 1.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>(1.0, 4.086259906247097e-24, 115.4482758620689...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.5703515386897479, -0.5703515386897479]</td>\n",
              "      <td>[0.7578087014694355, 0.24219129853056454]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.24219129853056454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-13</td>\n",
              "      <td>(2152-06-12 00:00:00, 2152-06-13 00:00:00)</td>\n",
              "      <td>0.130655</td>\n",
              "      <td>8.373489</td>\n",
              "      <td>138.940579</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.014815</td>\n",
              "      <td>0.130766</td>\n",
              "      <td>0.215207</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>74.778262</td>\n",
              "      <td>0.151826</td>\n",
              "      <td>25.0</td>\n",
              "      <td>47.70464</td>\n",
              "      <td>0.426931</td>\n",
              "      <td>3.300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.071838e-01</td>\n",
              "      <td>78.036967</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.303425</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.20000</td>\n",
              "      <td>0.028974</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.669370</td>\n",
              "      <td>0.985513</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.85</td>\n",
              "      <td>16.326121</td>\n",
              "      <td>29.7</td>\n",
              "      <td>1.477589</td>\n",
              "      <td>0.937650</td>\n",
              "      <td>0.460002</td>\n",
              "      <td>1.460824</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.961978e-01</td>\n",
              "      <td>97.6</td>\n",
              "      <td>...</td>\n",
              "      <td>160.416362</td>\n",
              "      <td>146.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.537595</td>\n",
              "      <td>115.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>16.227217</td>\n",
              "      <td>148.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.461156</td>\n",
              "      <td>14.781250</td>\n",
              "      <td>32.2</td>\n",
              "      <td>0.601945</td>\n",
              "      <td>0.428681</td>\n",
              "      <td>1.445393</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>146.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.726987</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.237618</td>\n",
              "      <td>0.876946</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.477641</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>16.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.605820</td>\n",
              "      <td>[0.9999999931350856, 1.3729828743819694e-08, 1...</td>\n",
              "      <td>(65.7068493150685, 1.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
              "      <td>(0.9999999931350856, 1.3729828743819694e-08, 1...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.9471888131157044, -0.9471888131157044]</td>\n",
              "      <td>[0.8692538594617801, 0.13074614053821987]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.13074614053821987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>133334.0</td>\n",
              "      <td>2118-03-08</td>\n",
              "      <td>(2118-03-07 00:00:00, 2118-03-08 00:00:00)</td>\n",
              "      <td>0.130655</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.014815</td>\n",
              "      <td>0.217266</td>\n",
              "      <td>0.784404</td>\n",
              "      <td>120.724835</td>\n",
              "      <td>77.823529</td>\n",
              "      <td>0.027335</td>\n",
              "      <td>7.0</td>\n",
              "      <td>48.00000</td>\n",
              "      <td>0.341337</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.083953e-01</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>10.8</td>\n",
              "      <td>0.276197</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.492897</td>\n",
              "      <td>346.0</td>\n",
              "      <td>0.530919</td>\n",
              "      <td>0.753552</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.60</td>\n",
              "      <td>16.326121</td>\n",
              "      <td>29.2</td>\n",
              "      <td>1.477589</td>\n",
              "      <td>0.295072</td>\n",
              "      <td>0.460002</td>\n",
              "      <td>1.460824</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.582276e-01</td>\n",
              "      <td>97.7</td>\n",
              "      <td>...</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>138.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.148567</td>\n",
              "      <td>108.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>16.227217</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.461156</td>\n",
              "      <td>20.235294</td>\n",
              "      <td>34.8</td>\n",
              "      <td>0.128329</td>\n",
              "      <td>0.438981</td>\n",
              "      <td>1.445393</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>138.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.682673</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.148717</td>\n",
              "      <td>0.876946</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.477641</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>13.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.566917</td>\n",
              "      <td>[0.10394428699230962, 0.20788857398461924, 80....</td>\n",
              "      <td>(48.45205479452055, 1.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
              "      <td>(0.10394428699230962, 0.20788857398461924, 80....</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[1.4681953423556071, -1.4681953423556071]</td>\n",
              "      <td>[0.94961631849267, 0.05038368150732997]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05038368150732997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>160561.0</td>\n",
              "      <td>2142-08-21</td>\n",
              "      <td>(2142-08-20 00:00:00, 2142-08-21 00:00:00)</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.300000</td>\n",
              "      <td>138.940579</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041623</td>\n",
              "      <td>0.404993</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>74.778262</td>\n",
              "      <td>0.414705</td>\n",
              "      <td>18.0</td>\n",
              "      <td>47.70464</td>\n",
              "      <td>0.426931</td>\n",
              "      <td>3.525</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.071838e-01</td>\n",
              "      <td>78.036967</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>9.3</td>\n",
              "      <td>0.818222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.34187</td>\n",
              "      <td>0.331550</td>\n",
              "      <td>327.0</td>\n",
              "      <td>0.603922</td>\n",
              "      <td>0.165775</td>\n",
              "      <td>2.061553</td>\n",
              "      <td>0.60</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>29.2</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.440415</td>\n",
              "      <td>0.165351</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.961978e-01</td>\n",
              "      <td>97.8</td>\n",
              "      <td>...</td>\n",
              "      <td>160.416362</td>\n",
              "      <td>130.5</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.222049</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>133.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>16.041667</td>\n",
              "      <td>34.7</td>\n",
              "      <td>0.128329</td>\n",
              "      <td>0.804919</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>130.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.726987</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.207153</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>15.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.675009</td>\n",
              "      <td>[0.9999909972160833, 1.800556783332397e-05, 99...</td>\n",
              "      <td>(62.156164383561645, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.9999909972160833, 1.800556783332397e-05, 99...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[0.978614363702355, -0.978614363702355]</td>\n",
              "      <td>[0.8762327240900406, 0.1237672759099594]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1237672759099594</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  361 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID    TIME_OBS  ... prediction                  Prob\n",
              "0  194216.0  2125-11-06  ...        0.0  0.057715858673709874\n",
              "1  170247.0  2156-09-17  ...        0.0   0.24219129853056454\n",
              "2  147237.0  2152-06-13  ...        0.0   0.13074614053821987\n",
              "3  133334.0  2118-03-08  ...        0.0   0.05038368150732997\n",
              "4  160561.0  2142-08-21  ...        0.0    0.1237672759099594\n",
              "\n",
              "[5 rows x 361 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cctUSBwbaRvy"
      },
      "source": [
        "trainingIds = tr_resultdf[\"ID\"]\n",
        "testingIds = te_resultdf[\"ID\"]\n",
        "trainingTimes = tr_resultdf[\"TIME_SPAN\"]\n",
        "testingTimes = te_resultdf[\"TIME_SPAN\"]"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eedX7KUgkHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e8f4ce-9bc7-4bb7-98ee-013a053199e3"
      },
      "source": [
        "trainingTimes[0][0]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2125, 11, 5, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRjYBIg6n0Wa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b282c601-0d75-495f-b6bf-c8e546a1f26c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROW_ID</th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>CHARTDATE</th>\n",
              "      <th>CHARTTIME</th>\n",
              "      <th>STORETIME</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>CGID</th>\n",
              "      <th>ISERROR</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>174</td>\n",
              "      <td>22532</td>\n",
              "      <td>167853.0</td>\n",
              "      <td>2151-08-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2151-7-16**]       Dischar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175</td>\n",
              "      <td>13702</td>\n",
              "      <td>107527.0</td>\n",
              "      <td>2118-06-14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2118-6-2**]       Discharg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>176</td>\n",
              "      <td>13702</td>\n",
              "      <td>167118.0</td>\n",
              "      <td>2119-05-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2119-5-4**]              D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>177</td>\n",
              "      <td>13702</td>\n",
              "      <td>196489.0</td>\n",
              "      <td>2124-08-18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2124-7-21**]              ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>178</td>\n",
              "      <td>26880</td>\n",
              "      <td>135453.0</td>\n",
              "      <td>2162-03-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2162-3-3**]              D...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ROW_ID  ...                                               TEXT\n",
              "0     174  ...  Admission Date:  [**2151-7-16**]       Dischar...\n",
              "1     175  ...  Admission Date:  [**2118-6-2**]       Discharg...\n",
              "2     176  ...  Admission Date:  [**2119-5-4**]              D...\n",
              "3     177  ...  Admission Date:  [**2124-7-21**]              ...\n",
              "4     178  ...  Admission Date:  [**2162-3-3**]              D...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atwnwTdxhkGz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "e45c91d6-51e9-4204-8544-4784398ed0b7"
      },
      "source": [
        "from datetime import datetime\n",
        "curId = trainingIds[2]\n",
        "print(curId)\n",
        "rowNoteDF = df.loc[df['HADM_ID'] == int(curId)]\n",
        "rowNoteDF = rowNoteDF.reset_index()\n",
        "cur = rowNoteDF[\"CHARTDATE\"][0]\n",
        "print(cur)\n",
        "x = datetime(int(cur[0:4]), int(cur[5:7]), int(cur[-2:]), 1)\n",
        "x\n",
        "print(trainingTimes[2][1])\n",
        "rowNoteDF.head(10)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "147237.0\n",
            "2152-06-13\n",
            "2152-06-13 00:00:00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>ROW_ID</th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>CHARTDATE</th>\n",
              "      <th>CHARTTIME</th>\n",
              "      <th>STORETIME</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>CGID</th>\n",
              "      <th>ISERROR</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3328</td>\n",
              "      <td>3181</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2152-6-4**]              D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62775</td>\n",
              "      <td>62150</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Echo</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>PATIENT/TEST INFORMATION:\\nIndication: Congest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>109332</td>\n",
              "      <td>121541</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ECG</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sinus rhythm\\nRight bundle branch block\\nLeft ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>109398</td>\n",
              "      <td>121591</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ECG</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Baseline artifact\\nSinus tachycardia\\nRight bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>109399</td>\n",
              "      <td>121592</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ECG</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sinus tachycardia.  Right bundle-branch block....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>109400</td>\n",
              "      <td>121593</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-05-29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ECG</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sinus rhythm.  Left atrial abnormality.  Right...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>112469</td>\n",
              "      <td>121540</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ECG</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sinus tachycardia\\nRight bundle branch block\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>324346</td>\n",
              "      <td>327813</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-04</td>\n",
              "      <td>2152-06-04 09:23:00</td>\n",
              "      <td>2152-06-04 09:23:59</td>\n",
              "      <td>Physician</td>\n",
              "      <td>Physician Attending Admission Note</td>\n",
              "      <td>20066.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Chief Complaint:  DKA\\n   HPI:\\n   65 yo woman...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>324355</td>\n",
              "      <td>327903</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-05</td>\n",
              "      <td>2152-06-05 15:14:00</td>\n",
              "      <td>2152-06-05 17:33:45</td>\n",
              "      <td>Nursing</td>\n",
              "      <td>Nursing Progress Note</td>\n",
              "      <td>14411.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pt is a 65 yr old adm [**2152-6-4**] from EW f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>324357</td>\n",
              "      <td>327907</td>\n",
              "      <td>3969</td>\n",
              "      <td>147237.0</td>\n",
              "      <td>2152-06-05</td>\n",
              "      <td>2152-06-05 09:06:00</td>\n",
              "      <td>2152-06-05 18:02:47</td>\n",
              "      <td>Physician</td>\n",
              "      <td>ICU Attending Note</td>\n",
              "      <td>20066.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Clinician:  Attending\\n   Hypotensive overnigh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index  ROW_ID  ...  ISERROR                                               TEXT\n",
              "0    3328    3181  ...      NaN  Admission Date:  [**2152-6-4**]              D...\n",
              "1   62775   62150  ...      NaN  PATIENT/TEST INFORMATION:\\nIndication: Congest...\n",
              "2  109332  121541  ...      NaN  Sinus rhythm\\nRight bundle branch block\\nLeft ...\n",
              "3  109398  121591  ...      NaN  Baseline artifact\\nSinus tachycardia\\nRight bu...\n",
              "4  109399  121592  ...      NaN  Sinus tachycardia.  Right bundle-branch block....\n",
              "5  109400  121593  ...      NaN  Sinus rhythm.  Left atrial abnormality.  Right...\n",
              "6  112469  121540  ...      NaN  Sinus tachycardia\\nRight bundle branch block\\n...\n",
              "7  324346  327813  ...      NaN  Chief Complaint:  DKA\\n   HPI:\\n   65 yo woman...\n",
              "8  324355  327903  ...      NaN  Pt is a 65 yr old adm [**2152-6-4**] from EW f...\n",
              "9  324357  327907  ...      NaN  Clinician:  Attending\\n   Hypotensive overnigh...\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEYk9SiKoVb-"
      },
      "source": [
        "#IMPORTANT PROBLEM - UNDERSTAND WHAT NOTES TO USE USING HADM_ID -> corresponds to each patient visit, figure out what features should like (perhaps n-vector where n is each type of category note)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ7oaf6wacPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8edc28b4-282b-4b02-889a-3338cc404694"
      },
      "source": [
        "trainingText = []\n",
        "for i in range(len(trainingIds)):\n",
        "  curId = trainingIds[i]\n",
        "  rowNoteDF = df.loc[df['ROW_ID'] == int(curId)]\n",
        "  rowNoteDF = rowNoteDF.reset_index()\n",
        "  cur = rowNoteDF[\"CHARTDATE\"][0]\n",
        "  noteDate = datetime(int(cur[0:4]), int(cur[5:7]), int(cur[-2:]), 1)\n",
        "  print(trainingTimes[i][0])\n",
        "  print(noteDate)\n",
        "  print(trainingTimes[i][1])\n",
        "  rowNoteDF.head()\n",
        "  break\n",
        "  if(trainingTimes[i][0] <= noteDate <= trainingTimes[i][1]):\n",
        "    trainingText.append(rowNoteDF[\"TEXT\"][0])\n",
        "  else:\n",
        "    trainingText.append([\"\"])\n",
        "    print(\"strange\")\n",
        "\n",
        "testingText = []\n",
        "for i in range(len(testingIds)):\n",
        "  curId = trainingIds[i]\n",
        "  rowNoteDF = df.loc[df['ROW_ID'] == int(curId)]\n",
        "  rowNoteDF = rowNoteDF.reset_index()\n",
        "  testingText.append(rowNoteDF[\"TEXT\"][0])\n",
        "print(len(trainingText))\n",
        "len(testingText)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2125-11-05 00:00:00\n",
            "2174-07-02 01:00:00\n",
            "2125-11-06 00:00:00\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "321"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2KrhPnYn0__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff16a5d2-116d-4170-e4fe-b6b9b5b8892a"
      },
      "source": [
        "# Tokenizing inputs and saving it in tokenizedInputs\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "tokenizedTraining = []\n",
        "for i in range(len(trainingText)):\n",
        "  tokenizedTraining.append(nltk.word_tokenize(trainingText[i]))\n",
        "tokenizedTesting = []\n",
        "for i in range(len(testingText)):\n",
        "  tokenizedTesting.append(nltk.word_tokenize(testingText[i]))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN1WSJRUlY2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d12f61-1db0-49de-a164-e1408293816e"
      },
      "source": [
        "import nltk\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import re, string\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "def remove_noise_and_lemmatize(tweet_tokens, stop_words = ()):\n",
        "    cleaned_tokens = []\n",
        "    for token, tag in pos_tag(tweet_tokens):\n",
        "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
        "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
        "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
        "        if tag.startswith(\"NN\"):\n",
        "            pos = 'n'\n",
        "        elif tag.startswith('VB'):\n",
        "            pos = 'v'\n",
        "        else:\n",
        "            pos = 'a'\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        token = lemmatizer.lemmatize(token, pos)\n",
        "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
        "            cleaned_tokens.append(token.lower())\n",
        "    return cleaned_tokens"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mjyXBkNmOZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3422e967-bbe0-4beb-e21c-8cedfa0f8e52"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "cleanedTraining = []  \n",
        "for i in range(len(tokenizedTraining)):\n",
        "  cleanedTraining.append(remove_noise_and_lemmatize(tokenizedTraining[i], stop_words))\n",
        "cleanedTesting = []  \n",
        "for i in range(len(tokenizedTesting)):\n",
        "  cleanedTesting.append(remove_noise_and_lemmatize(tokenizedTesting[i], stop_words))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}